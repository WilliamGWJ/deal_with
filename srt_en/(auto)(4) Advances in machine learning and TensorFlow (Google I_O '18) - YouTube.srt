1
00:00:05,850 --> 00:00:08,589
hi everybody and welcome to this session

2
00:00:08,589 --> 00:00:09,519
where we're going to talk about

3
00:00:09,519 --> 00:00:11,259
breakthroughs and machine learning I'm

4
00:00:11,259 --> 00:00:12,849
Laurence Moroney I'm a developer

5
00:00:12,849 --> 00:00:15,129
advocate at Google are working on

6
00:00:15,129 --> 00:00:16,710
tensorflow with the Google brain team

7
00:00:16,710 --> 00:00:19,000
we're here today to talk about the

8
00:00:19,000 --> 00:00:20,800
revolution that's going on in machine

9
00:00:20,800 --> 00:00:22,510
learning and how that revolution is

10
00:00:22,510 --> 00:00:24,099
transformative now

11
00:00:24,099 --> 00:00:25,359
I come from a software development

12
00:00:25,359 --> 00:00:27,480
background any software developers here

13
00:00:27,480 --> 00:00:30,759
given that at i/o sure and this is this

14
00:00:30,759 --> 00:00:32,710
transformation this revolution is

15
00:00:32,710 --> 00:00:34,540
particularly from a developer's

16
00:00:34,540 --> 00:00:36,520
perspective is really really cool

17
00:00:36,520 --> 00:00:38,559
because it's giving us a whole new set

18
00:00:38,559 --> 00:00:40,690
of tools that we can use to build

19
00:00:40,690 --> 00:00:42,910
scenarios and to build solutions for

20
00:00:42,910 --> 00:00:44,350
problems that may have been too complex

21
00:00:44,350 --> 00:00:47,020
to even consider prior to this it's also

22
00:00:47,020 --> 00:00:49,480
leading to massive advances in our

23
00:00:49,480 --> 00:00:50,829
understanding of things like the

24
00:00:50,829 --> 00:00:53,170
universe around us it's opening up new

25
00:00:53,170 --> 00:00:55,629
fields in arts and it's impacting and

26
00:00:55,629 --> 00:00:56,920
revolutionising things such as

27
00:00:56,920 --> 00:00:59,019
healthcare and so many more things so

28
00:00:59,019 --> 00:01:00,329
should we take a look at some of these

29
00:01:00,329 --> 00:01:03,969
so first of all astronomy at school I

30
00:01:03,969 --> 00:01:05,710
studied physics I wasn't the comm site

31
00:01:05,710 --> 00:01:07,180
person so I'm a physics and astronomy

32
00:01:07,180 --> 00:01:09,790
geek and it wasn't that long ago when we

33
00:01:09,790 --> 00:01:11,800
learned how to discover what new how new

34
00:01:11,800 --> 00:01:13,620
planets around other stars in our galaxy

35
00:01:13,620 --> 00:01:16,090
and what the way that we discovered it

36
00:01:16,090 --> 00:01:17,740
was that sometimes would observe like a

37
00:01:17,740 --> 00:01:19,960
little wobble in the star and that meant

38
00:01:19,960 --> 00:01:21,490
that there was a very large planet like

39
00:01:21,490 --> 00:01:23,020
Jupiter size or even bigger

40
00:01:23,020 --> 00:01:24,880
orbiting that star very closely and

41
00:01:24,880 --> 00:01:26,200
causing a wobble because of the

42
00:01:26,200 --> 00:01:28,450
gravitational attraction but of course

43
00:01:28,450 --> 00:01:30,040
the kind of planets we want to find out

44
00:01:30,040 --> 00:01:31,600
the small rocky ones like our earth on

45
00:01:31,600 --> 00:01:33,490
Mars where you know there's a chance of

46
00:01:33,490 --> 00:01:36,000
finding life on these planets and

47
00:01:36,000 --> 00:01:38,530
finding those and discovering those was

48
00:01:38,530 --> 00:01:41,050
very very difficult to do because small

49
00:01:41,050 --> 00:01:42,610
ones close to the star you just wouldn't

50
00:01:42,610 --> 00:01:46,750
see but there's with research that's

51
00:01:46,750 --> 00:01:48,100
been going on in the Kepler mission

52
00:01:48,100 --> 00:01:50,020
they've actually recently discovered

53
00:01:50,020 --> 00:01:51,880
this planet called Kepler 90i

54
00:01:51,880 --> 00:01:54,130
by sifting through data and building

55
00:01:54,130 --> 00:01:55,900
models for using machine learning and

56
00:01:55,900 --> 00:01:58,210
using tensorflow and Kepler 90i is

57
00:01:58,210 --> 00:02:00,670
actually much closer to its host star

58
00:02:00,670 --> 00:02:02,380
than Earth is so that its orbit is only

59
00:02:02,380 --> 00:02:05,650
14 days instead of our 365 and a quarter

60
00:02:05,650 --> 00:02:07,990
in a bitch and not only that which I

61
00:02:07,990 --> 00:02:09,789
find really cool but they didn't just

62
00:02:09,789 --> 00:02:11,770
find this as a single planet around that

63
00:02:11,770 --> 00:02:13,630
star they've actually mapped and

64
00:02:13,630 --> 00:02:15,700
the entire solar system of eight planets

65
00:02:15,700 --> 00:02:17,650
that are there so these are some of the

66
00:02:17,650 --> 00:02:20,020
advances it's it to me I find it's just

67
00:02:20,020 --> 00:02:21,490
a wonderful time to be alive because

68
00:02:21,490 --> 00:02:23,740
technology is enabling us to discover

69
00:02:23,740 --> 00:02:26,200
these great new things and even closer

70
00:02:26,200 --> 00:02:28,360
to home we've also discovered that

71
00:02:28,360 --> 00:02:30,550
looking at scans of the human eye as you

72
00:02:30,550 --> 00:02:32,500
would have seen in the keynotes you know

73
00:02:32,500 --> 00:02:35,440
with machine learning trained models on

74
00:02:35,440 --> 00:02:37,420
this we've been able to discover things

75
00:02:37,420 --> 00:02:39,280
such as blood pressure predictions or

76
00:02:39,280 --> 00:02:41,650
being able to assess a person's risk of

77
00:02:41,650 --> 00:02:44,320
a heart attack or a stroke now just

78
00:02:44,320 --> 00:02:46,480
imagine if this screening can be done on

79
00:02:46,480 --> 00:02:49,300
a small mobile phone now how profound is

80
00:02:49,300 --> 00:02:51,310
the effect going to be suddenly the

81
00:02:51,310 --> 00:02:52,810
whole world is going to be able to

82
00:02:52,810 --> 00:02:55,960
access easy rapid affordable and

83
00:02:55,960 --> 00:02:58,210
non-invasive screening for things such

84
00:02:58,210 --> 00:02:59,380
as heart diseases

85
00:02:59,380 --> 00:03:01,180
it'll be saving many lives but it will

86
00:03:01,180 --> 00:03:03,100
also be improving the quality of many

87
00:03:03,100 --> 00:03:06,670
many more lives now these are just a few

88
00:03:06,670 --> 00:03:08,980
of the breakthroughs and advances that

89
00:03:08,980 --> 00:03:10,810
have been made because of tensorflow

90
00:03:10,810 --> 00:03:13,090
intensive flow we've been working hard

91
00:03:13,090 --> 00:03:15,190
with the community with all of you to

92
00:03:15,190 --> 00:03:17,230
make this a machine learning platform

93
00:03:17,230 --> 00:03:19,720
for everybody so today I want we want to

94
00:03:19,720 --> 00:03:21,940
share a few of the new advances that

95
00:03:21,940 --> 00:03:23,680
have been working on this so including

96
00:03:23,680 --> 00:03:26,440
we'll be looking at robots and Vincents

97
00:03:26,440 --> 00:03:27,790
going to come out in a few moments to

98
00:03:27,790 --> 00:03:29,680
show us robots that learn and some of

99
00:03:29,680 --> 00:03:31,360
the work that they've been doing to

100
00:03:31,360 --> 00:03:34,630
improve how robots learn and then Debbie

101
00:03:34,630 --> 00:03:37,240
is going to be from Newark she's going

102
00:03:37,240 --> 00:03:39,220
to be showing us cosmology advancements

103
00:03:39,220 --> 00:03:41,170
and including showing how building a

104
00:03:41,170 --> 00:03:43,600
simulation of the entire universe will

105
00:03:43,600 --> 00:03:45,250
help us understand the nature of the

106
00:03:45,250 --> 00:03:47,230
unknowns in our universe like dark

107
00:03:47,230 --> 00:03:49,570
matter and dark energy but first of all

108
00:03:49,570 --> 00:03:51,640
I would love to welcome from the magenta

109
00:03:51,640 --> 00:03:53,560
team we have Doug who's a principal

110
00:03:53,560 --> 00:03:59,470
scientist Doug thanks Lawrence hey

111
00:03:59,470 --> 00:04:01,940
thanks Doug thank you very much

112
00:04:01,940 --> 00:04:05,840
all right day three we're getting there

113
00:04:05,840 --> 00:04:07,910
hi everybody I'm Doug I am a research

114
00:04:07,910 --> 00:04:09,890
scientist at Google working on a project

115
00:04:09,890 --> 00:04:12,260
called magenta and so before we talk

116
00:04:12,260 --> 00:04:13,970
about modeling the entire known universe

117
00:04:13,970 --> 00:04:16,400
so we talked about robots I want to talk

118
00:04:16,400 --> 00:04:17,690
to you a little bit about music and art

119
00:04:17,690 --> 00:04:19,459
and how to use machine learning

120
00:04:19,459 --> 00:04:23,330
potentially for expressive purposes so I

121
00:04:23,330 --> 00:04:24,950
want to talk first about a drawing

122
00:04:24,950 --> 00:04:26,990
project called sketch RNN where we

123
00:04:26,990 --> 00:04:29,060
trained a neural network to do something

124
00:04:29,060 --> 00:04:30,710
as important as draw the pig that you

125
00:04:30,710 --> 00:04:33,590
see on the right there and I want to use

126
00:04:33,590 --> 00:04:34,880
this as an example to actually highlight

127
00:04:34,880 --> 00:04:38,060
a few I think important machine learning

128
00:04:38,060 --> 00:04:40,550
concepts that were finding to be crucial

129
00:04:40,550 --> 00:04:41,930
for using machine learning in the

130
00:04:41,930 --> 00:04:45,620
context of art and music so let's dive

131
00:04:45,620 --> 00:04:47,420
in there's gonna be able to get a little

132
00:04:47,420 --> 00:04:49,100
technical but hopefully it'll be fun for

133
00:04:49,100 --> 00:04:50,870
you all what we're gonna do is try to

134
00:04:50,870 --> 00:04:53,480
learn to draw not by generating pixels

135
00:04:53,480 --> 00:04:55,760
but actually by generating pen strokes

136
00:04:55,760 --> 00:04:57,590
and I think this is a very interesting

137
00:04:57,590 --> 00:04:59,720
representation to use because it's very

138
00:04:59,720 --> 00:05:02,060
close to what we do when we draw so

139
00:05:02,060 --> 00:05:03,380
specifically we're going to take the

140
00:05:03,380 --> 00:05:05,150
data from the very popular quick-draw

141
00:05:05,150 --> 00:05:07,340
game playing pictionary against machine

142
00:05:07,340 --> 00:05:09,440
learning algorithm and that was captured

143
00:05:09,440 --> 00:05:11,930
as Delta X Delta Y movements of the pen

144
00:05:11,930 --> 00:05:14,090
we also know when the pen is put down on

145
00:05:14,090 --> 00:05:15,770
the page and when the pen is lifted up

146
00:05:15,770 --> 00:05:17,660
okay and we're gonna treat that as our

147
00:05:17,660 --> 00:05:19,160
training domain one thing what I would

148
00:05:19,160 --> 00:05:22,280
notice is that our observe is that we

149
00:05:22,280 --> 00:05:23,690
didn't necessarily need a lot of this

150
00:05:23,690 --> 00:05:25,730
data what's nice about the data is that

151
00:05:25,730 --> 00:05:28,400
it fits the creative process it's closer

152
00:05:28,400 --> 00:05:30,890
to drawing I argue than pixels are to

153
00:05:30,890 --> 00:05:32,450
drawing it's actually modeling the

154
00:05:32,450 --> 00:05:36,770
movement of the pen now what we're going

155
00:05:36,770 --> 00:05:38,150
to do with these drawings is we're going

156
00:05:38,150 --> 00:05:39,260
to push them through something called an

157
00:05:39,260 --> 00:05:41,150
auto encoder what you're seeing on the

158
00:05:41,150 --> 00:05:43,250
left the encoder networks job is to take

159
00:05:43,250 --> 00:05:45,560
those strokes of that cat and encode

160
00:05:45,560 --> 00:05:47,210
them in some way so that they can be

161
00:05:47,210 --> 00:05:49,490
stored as a latent vector the yellow box

162
00:05:49,490 --> 00:05:51,680
in the middle the job of the decoder is

163
00:05:51,680 --> 00:05:53,780
to decode that latent vector back into a

164
00:05:53,780 --> 00:05:56,240
generated sketch and the very important

165
00:05:56,240 --> 00:05:57,830
point in fact the only point that you

166
00:05:57,830 --> 00:05:59,030
really need to take away from this talk

167
00:05:59,030 --> 00:06:01,760
is that that latent vector is worth

168
00:06:01,760 --> 00:06:02,540
everything to us

169
00:06:02,540 --> 00:06:05,419
first it's smaller in size than the

170
00:06:05,419 --> 00:06:07,700
encoded or decoded drawing so it can't

171
00:06:07,700 --> 00:06:09,770
memorize everything and because it can't

172
00:06:09,770 --> 00:06:11,180
memorize we actually get some nice

173
00:06:11,180 --> 00:06:13,729
effects for example you might notice if

174
00:06:13,729 --> 00:06:14,940
you look carefully that

175
00:06:14,940 --> 00:06:17,850
cat on the left which is actual data and

176
00:06:17,850 --> 00:06:19,440
it's been pushed through the trained

177
00:06:19,440 --> 00:06:21,960
model and decoded is not the same as the

178
00:06:21,960 --> 00:06:24,630
cat on the right right the cat on the

179
00:06:24,630 --> 00:06:26,730
left has five whiskers but the model

180
00:06:26,730 --> 00:06:28,830
regenerated the sketch with six whiskers

181
00:06:28,830 --> 00:06:30,990
why because that's what it usually sees

182
00:06:30,990 --> 00:06:33,420
six whiskers is general its normal to

183
00:06:33,420 --> 00:06:35,190
the model whereas five whiskers is hard

184
00:06:35,190 --> 00:06:37,170
for the model to make sense of so this

185
00:06:37,170 --> 00:06:39,600
idea of having a tight low dimensional

186
00:06:39,600 --> 00:06:41,550
representation this latent vector that's

187
00:06:41,550 --> 00:06:43,500
been trained on lots of data the goal is

188
00:06:43,500 --> 00:06:45,810
that this model might learn to find some

189
00:06:45,810 --> 00:06:47,760
of the generalities in a drawing learn

190
00:06:47,760 --> 00:06:49,200
general strategies for creating

191
00:06:49,200 --> 00:06:51,000
something so here's an example of

192
00:06:51,000 --> 00:06:54,390
starting each of the four corners with a

193
00:06:54,390 --> 00:06:57,090
drawing done by a human David the first

194
00:06:57,090 --> 00:06:59,280
author and those are encoded in the

195
00:06:59,280 --> 00:07:00,750
corners and now we just move linearly

196
00:07:00,750 --> 00:07:03,000
around the space not the space of the

197
00:07:03,000 --> 00:07:04,530
strokes but the space of the latent

198
00:07:04,530 --> 00:07:06,660
vector and if you look closely what I

199
00:07:06,660 --> 00:07:08,490
think you'll see is that the movements

200
00:07:08,490 --> 00:07:10,680
and the changes from these faces say

201
00:07:10,680 --> 00:07:12,300
from left to right are actually quite

202
00:07:12,300 --> 00:07:14,730
smooth the model has dreamt up all of

203
00:07:14,730 --> 00:07:16,440
those faces in the middle yet to my eye

204
00:07:16,440 --> 00:07:19,020
they really do kind of fill the space of

205
00:07:19,020 --> 00:07:23,700
possible drawings finally as I pointed

206
00:07:23,700 --> 00:07:25,830
out with the cat whiskers these models

207
00:07:25,830 --> 00:07:28,080
generalize not memorize it's not that

208
00:07:28,080 --> 00:07:29,580
interesting to memorize a drawing it's

209
00:07:29,580 --> 00:07:31,050
much more interesting to learn general

210
00:07:31,050 --> 00:07:33,090
strategies for drawing and so we see

211
00:07:33,090 --> 00:07:34,830
that with the five to six wizard cat I

212
00:07:34,830 --> 00:07:36,510
think more interestingly and I think

213
00:07:36,510 --> 00:07:38,550
it's also suggestive we also see this

214
00:07:38,550 --> 00:07:40,530
with doing something like taking a model

215
00:07:40,530 --> 00:07:43,020
that's only seen pigs and giving it a

216
00:07:43,020 --> 00:07:45,300
picture of a truck and what's that model

217
00:07:45,300 --> 00:07:48,210
going to do it's going to find a pig

218
00:07:48,210 --> 00:07:49,770
truck because that's all it knows about

219
00:07:49,770 --> 00:07:51,990
right and if that seems silly which I

220
00:07:51,990 --> 00:07:54,450
grant it is in your own mind think about

221
00:07:54,450 --> 00:07:56,940
how how hard it would be at least for me

222
00:07:56,940 --> 00:07:58,740
if someone says draw a truck that looks

223
00:07:58,740 --> 00:08:00,419
like a pig it's actually kind of hard to

224
00:08:00,419 --> 00:08:02,370
make that transformation and these

225
00:08:02,370 --> 00:08:07,650
models do it finally by the way they

226
00:08:07,650 --> 00:08:10,440
they I get paid to do this I just want

227
00:08:10,440 --> 00:08:13,380
to point that out as an aside so it's

228
00:08:13,380 --> 00:08:14,490
kind of nice I said that last year it's

229
00:08:14,490 --> 00:08:16,980
still true okay so these late and spaced

230
00:08:16,980 --> 00:08:18,360
analogies another example of what's

231
00:08:18,360 --> 00:08:19,710
happening in these Leighton spaces

232
00:08:19,710 --> 00:08:21,840
obviously if you add and subtract pen

233
00:08:21,840 --> 00:08:24,000
strokes you're not going to get far with

234
00:08:24,000 --> 00:08:25,470
making something that's that's

235
00:08:25,470 --> 00:08:27,600
recognizable but if you have a look at

236
00:08:27,600 --> 00:08:28,139
the

237
00:08:28,139 --> 00:08:29,580
these latent spaced analogies we take

238
00:08:29,580 --> 00:08:32,820
the latent vector for a cat head and we

239
00:08:32,820 --> 00:08:34,979
add a pig body and we subtract the pig

240
00:08:34,979 --> 00:08:37,649
head and of course it stands to reason

241
00:08:37,649 --> 00:08:39,779
that you should get a cat body and we

242
00:08:39,779 --> 00:08:40,950
can do the same thing in Reverse and

243
00:08:40,950 --> 00:08:42,450
this is real data this actually works

244
00:08:42,450 --> 00:08:43,950
and the reason I mentioned it is it

245
00:08:43,950 --> 00:08:45,839
shows that these latent space models are

246
00:08:45,839 --> 00:08:48,240
learning some of the geometric relations

247
00:08:48,240 --> 00:08:52,920
between the forms that people draw I'm

248
00:08:52,920 --> 00:08:55,160
gonna switch gears now and move from

249
00:08:55,160 --> 00:08:58,170
drawing to music and talk a little bit

250
00:08:58,170 --> 00:09:00,000
about a model called n sense which is a

251
00:09:00,000 --> 00:09:01,890
neural network synthesizer that takes

252
00:09:01,890 --> 00:09:03,630
audio and learns to generalize in the

253
00:09:03,630 --> 00:09:07,290
space of music you may have seen from

254
00:09:07,290 --> 00:09:11,040
the beginning of I Oh with bathing that

255
00:09:11,040 --> 00:09:12,600
this has been put into a hardware unit

256
00:09:12,600 --> 00:09:13,860
called instant super how many people

257
00:09:13,860 --> 00:09:15,779
have heard of Henson super how many

258
00:09:15,779 --> 00:09:18,899
people want an instant super good ok

259
00:09:18,899 --> 00:09:21,390
well that's possible as you know ok so I

260
00:09:21,390 --> 00:09:22,589
want to for those of you that didn't see

261
00:09:22,589 --> 00:09:24,269
the opening I have a short version of

262
00:09:24,269 --> 00:09:26,070
the making of the instant super I like

263
00:09:26,070 --> 00:09:27,240
to roll that now to give you guys a

264
00:09:27,240 --> 00:09:28,970
better idea of what this model is up to

265
00:09:28,970 --> 00:09:50,220
let's let's roll it now I just feel like

266
00:09:50,220 --> 00:09:52,140
we're turning a corner and what could be

267
00:09:52,140 --> 00:09:55,300
new possibilities

268
00:09:55,300 --> 00:09:57,710
it could generate a sound that might

269
00:09:57,710 --> 00:10:02,780
inspire resume the fun part is like even

270
00:10:02,780 --> 00:10:03,860
though you think you know what you're

271
00:10:03,860 --> 00:10:05,090
doing there's some weird interaction

272
00:10:05,090 --> 00:10:07,310
happening that can give you something

273
00:10:07,310 --> 00:10:11,600
totally unexpected why wait why did that

274
00:10:11,600 --> 00:10:18,800
happen that way okay so what you see

275
00:10:18,800 --> 00:10:20,660
here by the way the last person with the

276
00:10:20,660 --> 00:10:22,220
long hair was Jesse Engel who was the

277
00:10:22,220 --> 00:10:23,600
the main scientist on the instance

278
00:10:23,600 --> 00:10:25,850
project this grid that you're seeing

279
00:10:25,850 --> 00:10:28,670
this square where you can move around

280
00:10:28,670 --> 00:10:31,640
the space is exactly the same idea as we

281
00:10:31,640 --> 00:10:33,560
saw with those faces so the idea is that

282
00:10:33,560 --> 00:10:34,730
you're moving around the Layton space

283
00:10:34,730 --> 00:10:36,260
and you're able to discover sounds that

284
00:10:36,260 --> 00:10:37,820
hopefully have some similarity and

285
00:10:37,820 --> 00:10:40,700
because they're made up of learning what

286
00:10:40,700 --> 00:10:42,380
makes humans you know how sound works

287
00:10:42,380 --> 00:10:44,000
for us and the same way as a pig truck

288
00:10:44,000 --> 00:10:46,790
gives us maybe some new ideas about how

289
00:10:46,790 --> 00:10:52,100
sound works and as you probably know you

290
00:10:52,100 --> 00:10:53,990
can make these yourself which i think is

291
00:10:53,990 --> 00:10:56,090
my mind my favorite part about the

292
00:10:56,090 --> 00:10:58,280
instant super project is that this is an

293
00:10:58,280 --> 00:11:00,500
open-source github for those of you who

294
00:11:00,500 --> 00:11:02,270
are makers and like to tinker please

295
00:11:02,270 --> 00:11:03,950
give it a shot if not we'll see some

296
00:11:03,950 --> 00:11:06,890
coming available from tons of people who

297
00:11:06,890 --> 00:11:10,340
are building them on their own so I want

298
00:11:10,340 --> 00:11:11,510
to keep going with music but I want to

299
00:11:11,510 --> 00:11:13,700
move away from audio and I want to move

300
00:11:13,700 --> 00:11:16,730
now to musical scores you know musical

301
00:11:16,730 --> 00:11:18,740
notes something that you know think of

302
00:11:18,740 --> 00:11:20,690
last night with with justice driving a

303
00:11:20,690 --> 00:11:23,450
sequencer and talk about basically the

304
00:11:23,450 --> 00:11:25,460
same idea which is can we learn a late

305
00:11:25,460 --> 00:11:28,400
in space where we can move around what's

306
00:11:28,400 --> 00:11:31,400
possible in in in a musical note or a

307
00:11:31,400 --> 00:11:33,050
musical score rather so what you see

308
00:11:33,050 --> 00:11:37,280
here is some three-part musical thing on

309
00:11:37,280 --> 00:11:39,110
the top and some one part musical thing

310
00:11:39,110 --> 00:11:41,510
on the bottom and then finding in a

311
00:11:41,510 --> 00:11:43,090
latent space something that's in between

312
00:11:43,090 --> 00:11:44,320
okay

313
00:11:44,320 --> 00:11:49,160
and now I put the faces underneath this

314
00:11:49,160 --> 00:11:51,280
what you're looking at now is a

315
00:11:51,280 --> 00:11:53,330
representation of a musical drum score

316
00:11:53,330 --> 00:11:55,910
where time is passing left to right and

317
00:11:55,910 --> 00:11:57,410
what we're going to see is we're going

318
00:11:57,410 --> 00:11:58,850
to start I'm going to play this for you

319
00:11:58,850 --> 00:12:00,500
it's a little bit long so I want to set

320
00:12:00,500 --> 00:12:04,280
this up we're gonna start with a drum

321
00:12:04,280 --> 00:12:06,650
beat one measure of drums and we're

322
00:12:06,650 --> 00:12:07,970
going to end with one measure of drums

323
00:12:07,970 --> 00:12:08,540
and you're going to hear

324
00:12:08,540 --> 00:12:09,950
those first you're gonna hear a and B

325
00:12:09,950 --> 00:12:12,260
and then you're gonna hear this latent

326
00:12:12,260 --> 00:12:14,510
space model try to figure out how to get

327
00:12:14,510 --> 00:12:17,900
from A to B and everything in between is

328
00:12:17,900 --> 00:12:19,970
made up by the model in exactly the same

329
00:12:19,970 --> 00:12:22,460
way that the faces in the middle are

330
00:12:22,460 --> 00:12:24,080
made up by the model so as you're

331
00:12:24,080 --> 00:12:26,330
listening basically listen for whether

332
00:12:26,330 --> 00:12:28,130
it makes musical sense or not that the

333
00:12:28,130 --> 00:12:29,000
intermediate drums

334
00:12:29,000 --> 00:12:32,200
let's give it a roll

335
00:12:32,200 --> 00:13:35,639
[Music]

336
00:13:35,639 --> 00:13:43,870
so you have it moving right along

337
00:13:43,870 --> 00:13:46,649
it turns out take a look at this command

338
00:13:46,649 --> 00:13:49,660
this make sense to some of you maybe we

339
00:13:49,660 --> 00:13:51,370
were surprised to learn after a year of

340
00:13:51,370 --> 00:13:53,199
doing magenta that this is not the right

341
00:13:53,199 --> 00:13:55,389
way to work with musicians and artists I

342
00:13:55,389 --> 00:13:57,819
know I laugh too but we really thought

343
00:13:57,819 --> 00:13:59,470
hey it's a great idea guys

344
00:13:59,470 --> 00:14:01,420
it's like paste this into terminal and

345
00:14:01,420 --> 00:14:03,100
they're like what's terminal and then

346
00:14:03,100 --> 00:14:05,170
you know you're in trouble right okay so

347
00:14:05,170 --> 00:14:07,839
we've we've moved quite a bit towards

348
00:14:07,839 --> 00:14:09,819
trying to build tools that musicians can

349
00:14:09,819 --> 00:14:12,279
use this is a drum machine actually that

350
00:14:12,279 --> 00:14:14,740
you can play with online built around

351
00:14:14,740 --> 00:14:17,500
tensorflow Jas and I have a short clip

352
00:14:17,500 --> 00:14:19,329
of this being used what you're going to

353
00:14:19,329 --> 00:14:20,949
see is all the red is from you as a

354
00:14:20,949 --> 00:14:22,660
musician you can play around with it and

355
00:14:22,660 --> 00:14:23,889
then the blue is generated by the model

356
00:14:23,889 --> 00:14:25,060
so let's give this a roll this one's

357
00:14:25,060 --> 00:14:28,620
quite a bit shorter

358
00:14:28,620 --> 00:14:49,410
[Music]

359
00:14:49,410 --> 00:14:53,470
so this is available for you as a code

360
00:14:53,470 --> 00:14:55,839
pen which allows you to play around at

361
00:14:55,839 --> 00:14:57,850
the HTML and the CSS and the JavaScript

362
00:14:57,850 --> 00:15:02,050
and really amazing a huge shout out to

363
00:15:02,050 --> 00:15:05,140
taro par vienen who who did this he

364
00:15:05,140 --> 00:15:06,910
grabbed one of our trained magenta

365
00:15:06,910 --> 00:15:10,210
models and he used tensorflow Jas and he

366
00:15:10,210 --> 00:15:11,410
hacked a bunch of code to make it work

367
00:15:11,410 --> 00:15:12,910
and he put it out on Twitter and we had

368
00:15:12,910 --> 00:15:15,610
no idea this was happening and then we

369
00:15:15,610 --> 00:15:16,660
reached out to him I reached out to my

370
00:15:16,660 --> 00:15:17,980
Twitter I said taro you're my hero this

371
00:15:17,980 --> 00:15:19,300
is awesome and he's like oh you guys

372
00:15:19,300 --> 00:15:20,710
care about this my King of course we

373
00:15:20,710 --> 00:15:21,970
care about this this is our dream to

374
00:15:21,970 --> 00:15:23,440
have people not just us playing with

375
00:15:23,440 --> 00:15:25,120
this technology so I love it that we've

376
00:15:25,120 --> 00:15:29,110
gotten there so part of what I want to

377
00:15:29,110 --> 00:15:30,310
talk about today actually close with

378
00:15:30,310 --> 00:15:32,440
we've cleaned up a lot of the code in

379
00:15:32,440 --> 00:15:34,390
fact taro helped and we've now were able

380
00:15:34,390 --> 00:15:36,730
to introduce magenta that Jas which is

381
00:15:36,730 --> 00:15:38,920
very tightly integrated with tensorflow

382
00:15:38,920 --> 00:15:41,230
Jas and it allows you for example to

383
00:15:41,230 --> 00:15:43,570
grab a check pointed model and set up a

384
00:15:43,570 --> 00:15:45,339
player and start sampling from it so in

385
00:15:45,339 --> 00:15:46,570
three lines of code you can set up a

386
00:15:46,570 --> 00:15:48,100
little drum machine or music sequencer

387
00:15:48,100 --> 00:15:49,810
and we're also doing the same thing with

388
00:15:49,810 --> 00:15:51,370
sketch RNN so we have the art side as

389
00:15:51,370 --> 00:15:56,050
well and we've seen a lot of demos

390
00:15:56,050 --> 00:15:57,190
driven by this a lot of really

391
00:15:57,190 --> 00:15:58,930
interesting work both by Googlers and by

392
00:15:58,930 --> 00:16:02,350
people from the outside and I think it

393
00:16:02,350 --> 00:16:03,730
highly aligns well with what we're doing

394
00:16:03,730 --> 00:16:06,160
in magenta so to close we're doing

395
00:16:06,160 --> 00:16:07,750
research and generative models we're

396
00:16:07,750 --> 00:16:09,250
working to engage with musicians and

397
00:16:09,250 --> 00:16:11,290
artists very happy to see that

398
00:16:11,290 --> 00:16:12,790
JavaScript stuff come along which is

399
00:16:12,790 --> 00:16:14,640
really seems to be the language for that

400
00:16:14,640 --> 00:16:16,810
hoping to see better tools come and

401
00:16:16,810 --> 00:16:18,070
heavy engagement with the open-source

402
00:16:18,070 --> 00:16:20,140
community if you want to learn more

403
00:16:20,140 --> 00:16:23,290
please visit GG echo slash magenta also

404
00:16:23,290 --> 00:16:25,089
you can follow my Twitter account I post

405
00:16:25,089 --> 00:16:26,230
regular updates and try to be a

406
00:16:26,230 --> 00:16:28,150
connector for that so that's what I have

407
00:16:28,150 --> 00:16:29,709
for you and now I'd like to switch gears

408
00:16:29,709 --> 00:16:32,529
and go to robots very exciting with my

409
00:16:32,529 --> 00:16:34,029
colleague from Google brain vincent van

410
00:16:34,029 --> 00:16:35,420
nuke thank you very much

411
00:16:35,420 --> 00:16:41,440
[Applause]

412
00:16:41,440 --> 00:16:43,300
thanks Doug

413
00:16:43,300 --> 00:16:47,770
so my name is Benson and I lead the

414
00:16:47,770 --> 00:16:50,810
brain robotics research team the

415
00:16:50,810 --> 00:16:54,470
robotics research team at Google we when

416
00:16:54,470 --> 00:16:57,050
you think about robots you may think

417
00:16:57,050 --> 00:17:00,380
about precision and control you may

418
00:17:00,380 --> 00:17:02,600
think about robots you know live in

419
00:17:02,600 --> 00:17:05,630
factories they've got one very specific

420
00:17:05,630 --> 00:17:08,000
job to do and they gotta do it over and

421
00:17:08,000 --> 00:17:10,490
over again but as you saw in the keynote

422
00:17:10,490 --> 00:17:14,600
earlier more and more robots are about

423
00:17:14,600 --> 00:17:17,150
people right they're self-driving cars

424
00:17:17,150 --> 00:17:19,250
that are driving in our streets

425
00:17:19,250 --> 00:17:22,550
interacting with people they essentially

426
00:17:22,550 --> 00:17:24,830
now live in our world not their world

427
00:17:24,830 --> 00:17:27,500
and so they they really have to adapt

428
00:17:27,500 --> 00:17:30,620
and perceive the world around them and

429
00:17:30,620 --> 00:17:32,990
learn how to operate in this human

430
00:17:32,990 --> 00:17:36,080
centric environment right so how do we

431
00:17:36,080 --> 00:17:39,440
get robots to learn instead of having to

432
00:17:39,440 --> 00:17:42,770
program them this is what we've been

433
00:17:42,770 --> 00:17:46,970
embarking on and it turns out we can get

434
00:17:46,970 --> 00:17:50,660
robots to learn it takes a lot of robots

435
00:17:50,660 --> 00:17:55,310
it takes a lot of time and but we can

436
00:17:55,310 --> 00:18:00,620
actually improve on this if we teach

437
00:18:00,620 --> 00:18:03,740
robots how to behave collaboratively so

438
00:18:03,740 --> 00:18:06,080
this is an example of a team of robots

439
00:18:06,080 --> 00:18:09,620
that are learning together how to do a

440
00:18:09,620 --> 00:18:12,230
very simple task like grasping objects

441
00:18:12,230 --> 00:18:14,930
right at the FIR at the beginning they

442
00:18:14,930 --> 00:18:17,930
have no idea what they're doing they try

443
00:18:17,930 --> 00:18:20,030
and try and try and sometimes they will

444
00:18:20,030 --> 00:18:21,680
grasp something every time they grasp

445
00:18:21,680 --> 00:18:25,580
something we give them a reward and over

446
00:18:25,580 --> 00:18:27,680
time they get better and better at it of

447
00:18:27,680 --> 00:18:31,190
course we use deep learning for this we

448
00:18:31,190 --> 00:18:32,840
basically have a convolutional network

449
00:18:32,840 --> 00:18:35,600
that maps those images that the robots

450
00:18:35,600 --> 00:18:37,910
see of the workspace in front of them to

451
00:18:37,910 --> 00:18:40,490
actions and possible actions and this

452
00:18:40,490 --> 00:18:43,130
collective learning of robots enables us

453
00:18:43,130 --> 00:18:45,860
to get to levels of performance that we

454
00:18:45,860 --> 00:18:48,140
haven't seen before but it takes a lot

455
00:18:48,140 --> 00:18:49,700
of robots

456
00:18:49,700 --> 00:18:52,670
in fact you know this is Google we would

457
00:18:52,670 --> 00:18:55,220
much rather use lots of computers if we

458
00:18:55,220 --> 00:18:57,710
could instead of lots of robots and so

459
00:18:57,710 --> 00:18:59,840
the question becomes could we actually

460
00:18:59,840 --> 00:19:03,110
use a lot of simulated robots virtual

461
00:19:03,110 --> 00:19:06,110
robots to do this kind of tasks and

462
00:19:06,110 --> 00:19:09,340
teach those robots to perform tasks and

463
00:19:09,340 --> 00:19:11,600
would it actually matter in the real

464
00:19:11,600 --> 00:19:14,000
world would they what they learn in

465
00:19:14,000 --> 00:19:17,630
simulation actually apply to real tasks

466
00:19:17,630 --> 00:19:20,870
and and it turns out the key to making

467
00:19:20,870 --> 00:19:24,200
this work is to learn simulations that

468
00:19:24,200 --> 00:19:27,320
are more and more faithful to reality so

469
00:19:27,320 --> 00:19:30,290
on the right here you see what a typical

470
00:19:30,290 --> 00:19:32,300
simulation of a robot would look like

471
00:19:32,300 --> 00:19:34,730
this is a virtual robot trying to grasp

472
00:19:34,730 --> 00:19:38,840
objects and simulation what you see on

473
00:19:38,840 --> 00:19:41,720
the other side here may look like a real

474
00:19:41,720 --> 00:19:44,090
robots doing the same task but in fact

475
00:19:44,090 --> 00:19:47,210
it is completely simulated as well we've

476
00:19:47,210 --> 00:19:50,450
learned a machine learning model that

477
00:19:50,450 --> 00:19:50,930
map's

478
00:19:50,930 --> 00:19:54,950
those simulated images to real images to

479
00:19:54,950 --> 00:19:56,240
real looking images there are

480
00:19:56,240 --> 00:19:58,130
essentially indistinguishable from what

481
00:19:58,130 --> 00:20:00,920
a real robot would see in the real world

482
00:20:00,920 --> 00:20:03,200
and by using this kind of data in a

483
00:20:03,200 --> 00:20:04,790
simulated environment and training a

484
00:20:04,790 --> 00:20:08,210
simulated model to accomplish tasks

485
00:20:08,210 --> 00:20:10,220
using those images we can actually

486
00:20:10,220 --> 00:20:11,660
transfer that information and make it

487
00:20:11,660 --> 00:20:14,360
work in the real world as well so

488
00:20:14,360 --> 00:20:16,690
there's lots of things we can do with

489
00:20:16,690 --> 00:20:20,600
these kinds of simulated robots this is

490
00:20:20,600 --> 00:20:23,180
Rainbow Dash our favorite little pony

491
00:20:23,180 --> 00:20:27,590
and what you see here here is him taking

492
00:20:27,590 --> 00:20:31,010
his very first steps and our very first

493
00:20:31,010 --> 00:20:34,370
hops I should say he's really good for

494
00:20:34,370 --> 00:20:36,290
somebody who's just starting to learn

495
00:20:36,290 --> 00:20:38,450
how to walk and the way we accomplish

496
00:20:38,450 --> 00:20:42,110
this is by having a virtual Rainbow Dash

497
00:20:42,110 --> 00:20:45,440
running in simulation we train it using

498
00:20:45,440 --> 00:20:48,050
deep reinforcement learning to run

499
00:20:48,050 --> 00:20:49,970
around in the simulator and then we can

500
00:20:49,970 --> 00:20:52,700
only basically download the model that

501
00:20:52,700 --> 00:20:54,590
we've learned the simulation on to the

502
00:20:54,590 --> 00:20:57,080
real robots and actually make it work in

503
00:20:57,080 --> 00:21:00,950
the real world as well

504
00:21:00,950 --> 00:21:04,200
there are many ways we can scale up

505
00:21:04,200 --> 00:21:06,870
robotics and robotic learning in this

506
00:21:06,870 --> 00:21:09,870
way one of the key ingredients turns out

507
00:21:09,870 --> 00:21:12,270
to be learning by itself self

508
00:21:12,270 --> 00:21:15,000
supervision self learning this is an

509
00:21:15,000 --> 00:21:17,610
example of for example what you see at

510
00:21:17,610 --> 00:21:19,320
the top here is somebody driving a car

511
00:21:19,320 --> 00:21:23,880
and what we're trying to learn in this

512
00:21:23,880 --> 00:21:26,610
instance is the 3d structure of the

513
00:21:26,610 --> 00:21:29,820
world the geometry of everything what

514
00:21:29,820 --> 00:21:32,790
you see at the bottom here is a

515
00:21:32,790 --> 00:21:35,310
representation of how far things are

516
00:21:35,310 --> 00:21:37,680
from the car right you probably are

517
00:21:37,680 --> 00:21:40,080
looking at avoiding obstacles and

518
00:21:40,080 --> 00:21:44,460
looking at other cars to not collide

519
00:21:44,460 --> 00:21:46,740
with them and so you want to learn about

520
00:21:46,740 --> 00:21:48,900
the 3d geometry based on those videos

521
00:21:48,900 --> 00:21:51,000
the traditional way that you would do

522
00:21:51,000 --> 00:21:54,630
this is by involving for example a 3d

523
00:21:54,630 --> 00:21:57,030
camera or a lighter or something that

524
00:21:57,030 --> 00:22:00,120
gives you a sense of depth here we're

525
00:22:00,120 --> 00:22:02,010
going to do none of that we're going to

526
00:22:02,010 --> 00:22:04,920
simply look at the video and learn

527
00:22:04,920 --> 00:22:07,770
directly from the video the 3d structure

528
00:22:07,770 --> 00:22:10,580
of the world and the way to do this is

529
00:22:10,580 --> 00:22:13,620
to look at the video and try to predict

530
00:22:13,620 --> 00:22:16,830
the future of this video you can imagine

531
00:22:16,830 --> 00:22:19,980
that if you actually understand the 3d

532
00:22:19,980 --> 00:22:22,530
geometry of the world you can do a

533
00:22:22,530 --> 00:22:24,240
pretty good job at predicting what's

534
00:22:24,240 --> 00:22:26,700
going to happen next in a video so we're

535
00:22:26,700 --> 00:22:28,710
going to use that signal that tells us

536
00:22:28,710 --> 00:22:30,390
how well we're doing at predicting the

537
00:22:30,390 --> 00:22:34,080
future to learn what the 3d geometry of

538
00:22:34,080 --> 00:22:36,390
the world looks like so at the end of

539
00:22:36,390 --> 00:22:38,250
the day what we end up with is yet

540
00:22:38,250 --> 00:22:40,290
another big convolutional network that

541
00:22:40,290 --> 00:22:42,390
map's what you see at the top to what

542
00:22:42,390 --> 00:22:44,670
you see at the bottom without involving

543
00:22:44,670 --> 00:22:49,080
any 3d camera or anything like that this

544
00:22:49,080 --> 00:22:51,960
idea of self learning or just learning

545
00:22:51,960 --> 00:22:53,760
without any supervision directly from

546
00:22:53,760 --> 00:22:55,940
the data is really really powerful

547
00:22:55,940 --> 00:22:58,500
another problem that we have when we're

548
00:22:58,500 --> 00:23:01,020
trying to teach robots how to do things

549
00:23:01,020 --> 00:23:03,720
is that we have to communicate to them

550
00:23:03,720 --> 00:23:06,540
what we want what we care about right

551
00:23:06,540 --> 00:23:09,900
and the best way you can do that is by

552
00:23:09,900 --> 00:23:12,000
simply showing them what you want them

553
00:23:12,000 --> 00:23:14,070
to perform so here is an example

554
00:23:14,070 --> 00:23:16,050
one of my colleagues basically doing the

555
00:23:16,050 --> 00:23:19,530
robot dance and robots that is just

556
00:23:19,530 --> 00:23:23,040
looking at him performing those tasks

557
00:23:23,040 --> 00:23:26,340
and trying to imitate visually what he

558
00:23:26,340 --> 00:23:28,530
is doing and what's remarkable here is

559
00:23:28,530 --> 00:23:30,060
that you know even though the robot for

560
00:23:30,060 --> 00:23:32,580
example doesn't have legs it tries to do

561
00:23:32,580 --> 00:23:35,220
this crouching motion as best it can

562
00:23:35,220 --> 00:23:36,990
given the agrees of freedom that it has

563
00:23:36,990 --> 00:23:39,660
available and all of this is learn

564
00:23:39,660 --> 00:23:43,350
entirely self supervise the way we go

565
00:23:43,350 --> 00:23:46,650
about this is that if you think about

566
00:23:46,650 --> 00:23:49,620
imitating somebody else for example

567
00:23:49,620 --> 00:23:52,710
somebody pouring a glass of water or

568
00:23:52,710 --> 00:23:56,970
kind of coke and it all relies on you

569
00:23:56,970 --> 00:24:00,450
being able to look at them from a third

570
00:24:00,450 --> 00:24:03,540
party view and picturing yourself doing

571
00:24:03,540 --> 00:24:05,940
the same thing from your point of view

572
00:24:05,940 --> 00:24:08,610
what it would look like if you did the

573
00:24:08,610 --> 00:24:11,220
same thing yourself right so we

574
00:24:11,220 --> 00:24:13,440
collected some of this data that looks

575
00:24:13,440 --> 00:24:14,970
like that where you have somebody

576
00:24:14,970 --> 00:24:16,560
looking at somebody else to do a task

577
00:24:16,560 --> 00:24:19,640
and you end up with those two videos of

578
00:24:19,640 --> 00:24:22,650
one taken by the person doing the task

579
00:24:22,650 --> 00:24:24,030
and I know the one taken by another

580
00:24:24,030 --> 00:24:25,980
person and what we want to teach the

581
00:24:25,980 --> 00:24:28,260
robots is that those two things are

582
00:24:28,260 --> 00:24:32,400
actually the same thing so we're going

583
00:24:32,400 --> 00:24:35,430
to use again machine learning to perform

584
00:24:35,430 --> 00:24:37,860
this match up we're gonna have a machine

585
00:24:37,860 --> 00:24:39,180
learning model that is going to tell us

586
00:24:39,180 --> 00:24:42,000
okay this image on the left is actually

587
00:24:42,000 --> 00:24:44,340
of the same task as this image on the

588
00:24:44,340 --> 00:24:46,530
right and once we've learned that

589
00:24:46,530 --> 00:24:48,600
correspondence with lots of things we

590
00:24:48,600 --> 00:24:50,670
can do with this one of them is just

591
00:24:50,670 --> 00:24:53,250
imitation like this imagine you have

592
00:24:53,250 --> 00:24:56,520
somebody pouring a glass of water the

593
00:24:56,520 --> 00:24:59,130
robot sees them they try to picture

594
00:24:59,130 --> 00:25:02,430
themselves doing the same task and try

595
00:25:02,430 --> 00:25:04,200
best they can to imitate what they're

596
00:25:04,200 --> 00:25:07,020
doing and so using again deep

597
00:25:07,020 --> 00:25:08,970
reinforcement learning we can train

598
00:25:08,970 --> 00:25:11,700
robots to learn those kinds of

599
00:25:11,700 --> 00:25:15,300
activities completely based on visual

600
00:25:15,300 --> 00:25:17,250
observation without any programming of

601
00:25:17,250 --> 00:25:20,190
any kind so I won't let that robot for

602
00:25:20,190 --> 00:25:22,320
me appear quite yet but it's very

603
00:25:22,320 --> 00:25:24,510
encouraging that we can just look have

604
00:25:24,510 --> 00:25:26,790
robots that understand essentially what

605
00:25:26,790 --> 00:25:27,280
the name

606
00:25:27,280 --> 00:25:30,340
sure what the fundamentals of the task

607
00:25:30,340 --> 00:25:33,490
is regardless of whether they're pouring

608
00:25:33,490 --> 00:25:35,830
a liquid or they're pouring beads or

609
00:25:35,830 --> 00:25:39,670
whatever the glasses look like or the

610
00:25:39,670 --> 00:25:42,100
containers all of that is abstracted and

611
00:25:42,100 --> 00:25:43,480
the robot actually really understand

612
00:25:43,480 --> 00:25:47,740
deeply what the task is about so I'm

613
00:25:47,740 --> 00:25:49,300
very excited about this whole

614
00:25:49,300 --> 00:25:52,510
perspective on teaching robots how to

615
00:25:52,510 --> 00:25:54,760
learn instead of having to program them

616
00:25:54,760 --> 00:25:57,670
right at some point I would want to be

617
00:25:57,670 --> 00:26:00,520
able to tell my google assistant hey ok

618
00:26:00,520 --> 00:26:01,060
Google

619
00:26:01,060 --> 00:26:04,990
please go for my laundry right and for

620
00:26:04,990 --> 00:26:06,600
that to happen we're gonna have to

621
00:26:06,600 --> 00:26:09,700
rebuild the science of Robotics from the

622
00:26:09,700 --> 00:26:13,750
ground up you're going to have to base

623
00:26:13,750 --> 00:26:16,120
it on understanding and machine learning

624
00:26:16,120 --> 00:26:20,080
and perception and of course we're going

625
00:26:20,080 --> 00:26:23,830
to have to do that at Google scale with

626
00:26:23,830 --> 00:26:25,780
that I'm going to give the stage to

627
00:26:25,780 --> 00:26:28,330
Debbie who's going to talk to us about

628
00:26:28,330 --> 00:26:30,180
cosmology thank you

629
00:26:30,180 --> 00:26:34,660
[Applause]

630
00:26:34,660 --> 00:26:41,410
thank you good afternoon everyone my

631
00:26:41,410 --> 00:26:43,420
name is Debbie Bart I'm we're talking

632
00:26:43,420 --> 00:26:44,740
about something a little bit different

633
00:26:44,740 --> 00:26:48,160
from what you've heard so far so I lead

634
00:26:48,160 --> 00:26:49,960
the data science engagement group at

635
00:26:49,960 --> 00:26:52,480
nurse a nurse is the national energy

636
00:26:52,480 --> 00:26:54,370
research scientific computing Center

637
00:26:54,370 --> 00:26:56,610
we're a supercomputing Center at

638
00:26:56,610 --> 00:26:59,140
Lawrence Berkeley National Lab just over

639
00:26:59,140 --> 00:27:02,230
the bay from here we are the mission

640
00:27:02,230 --> 00:27:04,210
computing Center for the Department of

641
00:27:04,210 --> 00:27:05,890
Energy Office of Science and what this

642
00:27:05,890 --> 00:27:07,050
means is that we have something like

643
00:27:07,050 --> 00:27:09,730
7,000 scientists are using our

644
00:27:09,730 --> 00:27:11,350
supercomputers to work on some of the

645
00:27:11,350 --> 00:27:14,110
biggest questions in science today and

646
00:27:14,110 --> 00:27:16,000
what I think is really cool as well is

647
00:27:16,000 --> 00:27:17,350
that I get to work with some of the most

648
00:27:17,350 --> 00:27:20,110
powerful computers on the planet one of

649
00:27:20,110 --> 00:27:21,190
the things that we're noticing

650
00:27:21,190 --> 00:27:22,540
especially in the last couple of years

651
00:27:22,540 --> 00:27:24,670
is we've seen that scientists are

652
00:27:24,670 --> 00:27:26,320
increasingly turning to deep learning

653
00:27:26,320 --> 00:27:27,970
and machine learning methods to solve

654
00:27:27,970 --> 00:27:29,440
some of these big questions that they're

655
00:27:29,440 --> 00:27:31,240
working on I was seeing these questions

656
00:27:31,240 --> 00:27:33,430
showing up in our workload on our

657
00:27:33,430 --> 00:27:36,790
supercomputers so I want to focus on one

658
00:27:36,790 --> 00:27:39,070
particular topic area it's very close to

659
00:27:39,070 --> 00:27:42,010
my heart which is cosmology because I'm

660
00:27:42,010 --> 00:27:44,290
a cosmologists are aiming my background

661
00:27:44,290 --> 00:27:47,200
is in cosmology research because I've

662
00:27:47,200 --> 00:27:48,850
always been interested in the really the

663
00:27:48,850 --> 00:27:50,710
most fundamental questions that we have

664
00:27:50,710 --> 00:27:52,990
in science about the nature of the

665
00:27:52,990 --> 00:27:54,960
universe and perhaps one of the most

666
00:27:54,960 --> 00:27:57,310
basic questions you can ask about the

667
00:27:57,310 --> 00:28:00,430
universe is what is it made of and these

668
00:28:00,430 --> 00:28:04,170
days we have a fairly good feel for how

669
00:28:04,170 --> 00:28:06,490
much dark energy there is in the

670
00:28:06,490 --> 00:28:08,410
universe how much dark matter how much

671
00:28:08,410 --> 00:28:09,940
regular matter there is in the universe

672
00:28:09,940 --> 00:28:12,310
and there's only about 5% of regular

673
00:28:12,310 --> 00:28:14,650
matter which is everything that you and

674
00:28:14,650 --> 00:28:16,420
I and all the stars and all the dust and

675
00:28:16,420 --> 00:28:17,770
all the gas and all the galaxies out

676
00:28:17,770 --> 00:28:19,270
there they're made of regular matter and

677
00:28:19,270 --> 00:28:21,160
that makes up a pretty tiny proportion

678
00:28:21,160 --> 00:28:23,740
of the contents of the universe the

679
00:28:23,740 --> 00:28:25,300
thing that I find really interesting is

680
00:28:25,300 --> 00:28:28,570
we don't just don't know what the rest

681
00:28:28,570 --> 00:28:32,140
of it is dark matter we don't know what

682
00:28:32,140 --> 00:28:34,150
that's made of but we see indirectly the

683
00:28:34,150 --> 00:28:36,640
gravitational effect it has dark energy

684
00:28:36,640 --> 00:28:38,260
we don't know what that is at all that

685
00:28:38,260 --> 00:28:40,180
was only recently discovered about 15

686
00:28:40,180 --> 00:28:42,760
years ago and dark energy just the name

687
00:28:42,760 --> 00:28:44,800
that we give to an observation

688
00:28:44,800 --> 00:28:46,750
which is the accelerated expansion of

689
00:28:46,750 --> 00:28:50,080
the universe and this is I think really

690
00:28:50,080 --> 00:28:53,050
exciting the fact that there is so much

691
00:28:53,050 --> 00:28:54,850
that we have yet to discover means that

692
00:28:54,850 --> 00:28:56,530
there are tremendous possibilities for

693
00:28:56,530 --> 00:28:59,170
new ways for us to understand our

694
00:28:59,170 --> 00:29:02,770
universe and we are building a bigger

695
00:29:02,770 --> 00:29:04,360
and better telescopes we're collecting

696
00:29:04,360 --> 00:29:06,940
data all the time and taking images and

697
00:29:06,940 --> 00:29:09,820
observations of the sky to get more data

698
00:29:09,820 --> 00:29:12,760
to help us understand this because we

699
00:29:12,760 --> 00:29:14,830
only have one universe to observe so we

700
00:29:14,830 --> 00:29:16,060
need to be able to collect as much data

701
00:29:16,060 --> 00:29:18,520
as we can on that universe and we need

702
00:29:18,520 --> 00:29:20,230
to be able to extract all the

703
00:29:20,230 --> 00:29:23,050
information we can from our data from

704
00:29:23,050 --> 00:29:25,630
our observations and cosmologists are

705
00:29:25,630 --> 00:29:28,180
increasingly turning to deep learning to

706
00:29:28,180 --> 00:29:30,250
extract meaning from our data and I'm

707
00:29:30,250 --> 00:29:31,180
going to talk about a couple of

708
00:29:31,180 --> 00:29:33,340
different ways that we're doing that but

709
00:29:33,340 --> 00:29:34,600
first of all I want to kind of ground

710
00:29:34,600 --> 00:29:35,950
this in the background of how we

711
00:29:35,950 --> 00:29:40,420
actually do experiments in cosmology

712
00:29:40,420 --> 00:29:42,100
because it's cosmology is not an

713
00:29:42,100 --> 00:29:44,140
experimental science in the way that

714
00:29:44,140 --> 00:29:46,030
many other physical sciences are so it's

715
00:29:46,030 --> 00:29:48,280
not a lot we can do to experiment with

716
00:29:48,280 --> 00:29:50,230
the universe we can't really do much to

717
00:29:50,230 --> 00:29:52,420
change the nature of space-time although

718
00:29:52,420 --> 00:29:54,790
it would be fun if we could but instead

719
00:29:54,790 --> 00:29:57,160
we have to run simulations so we run

720
00:29:57,160 --> 00:29:59,860
simulations in supercomputers of

721
00:29:59,860 --> 00:30:02,950
theoretical universes and the different

722
00:30:02,950 --> 00:30:04,270
physical models and the different

723
00:30:04,270 --> 00:30:06,430
parameters that control those physical

724
00:30:06,430 --> 00:30:08,260
models and that's how we experiment we

725
00:30:08,260 --> 00:30:10,270
run these simulated universes and then

726
00:30:10,270 --> 00:30:11,560
we compare the outputs of these

727
00:30:11,560 --> 00:30:13,900
simulations to our observations of the

728
00:30:13,900 --> 00:30:16,810
real universe around us so when we make

729
00:30:16,810 --> 00:30:18,600
this comparison we're typically using

730
00:30:18,600 --> 00:30:21,130
some statistical measure some kind of

731
00:30:21,130 --> 00:30:22,690
reduced statistic like the power

732
00:30:22,690 --> 00:30:25,570
spectrum which is illustrating this

733
00:30:25,570 --> 00:30:29,400
animation here the power spectrum is a

734
00:30:29,400 --> 00:30:32,200
measure of how matter is distributed

735
00:30:32,200 --> 00:30:33,730
throughout the universe whether it's

736
00:30:33,730 --> 00:30:35,230
kind of distributed fairly evenly

737
00:30:35,230 --> 00:30:36,820
throughout space or whether it's

738
00:30:36,820 --> 00:30:39,520
clustered on small scales and this is

739
00:30:39,520 --> 00:30:43,120
illustrated in this the images on the

740
00:30:43,120 --> 00:30:44,920
top of the slide here which is snapshots

741
00:30:44,920 --> 00:30:48,210
of a simulated universe run in a

742
00:30:48,210 --> 00:30:51,880
supercomputer and you can see that over

743
00:30:51,880 --> 00:30:54,760
time gravity is pulling matter together

744
00:30:54,760 --> 00:30:56,710
and so thats dark matter and regular

745
00:30:56,710 --> 00:30:57,330
matter

746
00:30:57,330 --> 00:30:59,070
he's acting upon that collapsing the

747
00:30:59,070 --> 00:31:01,830
matter into these very typical cluster

748
00:31:01,830 --> 00:31:03,869
and filamentary type structures whereas

749
00:31:03,869 --> 00:31:05,999
dark energy is expanding space itself

750
00:31:05,999 --> 00:31:08,279
expanding the volume of the this a

751
00:31:08,279 --> 00:31:11,639
miniature universe and so by looking at

752
00:31:11,639 --> 00:31:13,649
the distribution of matter and we can

753
00:31:13,649 --> 00:31:15,090
start to learn something about the

754
00:31:15,090 --> 00:31:17,730
nature of the matter itself how gravity

755
00:31:17,730 --> 00:31:20,129
is acting on that and what dark energy

756
00:31:20,129 --> 00:31:23,669
is doing but as you can imagine running

757
00:31:23,669 --> 00:31:25,649
these kinds of simulations is very

758
00:31:25,649 --> 00:31:27,330
computationally expensive even if you're

759
00:31:27,330 --> 00:31:29,609
only simulating a tiny universe it still

760
00:31:29,609 --> 00:31:31,289
requires a tremendous amount of compute

761
00:31:31,289 --> 00:31:35,340
power and we spend billions of computer

762
00:31:35,340 --> 00:31:37,169
hours on supercomputers around the world

763
00:31:37,169 --> 00:31:39,749
on these kinds of simulations including

764
00:31:39,749 --> 00:31:42,419
the supercomputers that I work with and

765
00:31:42,419 --> 00:31:44,399
one of the ways that we're using deep

766
00:31:44,399 --> 00:31:49,230
learning is to reduce the need for such

767
00:31:49,230 --> 00:31:51,929
expensive simulations similar to the

768
00:31:51,929 --> 00:31:53,039
previous speaker was talking about

769
00:31:53,039 --> 00:31:54,690
Vincent's walking bout with robotics

770
00:31:54,690 --> 00:31:57,629
we're exploring using generative

771
00:31:57,629 --> 00:32:01,320
networks to produce in this case this

772
00:32:01,320 --> 00:32:03,539
example two dimensional maps of the

773
00:32:03,539 --> 00:32:05,999
universe so these are two dimensional

774
00:32:05,999 --> 00:32:07,590
maps of the mass concentration of the

775
00:32:07,590 --> 00:32:08,879
universe so you can imagine the

776
00:32:08,879 --> 00:32:11,369
three-dimensional volume collapsed into

777
00:32:11,369 --> 00:32:14,009
a two dimensional projection of the mass

778
00:32:14,009 --> 00:32:16,200
density in the universe as you're

779
00:32:16,200 --> 00:32:19,100
looking out at the sky and we use again

780
00:32:19,100 --> 00:32:22,350
which is based on a fairly standard DC

781
00:32:22,350 --> 00:32:26,190
gaen topology to produce new maps of

782
00:32:26,190 --> 00:32:29,549
these new mass maps based on simulations

783
00:32:29,549 --> 00:32:32,309
so this is an augmentation we're using

784
00:32:32,309 --> 00:32:35,340
this network to augment an existing

785
00:32:35,340 --> 00:32:38,309
simulation to produce new maps and we

786
00:32:38,309 --> 00:32:40,080
see that it's doing a pretty good job so

787
00:32:40,080 --> 00:32:42,330
just by looking by eye at the generated

788
00:32:42,330 --> 00:32:44,190
images they look pretty similar to the

789
00:32:44,190 --> 00:32:46,109
real input images the real simulated

790
00:32:46,109 --> 00:32:48,960
images but as a scientist kind of

791
00:32:48,960 --> 00:32:50,429
squinting at something and saying oh

792
00:32:50,429 --> 00:32:51,989
yeah that looks about right is not good

793
00:32:51,989 --> 00:32:55,289
enough and what I want is to be able to

794
00:32:55,289 --> 00:32:57,090
quantify this to be able to quantify how

795
00:32:57,090 --> 00:32:59,509
our network is working and quantify how

796
00:32:59,509 --> 00:33:02,700
like the real images our generated

797
00:33:02,700 --> 00:33:04,259
images are and this is I think where

798
00:33:04,259 --> 00:33:05,970
scientific data has a real advantage

799
00:33:05,970 --> 00:33:11,059
compared to natural image data because

800
00:33:11,059 --> 00:33:13,860
scientific data usually are very often

801
00:33:13,860 --> 00:33:16,649
has associated statistics with it so

802
00:33:16,649 --> 00:33:18,690
statistics that you can use to evaluate

803
00:33:18,690 --> 00:33:21,809
the success of your model so in this

804
00:33:21,809 --> 00:33:24,630
case we were looking at reduced

805
00:33:24,630 --> 00:33:27,330
statistics that describe the patterns in

806
00:33:27,330 --> 00:33:29,520
the the maps like the power spectra and

807
00:33:29,520 --> 00:33:31,590
other measures of the topology of the

808
00:33:31,590 --> 00:33:34,140
maps and we see that not only do the

809
00:33:34,140 --> 00:33:37,020
maps and look about right but the the

810
00:33:37,020 --> 00:33:38,610
statistics that are contained in those

811
00:33:38,610 --> 00:33:40,140
maps match those from the real

812
00:33:40,140 --> 00:33:42,539
simulations so we can quantify the

813
00:33:42,539 --> 00:33:45,419
accuracy of our network and this is

814
00:33:45,419 --> 00:33:46,620
something that potentially could be

815
00:33:46,620 --> 00:33:48,240
useful for the wider deep learning

816
00:33:48,240 --> 00:33:50,669
community I'm using scientific data that

817
00:33:50,669 --> 00:33:52,590
has these associated statistics could be

818
00:33:52,590 --> 00:33:54,270
of real interest I think to deep

819
00:33:54,270 --> 00:33:56,070
learning practitioners in trying to

820
00:33:56,070 --> 00:33:57,600
quantify how well your networks are

821
00:33:57,600 --> 00:34:00,600
working so I mentioned before that this

822
00:34:00,600 --> 00:34:02,700
is an augmentation again that we've been

823
00:34:02,700 --> 00:34:05,220
working on so far it can produce new

824
00:34:05,220 --> 00:34:07,620
maps based on a physics model that it's

825
00:34:07,620 --> 00:34:09,359
already seen and we're working at

826
00:34:09,359 --> 00:34:11,700
scaling this up and producing physics

827
00:34:11,700 --> 00:34:13,980
models that the network has never seen

828
00:34:13,980 --> 00:34:15,359
before so making this into a true

829
00:34:15,359 --> 00:34:18,599
emulator and this will help reduce the

830
00:34:18,599 --> 00:34:20,099
need for these very computationally

831
00:34:20,099 --> 00:34:21,960
expensive simulations and allow

832
00:34:21,960 --> 00:34:24,030
cosmologists to explore parameter space

833
00:34:24,030 --> 00:34:28,800
a bit more freely and I'd like to

834
00:34:28,800 --> 00:34:31,200
explore a little bit further what this

835
00:34:31,200 --> 00:34:33,210
network is actually learning I saw a

836
00:34:33,210 --> 00:34:34,560
really interesting talk this morning

837
00:34:34,560 --> 00:34:36,119
here and that was touching on this kind

838
00:34:36,119 --> 00:34:39,899
of thing how we can use machine learning

839
00:34:39,899 --> 00:34:42,510
to gain insight into the nature of the

840
00:34:42,510 --> 00:34:45,270
data that we're working with so in their

841
00:34:45,270 --> 00:34:46,800
work that I'm showing here we were

842
00:34:46,800 --> 00:34:49,050
looking at which structures in our mass

843
00:34:49,050 --> 00:34:50,940
maps are contributing to the model and

844
00:34:50,940 --> 00:34:52,440
most strongly contributing to the model

845
00:34:52,440 --> 00:34:54,899
by looking at a quantity called salience

846
00:34:54,899 --> 00:34:58,349
II and so by if you look at the map of

847
00:34:58,349 --> 00:34:59,550
saying it C which is the black and white

848
00:34:59,550 --> 00:35:01,560
image here you can see that the peaks in

849
00:35:01,560 --> 00:35:03,480
the salient C map corresponds to peaks

850
00:35:03,480 --> 00:35:06,450
in the mass map and so these peaks and

851
00:35:06,450 --> 00:35:08,220
amass mady's are concentrations of

852
00:35:08,220 --> 00:35:10,230
matter and these corresponds to galaxy

853
00:35:10,230 --> 00:35:12,540
clusters typically in the real universe

854
00:35:12,540 --> 00:35:15,270
and this isn't news to cosmologists and

855
00:35:15,270 --> 00:35:17,940
we've known for decades that galaxy

856
00:35:17,940 --> 00:35:19,640
clusters are a really good way of

857
00:35:19,640 --> 00:35:21,940
exploring cosmology

858
00:35:21,940 --> 00:35:24,339
but the shapes of the features that this

859
00:35:24,339 --> 00:35:26,349
network have learns are not you know

860
00:35:26,349 --> 00:35:28,510
nice round Gaussian balls they are

861
00:35:28,510 --> 00:35:30,460
irregular and they're showing some

862
00:35:30,460 --> 00:35:31,569
structure and this is something that's

863
00:35:31,569 --> 00:35:33,369
really interesting to me and there's

864
00:35:33,369 --> 00:35:35,349
also indications that some of the

865
00:35:35,349 --> 00:35:37,270
smaller mass concentrations are showing

866
00:35:37,270 --> 00:35:39,130
off as important features in this

867
00:35:39,130 --> 00:35:40,750
network and that's perhaps a little bit

868
00:35:40,750 --> 00:35:44,710
unexpected so by taking this kind of

869
00:35:44,710 --> 00:35:46,720
introspection into the features that our

870
00:35:46,720 --> 00:35:48,670
network is learning we can start to

871
00:35:48,670 --> 00:35:50,200
learn something about the data and get

872
00:35:50,200 --> 00:35:52,500
insight into some of the physical

873
00:35:52,500 --> 00:35:55,510
processes that are going on in our data

874
00:35:55,510 --> 00:35:57,910
and learn what kind of structures

875
00:35:57,910 --> 00:35:59,560
perhaps are most sensitive to the

876
00:35:59,560 --> 00:36:01,630
interplay of gravity and dark energy I

877
00:36:01,630 --> 00:36:03,670
think this is something that's a real a

878
00:36:03,670 --> 00:36:06,040
real strong point of deep learning when

879
00:36:06,040 --> 00:36:08,109
you are allowing the network to learn

880
00:36:08,109 --> 00:36:10,300
features for itself rather than imposing

881
00:36:10,300 --> 00:36:12,190
features doing feature engineering or

882
00:36:12,190 --> 00:36:14,140
telling at any particular statistics you

883
00:36:14,140 --> 00:36:16,119
can allow the the network to tell you

884
00:36:16,119 --> 00:36:17,410
something about your data that might

885
00:36:17,410 --> 00:36:22,660
surprise you so far that was looking at

886
00:36:22,660 --> 00:36:24,940
two dimensional maps but of course the

887
00:36:24,940 --> 00:36:26,490
universe is not a two dimensional space

888
00:36:26,490 --> 00:36:29,950
it's at least four dimensions perhaps

889
00:36:29,950 --> 00:36:31,390
many more dimensions depending on your

890
00:36:31,390 --> 00:36:33,400
favorite model of string theory and what

891
00:36:33,400 --> 00:36:35,079
we've been looking at three dimensions

892
00:36:35,079 --> 00:36:37,380
is scaling this up another another level

893
00:36:37,380 --> 00:36:39,490
and what the reason why three dimensions

894
00:36:39,490 --> 00:36:40,569
are interesting from us from a

895
00:36:40,569 --> 00:36:42,369
computational point of view because in a

896
00:36:42,369 --> 00:36:43,900
three dimensional data volume you're

897
00:36:43,900 --> 00:36:45,460
looking at three dimensional matrices

898
00:36:45,460 --> 00:36:47,619
three dimensional convolutions this is

899
00:36:47,619 --> 00:36:48,670
something that's computationally

900
00:36:48,670 --> 00:36:50,440
expensive and it's something that can

901
00:36:50,440 --> 00:36:52,599
run really well on a supercomputing

902
00:36:52,599 --> 00:36:56,260
architecture so a team at CMU recently

903
00:36:56,260 --> 00:36:58,390
demonstrated for the first time that

904
00:36:58,390 --> 00:36:59,950
deep learning can be used to determine

905
00:36:59,950 --> 00:37:01,720
the physical model of the universe from

906
00:37:01,720 --> 00:37:03,520
three-dimensional simulations or the

907
00:37:03,520 --> 00:37:06,280
full matter distribution so this is the

908
00:37:06,280 --> 00:37:08,589
full three dimensional matter rather

909
00:37:08,589 --> 00:37:10,270
than a two dimensional projection of the

910
00:37:10,270 --> 00:37:13,750
matter density and this work showed that

911
00:37:13,750 --> 00:37:14,950
the network was able to make

912
00:37:14,950 --> 00:37:17,079
significantly better estimates of the

913
00:37:17,079 --> 00:37:19,030
parameters that describe the physics of

914
00:37:19,030 --> 00:37:21,339
the simulated universe compared to

915
00:37:21,339 --> 00:37:23,410
traditional methods and where you might

916
00:37:23,410 --> 00:37:25,060
be looking at one of these statistics

917
00:37:25,060 --> 00:37:28,690
like the power spectrum and so this is a

918
00:37:28,690 --> 00:37:30,310
really nice example of how the network

919
00:37:30,310 --> 00:37:33,579
was able to learn and what structures in

920
00:37:33,579 --> 00:37:35,039
this three-dimensional

921
00:37:35,039 --> 00:37:37,179
massive volume were important rather

922
00:37:37,179 --> 00:37:40,539
than just looking at statistics that we

923
00:37:40,539 --> 00:37:41,890
in advance thought was going to be

924
00:37:41,890 --> 00:37:45,130
useful so we're working on scaling this

925
00:37:45,130 --> 00:37:47,140
up at the moment in collaboration with

926
00:37:47,140 --> 00:37:50,679
nurse UC Berkeley Intel in Cray who are

927
00:37:50,679 --> 00:37:53,289
industry partners at nurse we're using

928
00:37:53,289 --> 00:37:55,869
larger simulation volumes even more data

929
00:37:55,869 --> 00:37:59,380
and we're using tensor flow running on

930
00:37:59,380 --> 00:38:02,319
thousands of CPU notes achieving with

931
00:38:02,319 --> 00:38:04,150
several petabytes petaflop

932
00:38:04,150 --> 00:38:06,309
of performance on Cori which is our

933
00:38:06,309 --> 00:38:08,439
flagship supercomputer but perhaps the

934
00:38:08,439 --> 00:38:09,669
most important part of this is that

935
00:38:09,669 --> 00:38:11,829
we're able to predict more physical

936
00:38:11,829 --> 00:38:14,380
parameters with even greater accuracy by

937
00:38:14,380 --> 00:38:15,969
scaling up the training of this and this

938
00:38:15,969 --> 00:38:16,900
is something that we're really excited

939
00:38:16,900 --> 00:38:20,829
about and I think it's worth talking a

940
00:38:20,829 --> 00:38:22,539
little bit more in technical daeso about

941
00:38:22,539 --> 00:38:24,219
how we achieve this performance how we

942
00:38:24,219 --> 00:38:25,900
are using tensor flow on our

943
00:38:25,900 --> 00:38:27,489
supercomputers to get this kind of

944
00:38:27,489 --> 00:38:28,959
performance and get this kind of insight

945
00:38:28,959 --> 00:38:31,449
into our data and into our science now

946
00:38:31,449 --> 00:38:34,749
supercomputers are fairly specialized we

947
00:38:34,749 --> 00:38:37,659
have specialized hardware to allow the

948
00:38:37,659 --> 00:38:39,489
tens of thousands of compute nodes we

949
00:38:39,489 --> 00:38:41,079
have on these supercomputers to act

950
00:38:41,079 --> 00:38:43,929
together as one compute machine you want

951
00:38:43,929 --> 00:38:45,729
to use this machine as efficiently as

952
00:38:45,729 --> 00:38:47,289
possible to train our network we have a

953
00:38:47,289 --> 00:38:49,329
lot of performance available to us we

954
00:38:49,329 --> 00:38:50,589
want to be able to take advantage of

955
00:38:50,589 --> 00:38:52,929
that when we're running tensorflow so

956
00:38:52,929 --> 00:38:54,849
the approach we take is using a fully

957
00:38:54,849 --> 00:38:57,219
synchronous data parallel approach where

958
00:38:57,219 --> 00:38:59,619
each node is training on a subset of the

959
00:38:59,619 --> 00:39:02,349
data and we started off as many people

960
00:39:02,349 --> 00:39:05,169
do using a G RPC for this where each

961
00:39:05,169 --> 00:39:07,029
compute node is communicating with a

962
00:39:07,029 --> 00:39:09,579
parameter server to send their parameter

963
00:39:09,579 --> 00:39:11,439
updates and have that sent back and

964
00:39:11,439 --> 00:39:13,659
forward but like many other people have

965
00:39:13,659 --> 00:39:16,419
noted this is not a very efficient way

966
00:39:16,419 --> 00:39:18,819
to run at scale we found that if we are

967
00:39:18,819 --> 00:39:21,489
running beyond 100 nodes or so then we

968
00:39:21,489 --> 00:39:22,989
had a real communication bottleneck

969
00:39:22,989 --> 00:39:25,299
between the compute nodes and the

970
00:39:25,299 --> 00:39:29,319
parameter servers so instead we use MPI

971
00:39:29,319 --> 00:39:31,839
which is a message passing interface to

972
00:39:31,839 --> 00:39:33,699
allow our compute nodes to communicate

973
00:39:33,699 --> 00:39:35,679
with each other directly so removing the

974
00:39:35,679 --> 00:39:39,309
need for parameter servers and this is

975
00:39:39,309 --> 00:39:40,719
also has the advantage that can really

976
00:39:40,719 --> 00:39:42,339
take advantage of our high speed

977
00:39:42,339 --> 00:39:43,740
interconnects

978
00:39:43,740 --> 00:39:45,870
the specialized hardware that connects

979
00:39:45,870 --> 00:39:49,290
our compute nodes so we use a for

980
00:39:49,290 --> 00:39:51,210
gradient aggregation for this we use

981
00:39:51,210 --> 00:39:54,300
specialized MPI collective all reduce

982
00:39:54,300 --> 00:39:57,600
which is designed by Cray who are our

983
00:39:57,600 --> 00:40:00,120
partners with our supercomputers and

984
00:40:00,120 --> 00:40:05,340
this MPI all reduce is is is pretty neat

985
00:40:05,340 --> 00:40:07,950
it's able to avoid imbalances in a node

986
00:40:07,950 --> 00:40:09,690
performance the straggler effect that

987
00:40:09,690 --> 00:40:11,760
some of you might run into it's

988
00:40:11,760 --> 00:40:13,920
overlapping communication and compute in

989
00:40:13,920 --> 00:40:16,500
a way that allows very effective scaling

990
00:40:16,500 --> 00:40:18,300
and we've seen that we were able to run

991
00:40:18,300 --> 00:40:19,800
tensor flow on thousands of compute

992
00:40:19,800 --> 00:40:20,820
nodes with very little drop in

993
00:40:20,820 --> 00:40:23,070
efficiency and something that I've been

994
00:40:23,070 --> 00:40:25,590
really excited to see here is a MPI or

995
00:40:25,590 --> 00:40:28,440
reduce is coming soon in tensor flow and

996
00:40:28,440 --> 00:40:30,390
we're excited to see how this is going

997
00:40:30,390 --> 00:40:33,600
to work in the larger community so the

998
00:40:33,600 --> 00:40:34,650
three things I'd like you to take away

999
00:40:34,650 --> 00:40:36,120
from this talk the first is that

1000
00:40:36,120 --> 00:40:37,620
cosmology has some really cool science

1001
00:40:37,620 --> 00:40:39,120
problems and some really cool deep

1002
00:40:39,120 --> 00:40:41,220
learning problems the second is that

1003
00:40:41,220 --> 00:40:42,840
scientific data is different from

1004
00:40:42,840 --> 00:40:45,420
natural image data and so these one

1005
00:40:45,420 --> 00:40:46,950
understood statistics that we often have

1006
00:40:46,950 --> 00:40:48,870
associated the scientific data could be

1007
00:40:48,870 --> 00:40:50,310
a real use I think in the deep learning

1008
00:40:50,310 --> 00:40:52,740
community and the third thing is that

1009
00:40:52,740 --> 00:40:55,200
MPI or reduce in our experience is the

1010
00:40:55,200 --> 00:40:57,000
optimal strategy for scaling tensor flow

1011
00:40:57,000 --> 00:40:58,950
up to multiple nodes and we're looking

1012
00:40:58,950 --> 00:41:00,090
forward to seeing how the rest of the

1013
00:41:00,090 --> 00:41:03,120
community is gonna work with this so now

1014
00:41:03,120 --> 00:41:04,680
in turn things back to Lawrence thank

1015
00:41:04,680 --> 00:41:06,140
you

1016
00:41:06,140 --> 00:41:08,030
Thank You Debbie

1017
00:41:08,030 --> 00:41:10,410
great stuff actually simulating

1018
00:41:10,410 --> 00:41:13,320
universes so we're running very short on

1019
00:41:13,320 --> 00:41:14,670
time so I just want to share these are

1020
00:41:14,670 --> 00:41:16,740
like just three great stories but there

1021
00:41:16,740 --> 00:41:18,180
are countless more stories out there

1022
00:41:18,180 --> 00:41:21,000
this is a map that I created of people

1023
00:41:21,000 --> 00:41:23,100
who starred tensorflow and github and

1024
00:41:23,100 --> 00:41:25,260
who shared their location and we have

1025
00:41:25,260 --> 00:41:27,090
people from the outback of Australia to

1026
00:41:27,090 --> 00:41:29,520
the green fields of Ireland from the

1027
00:41:29,520 --> 00:41:32,040
North Arctic Circle in Norway all the

1028
00:41:32,040 --> 00:41:33,570
way down to deception island in

1029
00:41:33,570 --> 00:41:35,280
Antarctica there are countless stories

1030
00:41:35,280 --> 00:41:38,100
being created countless great new things

1031
00:41:38,100 --> 00:41:39,510
being done with tensorflow and with

1032
00:41:39,510 --> 00:41:41,190
machine learning we think some of those

1033
00:41:41,190 --> 00:41:42,840
stories are yours and if they are please

1034
00:41:42,840 --> 00:41:44,610
get in touch with us we'd love to hear

1035
00:41:44,610 --> 00:41:46,050
them and would love to share them so

1036
00:41:46,050 --> 00:41:47,670
with that I just want to say thank you

1037
00:41:47,670 --> 00:41:49,650
very much for attending today enjoy

1038
00:41:49,650 --> 00:41:51,540
what's left of i/o and have a safe

1039
00:41:51,540 --> 00:41:53,320
journey home thank you

1040
00:41:53,320 --> 00:42:15,249
[Music]

