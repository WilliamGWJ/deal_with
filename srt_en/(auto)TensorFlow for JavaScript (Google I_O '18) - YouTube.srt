1
00:00:05,600 --> 00:00:08,849
hi everyone thanks for coming today to

2
00:00:08,849 --> 00:00:11,730
see our talk my name is Daniel my name

3
00:00:11,730 --> 00:00:15,209
is Nikhil and I'm Nick and today we're

4
00:00:15,209 --> 00:00:18,210
very happy to talk about JavaScript all

5
00:00:18,210 --> 00:00:20,880
right so if you're in the world of

6
00:00:20,880 --> 00:00:23,640
machine learning if you're doing

7
00:00:23,640 --> 00:00:25,589
training a model or anything about

8
00:00:25,589 --> 00:00:28,380
machine learning you're most certainly

9
00:00:28,380 --> 00:00:31,230
dealing with Python right and for a good

10
00:00:31,230 --> 00:00:31,769
reason

11
00:00:31,769 --> 00:00:33,810
Python has been one of the mainstream

12
00:00:33,810 --> 00:00:36,330
languages for scientific computing for

13
00:00:36,330 --> 00:00:38,760
the last decade it has a lot of tools

14
00:00:38,760 --> 00:00:42,750
but it doesn't have to be that way it

15
00:00:42,750 --> 00:00:46,260
doesn't have to end there today we're

16
00:00:46,260 --> 00:00:48,270
here to convince you that the browser

17
00:00:48,270 --> 00:00:51,870
and JavaScript have a lot to offer to

18
00:00:51,870 --> 00:00:55,170
the world of machine learning and pencil

19
00:00:55,170 --> 00:00:57,300
flow playground is a great example of

20
00:00:57,300 --> 00:00:59,550
that how many people here have seen this

21
00:00:59,550 --> 00:01:04,710
visualization quite a few I'm glad for

22
00:01:04,710 --> 00:01:07,040
those of you that haven't seen it

23
00:01:07,040 --> 00:01:10,620
tensorflow playground is in browser

24
00:01:10,620 --> 00:01:13,680
neural network visualization shows you

25
00:01:13,680 --> 00:01:16,320
what is happening inside the neural

26
00:01:16,320 --> 00:01:18,800
network as the network is training and

27
00:01:18,800 --> 00:01:21,480
when we release this this was kind of a

28
00:01:21,480 --> 00:01:24,390
fun small project when we released this

29
00:01:24,390 --> 00:01:28,380
it had a tremendous success especially

30
00:01:28,380 --> 00:01:30,330
in the educational domain and even today

31
00:01:30,330 --> 00:01:32,670
we're getting emails from high schools

32
00:01:32,670 --> 00:01:34,100
and universities around the world

33
00:01:34,100 --> 00:01:36,270
thanking us for building this and

34
00:01:36,270 --> 00:01:38,130
they're using it to teach students

35
00:01:38,130 --> 00:01:42,000
beginners about machine learning when we

36
00:01:42,000 --> 00:01:44,400
saw the success of tensorflow playground

37
00:01:44,400 --> 00:01:46,500
we started wondering why is it so

38
00:01:46,500 --> 00:01:49,409
successful and we think the browser and

39
00:01:49,409 --> 00:01:53,330
JavaScript have a lot to do with it for

40
00:01:53,330 --> 00:01:55,620
one thing that's very special about the

41
00:01:55,620 --> 00:01:58,350
browser it has no drivers and no

42
00:01:58,350 --> 00:02:00,780
installations you can share your app

43
00:02:00,780 --> 00:02:02,850
with anyone and all they have to do is

44
00:02:02,850 --> 00:02:05,510
click on a link and see your application

45
00:02:05,510 --> 00:02:07,830
another important thing about the

46
00:02:07,830 --> 00:02:10,109
browser is highly interactive in the

47
00:02:10,109 --> 00:02:12,480
playground app you we have all these

48
00:02:12,480 --> 00:02:14,200
controls

49
00:02:14,200 --> 00:02:16,120
drop down controls that you can change

50
00:02:16,120 --> 00:02:18,720
and quickly run different experiments

51
00:02:18,720 --> 00:02:20,950
another nice thing about the browser

52
00:02:20,950 --> 00:02:23,770
it runs on laptops it runs on mobile

53
00:02:23,770 --> 00:02:26,620
devices and these devices have sensors

54
00:02:26,620 --> 00:02:29,230
like the microphone and the camera and

55
00:02:29,230 --> 00:02:31,690
the accelerometer and they're all behind

56
00:02:31,690 --> 00:02:34,450
standardized web api's that you can

57
00:02:34,450 --> 00:02:37,120
easily access in your web app we didn't

58
00:02:37,120 --> 00:02:38,590
take advantage of this in the playground

59
00:02:38,590 --> 00:02:41,190
but we'll show you some demos later and

60
00:02:41,190 --> 00:02:43,870
most importantly when you're building

61
00:02:43,870 --> 00:02:47,410
web apps these apps run client-side

62
00:02:47,410 --> 00:02:50,770
which makes it easy to have the data

63
00:02:50,770 --> 00:02:52,690
stay on the client and never have to

64
00:02:52,690 --> 00:02:54,400
send it back to a server you can do

65
00:02:54,400 --> 00:02:57,160
processing on device and this is

66
00:02:57,160 --> 00:03:00,340
important for privacy now to come back

67
00:03:00,340 --> 00:03:03,459
to the playground example the library

68
00:03:03,459 --> 00:03:05,530
that powers this visualization is not

69
00:03:05,530 --> 00:03:08,050
tensorflow it is a small neural network

70
00:03:08,050 --> 00:03:11,170
library 300 lines of JavaScript code we

71
00:03:11,170 --> 00:03:14,590
wrote we wrote for this visualization

72
00:03:14,590 --> 00:03:19,180
and it wasn't meant to be reusable or to

73
00:03:19,180 --> 00:03:21,820
scale for bigger neural networks but it

74
00:03:21,820 --> 00:03:24,519
became clear to us when this became so

75
00:03:24,519 --> 00:03:27,160
successful and popular that we should go

76
00:03:27,160 --> 00:03:30,100
on and build such a library and we went

77
00:03:30,100 --> 00:03:33,010
and built deep learn j/s we released it

78
00:03:33,010 --> 00:03:37,209
August 2017 we figured out a way how to

79
00:03:37,209 --> 00:03:40,930
make it fast and scale by utilizing the

80
00:03:40,930 --> 00:03:43,900
GPU of laptops and cell phones through

81
00:03:43,900 --> 00:03:45,880
WebGL for those of you that are not

82
00:03:45,880 --> 00:03:47,790
familiar WebGL is a technology

83
00:03:47,790 --> 00:03:49,930
originally meant for rendering 3d

84
00:03:49,930 --> 00:03:53,500
graphics and the library that we built

85
00:03:53,500 --> 00:03:55,750
allows for both inference and training

86
00:03:55,750 --> 00:03:59,470
entirely in the browser when we release

87
00:03:59,470 --> 00:04:01,390
deep lunges we had an incredible

88
00:04:01,390 --> 00:04:05,110
momentum the community went instantly

89
00:04:05,110 --> 00:04:07,720
with it and took pre-trained models from

90
00:04:07,720 --> 00:04:10,620
Python and ported it in the browser one

91
00:04:10,620 --> 00:04:12,850
example I want to show you of that is

92
00:04:12,850 --> 00:04:15,280
the style transfer demo someone went and

93
00:04:15,280 --> 00:04:18,040
took the pre trained model and this demo

94
00:04:18,040 --> 00:04:20,290
has an image a source image on the left

95
00:04:20,290 --> 00:04:23,380
as artists on the right and then it can

96
00:04:23,380 --> 00:04:25,599
mash them together and they made this in

97
00:04:25,599 --> 00:04:26,010
a crea

98
00:04:26,010 --> 00:04:28,980
interesting application another demo is

99
00:04:28,980 --> 00:04:32,730
people would take models that read a lot

100
00:04:32,730 --> 00:04:34,650
of text and then they could generate new

101
00:04:34,650 --> 00:04:36,810
sentences and then they ported it in the

102
00:04:36,810 --> 00:04:38,940
browser and explored novel interfaces

103
00:04:38,940 --> 00:04:40,700
how you can explore all the different

104
00:04:40,700 --> 00:04:44,400
endings of a sentence in the educational

105
00:04:44,400 --> 00:04:47,340
domain people took the standard

106
00:04:47,340 --> 00:04:50,370
convolutional neural nets and built this

107
00:04:50,370 --> 00:04:52,770
fun little game where you can train your

108
00:04:52,770 --> 00:04:57,930
own image recognition model just by

109
00:04:57,930 --> 00:04:59,640
using the webcam and this was very

110
00:04:59,640 --> 00:05:03,750
popular and lastly researchers took

111
00:05:03,750 --> 00:05:05,730
another example they took a phone

112
00:05:05,730 --> 00:05:08,340
generation model that can generate new

113
00:05:08,340 --> 00:05:10,440
fonts previously it was trained in a lot

114
00:05:10,440 --> 00:05:12,870
of font styles and then they build this

115
00:05:12,870 --> 00:05:15,030
novel interface in the browser highly

116
00:05:15,030 --> 00:05:16,440
interactive where you can explore

117
00:05:16,440 --> 00:05:20,190
different types of fonts now building on

118
00:05:20,190 --> 00:05:22,110
that incredible momentum we had with

119
00:05:22,110 --> 00:05:22,980
deep lunges

120
00:05:22,980 --> 00:05:25,290
about a month ago at the tensorflow dev

121
00:05:25,290 --> 00:05:27,600
summit we announced that we're joining

122
00:05:27,600 --> 00:05:30,450
the tensorflow family and with that we

123
00:05:30,450 --> 00:05:32,820
introduced a new ecosystem of tools and

124
00:05:32,820 --> 00:05:35,070
libraries around javascript and machine

125
00:05:35,070 --> 00:05:39,240
learning called tensorflow jeaious now

126
00:05:39,240 --> 00:05:41,220
before we dive into the details I want

127
00:05:41,220 --> 00:05:43,440
to go over three main use cases of what

128
00:05:43,440 --> 00:05:45,840
you can do with tensorflow j/s today you

129
00:05:45,840 --> 00:05:47,460
can write models directly in the browser

130
00:05:47,460 --> 00:05:50,910
we have sets of api's for that you can

131
00:05:50,910 --> 00:05:53,220
also take pre trained models that were

132
00:05:53,220 --> 00:05:55,770
trained in Python or other languages and

133
00:05:55,770 --> 00:05:57,810
then port them for inference in the

134
00:05:57,810 --> 00:06:00,870
browser you can also take these existing

135
00:06:00,870 --> 00:06:03,450
pre-trained models and retrain them do

136
00:06:03,450 --> 00:06:07,190
transfer learning right there on device

137
00:06:07,190 --> 00:06:09,900
to give you a schematic view of the

138
00:06:09,900 --> 00:06:11,910
library we have the browser that does

139
00:06:11,910 --> 00:06:13,940
all the computation using WebGL

140
00:06:13,940 --> 00:06:16,890
tensorflow jeaious has two sets of api's

141
00:06:16,890 --> 00:06:19,860
that sit on top of this a core api which

142
00:06:19,860 --> 00:06:22,200
is a which gives you low-level building

143
00:06:22,200 --> 00:06:24,510
blocks linear linear algebra operations

144
00:06:24,510 --> 00:06:28,680
like multiply and add and on top of it

145
00:06:28,680 --> 00:06:30,630
we have layers api which gives you

146
00:06:30,630 --> 00:06:32,220
high-level building blocks and best

147
00:06:32,220 --> 00:06:34,980
practices to build neural nets and on

148
00:06:34,980 --> 00:06:36,930
top of that because there's so many

149
00:06:36,930 --> 00:06:39,280
models written in Python today we

150
00:06:39,280 --> 00:06:41,889
our tools to take an existing model a

151
00:06:41,889 --> 00:06:44,020
Karass model and attends a floor safe

152
00:06:44,020 --> 00:06:45,520
model these are two formats that are

153
00:06:45,520 --> 00:06:48,639
very popular server-side and these tools

154
00:06:48,639 --> 00:06:50,800
will automatically convert that model to

155
00:06:50,800 --> 00:06:54,340
run in the browser now to give you an

156
00:06:54,340 --> 00:06:57,550
example of our core API I'm gonna show

157
00:06:57,550 --> 00:07:00,430
you how we're gonna go over a code that

158
00:07:00,430 --> 00:07:02,710
tries to train a model that fits a

159
00:07:02,710 --> 00:07:04,750
polynomial curve and we have to learn

160
00:07:04,750 --> 00:07:07,090
the three coefficients a B and C now

161
00:07:07,090 --> 00:07:09,639
this example is pretty simple but the

162
00:07:09,639 --> 00:07:11,680
code walks you through all the steps of

163
00:07:11,680 --> 00:07:13,540
how you would train such a model and

164
00:07:13,540 --> 00:07:16,390
these steps generalize across different

165
00:07:16,390 --> 00:07:20,740
models so we import tensorflow for tens

166
00:07:20,740 --> 00:07:23,290
of flow / tens of flow j s for those of

167
00:07:23,290 --> 00:07:25,150
you that are not familiar this is in

168
00:07:25,150 --> 00:07:29,350
standard es6 modern javascript import we

169
00:07:29,350 --> 00:07:31,030
have our three variables that we're

170
00:07:31,030 --> 00:07:34,510
trying to learn a b and c we mark them

171
00:07:34,510 --> 00:07:36,250
as variables which means that the

172
00:07:36,250 --> 00:07:39,250
optimizer the machine the machinery that

173
00:07:39,250 --> 00:07:41,050
runs and trains our neural network can

174
00:07:41,050 --> 00:07:44,080
change these variables for us we have

175
00:07:44,080 --> 00:07:49,330
our function f of X given some data it

176
00:07:49,330 --> 00:07:51,400
will compute the output this is just a

177
00:07:51,400 --> 00:07:55,530
polynomial function quadratic function

178
00:07:55,530 --> 00:07:58,660
on top of the standard API like TF

179
00:07:58,660 --> 00:08:01,150
identity of multiply we also have a

180
00:08:01,150 --> 00:08:03,490
chaining API chaining has been very

181
00:08:03,490 --> 00:08:05,320
popular in the JavaScript world so you

182
00:08:05,320 --> 00:08:07,900
can call these methods these

183
00:08:07,900 --> 00:08:09,700
mathematical methods on the tensor

184
00:08:09,700 --> 00:08:12,130
itself and this reads better closer to

185
00:08:12,130 --> 00:08:16,150
how we write math so that's our model to

186
00:08:16,150 --> 00:08:16,780
train it

187
00:08:16,780 --> 00:08:19,000
we need a loss function and in this case

188
00:08:19,000 --> 00:08:21,010
we are just measuring the distance

189
00:08:21,010 --> 00:08:22,690
between the prediction of the model and

190
00:08:22,690 --> 00:08:26,350
the label the ground truth data we need

191
00:08:26,350 --> 00:08:28,510
an optimizer this is the machinery that

192
00:08:28,510 --> 00:08:30,729
can optimize and find those coefficients

193
00:08:30,729 --> 00:08:34,930
we specify a learning rate there and for

194
00:08:34,930 --> 00:08:37,599
some number of epochs passes over our

195
00:08:37,599 --> 00:08:40,240
data we call optimizer that minimize

196
00:08:40,240 --> 00:08:45,010
with our loss and our f of X and Y's so

197
00:08:45,010 --> 00:08:48,820
that's our model now this is clearly not

198
00:08:48,820 --> 00:08:50,830
how everyone writes machine learning

199
00:08:50,830 --> 00:08:51,960
models today

200
00:08:51,960 --> 00:08:53,670
over the years we've developed best

201
00:08:53,670 --> 00:08:55,740
practices in high-level building blocks

202
00:08:55,740 --> 00:08:58,710
and new api submerged like TF layers and

203
00:08:58,710 --> 00:09:01,650
caris that makes mod much easier to

204
00:09:01,650 --> 00:09:03,900
write these models and for that I want

205
00:09:03,900 --> 00:09:06,930
to walk over our layers API to show you

206
00:09:06,930 --> 00:09:09,690
how easy it is we're going to go through

207
00:09:09,690 --> 00:09:12,240
a simple neural network that sums to

208
00:09:12,240 --> 00:09:15,330
numbers but what's special about this

209
00:09:15,330 --> 00:09:18,330
network is that the input comes as a

210
00:09:18,330 --> 00:09:21,150
string character by character so ninety

211
00:09:21,150 --> 00:09:23,730
plus ten is the input to this network

212
00:09:23,730 --> 00:09:26,640
being fed as a string and the network

213
00:09:26,640 --> 00:09:28,800
has an internal memory where it encodes

214
00:09:28,800 --> 00:09:31,050
this information it has to save it and

215
00:09:31,050 --> 00:09:33,960
then on the other end the neural network

216
00:09:33,960 --> 00:09:37,740
has to output the sum 1 0 0 again

217
00:09:37,740 --> 00:09:41,070
character by character now you might

218
00:09:41,070 --> 00:09:43,140
wonder why go through such a trouble to

219
00:09:43,140 --> 00:09:45,240
train this neural network like this but

220
00:09:45,240 --> 00:09:47,460
this example forms the basis of modern

221
00:09:47,460 --> 00:09:50,220
machine translation and that's why we're

222
00:09:50,220 --> 00:09:53,760
going over this to show you the code we

223
00:09:53,760 --> 00:09:56,060
import tensorflow from desert flow Jas

224
00:09:56,060 --> 00:09:58,920
we have our model we say TF dot

225
00:09:58,920 --> 00:10:00,660
sequential which means it's just a

226
00:10:00,660 --> 00:10:03,090
linear stack of layers the first two

227
00:10:03,090 --> 00:10:04,710
layers I'm not going to go into details

228
00:10:04,710 --> 00:10:07,320
but those two are building blocks that

229
00:10:07,320 --> 00:10:09,630
can take these strings into a memory

230
00:10:09,630 --> 00:10:12,630
into an internal representation and the

231
00:10:12,630 --> 00:10:15,120
last three layers take this internal

232
00:10:15,120 --> 00:10:17,670
representation and turn it into numbers

233
00:10:17,670 --> 00:10:21,360
and that's our model to Train it we need

234
00:10:21,360 --> 00:10:24,300
to compile it with a loss and optimizer

235
00:10:24,300 --> 00:10:27,120
and a metric we want to monitor in this

236
00:10:27,120 --> 00:10:29,520
case accuracy and we call model that fit

237
00:10:29,520 --> 00:10:32,310
with our data now one thing I want to

238
00:10:32,310 --> 00:10:35,130
point out about model dot fit training

239
00:10:35,130 --> 00:10:38,460
can take for this example it can take 30

240
00:10:38,460 --> 00:10:40,680
or 40 seconds in the browser and while

241
00:10:40,680 --> 00:10:42,390
that's running we don't want to block

242
00:10:42,390 --> 00:10:44,880
the main UI thread we want our app to be

243
00:10:44,880 --> 00:10:47,190
responsive this is why model dot fit is

244
00:10:47,190 --> 00:10:49,410
an asynchronous call and we get a

245
00:10:49,410 --> 00:10:51,900
callback once it's done with the history

246
00:10:51,900 --> 00:10:54,990
object which has our accuracy as it

247
00:10:54,990 --> 00:10:59,490
evolved over time now I went through

248
00:10:59,490 --> 00:11:01,670
examples of how you write these models

249
00:11:01,670 --> 00:11:05,220
in the browser but there is also a lot

250
00:11:05,220 --> 00:11:05,780
of

251
00:11:05,780 --> 00:11:07,850
models that have already been written in

252
00:11:07,850 --> 00:11:11,510
Python and for that we have tools that

253
00:11:11,510 --> 00:11:13,370
allow you to import them automatically

254
00:11:13,370 --> 00:11:16,640
before we dive into the details I want

255
00:11:16,640 --> 00:11:19,730
to go through show you a fun little game

256
00:11:19,730 --> 00:11:21,800
that our friends at Google brand studio

257
00:11:21,800 --> 00:11:24,110
built called image called emoji

258
00:11:24,110 --> 00:11:26,330
scavenger hunt and this game takes

259
00:11:26,330 --> 00:11:28,870
advantage of a pre trained model a

260
00:11:28,870 --> 00:11:31,490
convolutional neural network that can

261
00:11:31,490 --> 00:11:34,610
detect 400 items and I'm gonna walk over

262
00:11:34,610 --> 00:11:42,140
to a pixel phone and open up a browser

263
00:11:42,140 --> 00:11:44,360
just to show you that test flow J's can

264
00:11:44,360 --> 00:11:45,830
also run in a browser because we're

265
00:11:45,830 --> 00:11:49,130
using standard WebGL and I'm gonna ask

266
00:11:49,130 --> 00:11:52,010
here any kill on my right to help me out

267
00:11:52,010 --> 00:11:54,050
here because I'm gonna need some help

268
00:11:54,050 --> 00:11:56,960
now to give you some little details

269
00:11:56,960 --> 00:11:59,090
about the game it shows you an emoji and

270
00:11:59,090 --> 00:12:02,420
then you have to go with your camera run

271
00:12:02,420 --> 00:12:04,280
around your house and find the real

272
00:12:04,280 --> 00:12:06,140
version item of that emoji before the

273
00:12:06,140 --> 00:12:08,000
time runs out and there is a neural

274
00:12:08,000 --> 00:12:11,060
network that has to detect that all

275
00:12:11,060 --> 00:12:14,810
right shall we start all right let me

276
00:12:14,810 --> 00:12:18,500
see we're gonna play it here live all

277
00:12:18,500 --> 00:12:22,390
right we have to find a watch 20 seconds

278
00:12:22,390 --> 00:12:24,050
all right that's great

279
00:12:24,050 --> 00:12:27,800
whoo all right let me see what's the

280
00:12:27,800 --> 00:12:32,990
next alright we need a shoe come on Phil

281
00:12:32,990 --> 00:12:34,730
do things buddy

282
00:12:34,730 --> 00:12:40,460
yay let's see what our next item is

283
00:12:40,460 --> 00:12:42,770
banana we have 30 seconds to find a

284
00:12:42,770 --> 00:12:45,740
banana does anyone have a banana anyone

285
00:12:45,740 --> 00:12:46,370
have a banana

286
00:12:46,370 --> 00:12:49,310
Oh awesome we got a banana over here

287
00:12:49,310 --> 00:12:52,070
fingers man there we go all right

288
00:12:52,070 --> 00:12:55,160
awesome all right so we're our high

289
00:12:55,160 --> 00:12:57,710
scores going up let's see what our next

290
00:12:57,710 --> 00:13:01,470
item is beer

291
00:13:01,470 --> 00:13:04,260
beard Daniels 12:30 in the middle of Io

292
00:13:04,260 --> 00:13:06,330
let's get back to the talk man alright

293
00:13:06,330 --> 00:13:14,700
man alright so let's talk a little bit

294
00:13:14,700 --> 00:13:17,390
about how we actually built that game

295
00:13:17,390 --> 00:13:21,260
switch back to the slides here okay so

296
00:13:21,260 --> 00:13:24,210
what we did was we trained a model in

297
00:13:24,210 --> 00:13:27,420
Python to predict from images 400

298
00:13:27,420 --> 00:13:29,100
different classes that would be good for

299
00:13:29,100 --> 00:13:31,440
an emoji scavenger hunt game these are

300
00:13:31,440 --> 00:13:33,980
things like a banana a watch and a shoe

301
00:13:33,980 --> 00:13:36,600
the way we did this was we took a pre

302
00:13:36,600 --> 00:13:38,700
trained model called mobile net and now

303
00:13:38,700 --> 00:13:39,930
if you don't know what mobile net is

304
00:13:39,930 --> 00:13:42,240
it's a state-of-the-art computer vision

305
00:13:42,240 --> 00:13:44,130
model that's designed for edge devices

306
00:13:44,130 --> 00:13:46,560
it's designed for mobile phones so we

307
00:13:46,560 --> 00:13:48,870
did is we took that model and we reuse

308
00:13:48,870 --> 00:13:50,580
the features that I would learned there

309
00:13:50,580 --> 00:13:53,310
and we did a transfer learning task to

310
00:13:53,310 --> 00:13:57,840
our 400 class classifier so then once we

311
00:13:57,840 --> 00:14:00,300
do that we have an object detector so

312
00:14:00,300 --> 00:14:02,520
this object detector lives entirely in

313
00:14:02,520 --> 00:14:05,250
the Python world so the next step of

314
00:14:05,250 --> 00:14:07,200
this process is to actually take that

315
00:14:07,200 --> 00:14:09,450
and convert it into a format that we'll

316
00:14:09,450 --> 00:14:11,640
be able to ingest in the web and then

317
00:14:11,640 --> 00:14:13,500
we'll skin the game and add sound

318
00:14:13,500 --> 00:14:15,990
effects and that kind of thing so let's

319
00:14:15,990 --> 00:14:17,880
talk a little bit about the details of

320
00:14:17,880 --> 00:14:21,450
actually going through that process so

321
00:14:21,450 --> 00:14:23,580
in Python when we're actually

322
00:14:23,580 --> 00:14:25,920
checkpointing and training our model we

323
00:14:25,920 --> 00:14:28,200
have to save it to disk so there's a

324
00:14:28,200 --> 00:14:30,390
couple ways you do this the common way

325
00:14:30,390 --> 00:14:32,160
with tensorflow is to use what's called

326
00:14:32,160 --> 00:14:34,860
a saved model details are not important

327
00:14:34,860 --> 00:14:37,200
for this talk here but the idea here is

328
00:14:37,200 --> 00:14:39,030
that there are files on disk that you

329
00:14:39,030 --> 00:14:42,300
need to write daniel also mentioned that

330
00:14:42,300 --> 00:14:44,730
we support importing from Charis now

331
00:14:44,730 --> 00:14:47,730
caris is a high-level library that lives

332
00:14:47,730 --> 00:14:49,050
on top of tensorflow

333
00:14:49,050 --> 00:14:51,660
that gives you a sort of higher level

334
00:14:51,660 --> 00:14:54,240
API to use these things details

335
00:14:54,240 --> 00:14:56,310
unimportant there are also files on disk

336
00:14:56,310 --> 00:14:58,860
that it uses to checkpoint all right so

337
00:14:58,860 --> 00:15:01,080
we have a set of files and now the next

338
00:15:01,080 --> 00:15:02,880
step is to actually convert them to a

339
00:15:02,880 --> 00:15:04,890
format that we can ingest in a in a web

340
00:15:04,890 --> 00:15:09,450
page so we have released a tool on pip

341
00:15:09,450 --> 00:15:12,030
called tensorflow J's inside of that

342
00:15:12,030 --> 00:15:12,810
tool we have

343
00:15:12,810 --> 00:15:15,540
some converging scripts all you do is

344
00:15:15,540 --> 00:15:17,880
run the script you point it to those

345
00:15:17,880 --> 00:15:20,370
saved files that you had on disk and you

346
00:15:20,370 --> 00:15:22,410
point it to an output directory and you

347
00:15:22,410 --> 00:15:24,420
will get a set of static build artifacts

348
00:15:24,420 --> 00:15:27,450
that we'll be able to use on the web the

349
00:15:27,450 --> 00:15:30,180
same flow holds for Karis models you

350
00:15:30,180 --> 00:15:32,640
point to your input h5 file and out pops

351
00:15:32,640 --> 00:15:34,970
a directory of static build artifacts

352
00:15:34,970 --> 00:15:37,800
alright so you take those static build

353
00:15:37,800 --> 00:15:39,390
artifacts and you host them on your

354
00:15:39,390 --> 00:15:41,250
website this is the same way you would

355
00:15:41,250 --> 00:15:43,650
host pngs or CSS or anything of that

356
00:15:43,650 --> 00:15:47,279
sort alright so once you do that we

357
00:15:47,279 --> 00:15:50,040
provide some api's in tensorflow j/s to

358
00:15:50,040 --> 00:15:52,920
load those static build artifacts so it

359
00:15:52,920 --> 00:15:55,200
looks something like this for tensorflow

360
00:15:55,200 --> 00:15:58,170
save model we load the model up and we

361
00:15:58,170 --> 00:16:00,540
get a model object back that model

362
00:16:00,540 --> 00:16:02,370
object can actually make predictions

363
00:16:02,370 --> 00:16:04,529
with tensorflow JS tensors right in the

364
00:16:04,529 --> 00:16:08,040
browser the same flow holds for Karis

365
00:16:08,040 --> 00:16:10,050
models we point to those static build

366
00:16:10,050 --> 00:16:11,790
artifacts and we have a model that we

367
00:16:11,790 --> 00:16:14,850
can make predictions on ok so under the

368
00:16:14,850 --> 00:16:15,420
covers

369
00:16:15,420 --> 00:16:17,580
there's actually a lot going on when we

370
00:16:17,580 --> 00:16:19,890
convert these files to a format that we

371
00:16:19,890 --> 00:16:22,080
can ingest in the web we actually are

372
00:16:22,080 --> 00:16:24,540
pruning nodes off of that graph that

373
00:16:24,540 --> 00:16:26,310
aren't needed to make that prediction

374
00:16:26,310 --> 00:16:28,890
this makes the network transfer much

375
00:16:28,890 --> 00:16:32,420
smaller and our predictions much faster

376
00:16:32,420 --> 00:16:35,280
we're also taking those weights and

377
00:16:35,280 --> 00:16:37,650
sharding and packing them into 4

378
00:16:37,650 --> 00:16:40,560
megabytes this means that the next time

379
00:16:40,560 --> 00:16:43,260
the browser loads that page your waste

380
00:16:43,260 --> 00:16:47,640
will be cached so it's super snappy we

381
00:16:47,640 --> 00:16:49,800
also support about 90 of the most

382
00:16:49,800 --> 00:16:51,720
commonly used tensorflow ops today and

383
00:16:51,720 --> 00:16:53,339
we're working hard to continue

384
00:16:53,339 --> 00:16:56,640
supporting more and on the Kara side we

385
00:16:56,640 --> 00:16:58,709
support 32 of the most commonly used

386
00:16:58,709 --> 00:17:00,450
Kara Slater's during that importing

387
00:17:00,450 --> 00:17:03,750
phase and we also support training and

388
00:17:03,750 --> 00:17:06,179
evaluation of those models so computing

389
00:17:06,179 --> 00:17:08,640
accuracy once you get them in of course

390
00:17:08,640 --> 00:17:11,060
you can also make predictions as well

391
00:17:11,060 --> 00:17:14,819
all right so I want to show you a demo

392
00:17:14,819 --> 00:17:17,730
before I bore you any more this demo is

393
00:17:17,730 --> 00:17:20,850
built by our friends at Creative Lab as

394
00:17:20,850 --> 00:17:22,800
a collaboration between them and a few

395
00:17:22,800 --> 00:17:24,209
researchers on Google

396
00:17:24,209 --> 00:17:26,429
so I'm gonna go back over here to this

397
00:17:26,429 --> 00:17:37,950
laptop okay so the idea of this model is

398
00:17:37,950 --> 00:17:40,559
it takes a 2d image of a human being and

399
00:17:40,559 --> 00:17:43,200
it estimates a set of key points that

400
00:17:43,200 --> 00:17:45,090
relate to their skeleton so things like

401
00:17:45,090 --> 00:17:46,799
your wrists point the Centers of your

402
00:17:46,799 --> 00:17:48,390
eyes your shoulders and that kind of

403
00:17:48,390 --> 00:17:50,820
thing so I'm just gonna turn the demo on

404
00:17:50,820 --> 00:17:53,580
here so when I do that the webcam will

405
00:17:53,580 --> 00:17:55,860
turn on and it's gonna start predicting

406
00:17:55,860 --> 00:17:57,360
some key points for me and I'm gonna

407
00:17:57,360 --> 00:17:58,830
step back here so you can actually see

408
00:17:58,830 --> 00:18:01,260
the full thing and as I move around

409
00:18:01,260 --> 00:18:03,240
you'll see you know the skeleton change

410
00:18:03,240 --> 00:18:07,230
and make some predictions about me all

411
00:18:07,230 --> 00:18:08,669
right so there's obviously a lot you can

412
00:18:08,669 --> 00:18:11,039
do with this we're really excited to

413
00:18:11,039 --> 00:18:13,169
show you a fun little demo it's very

414
00:18:13,169 --> 00:18:16,260
it's very thin and what's gonna happen

415
00:18:16,260 --> 00:18:18,990
is when I click this slider we're gonna

416
00:18:18,990 --> 00:18:20,970
move to a separate mode where it's going

417
00:18:20,970 --> 00:18:22,529
to look for another image on the

418
00:18:22,529 --> 00:18:24,809
internet that has a person with the same

419
00:18:24,809 --> 00:18:30,360
pose as me okay let's turn that on is it

420
00:18:30,360 --> 00:18:36,890
gonna work here

421
00:18:36,890 --> 00:18:39,649
of course it's not working now okay well

422
00:18:39,649 --> 00:18:41,299
we have a physical installation of this

423
00:18:41,299 --> 00:18:42,679
which you can go check out it's at the

424
00:18:42,679 --> 00:18:45,500
experiments tent at Allen H and it's

425
00:18:45,500 --> 00:18:47,690
really fun it's a full full-screen

426
00:18:47,690 --> 00:18:49,190
version of that where you can see

427
00:18:49,190 --> 00:18:52,039
another version of you we have released

428
00:18:52,039 --> 00:18:54,890
this model on NPM so you can go and use

429
00:18:54,890 --> 00:18:56,570
this and you need no machine learning

430
00:18:56,570 --> 00:18:59,090
experience to do it the API lets you

431
00:18:59,090 --> 00:19:01,070
point to an image and out pops an array

432
00:19:01,070 --> 00:19:03,710
of key points it's that easy so we're

433
00:19:03,710 --> 00:19:05,090
really excited to see what you do with

434
00:19:05,090 --> 00:19:16,880
that okay so there's a lot you can do

435
00:19:16,880 --> 00:19:18,649
with just porting the models to the

436
00:19:18,649 --> 00:19:20,840
browser for inference but since the

437
00:19:20,840 --> 00:19:22,429
beginning of deep learning is and

438
00:19:22,429 --> 00:19:24,500
tensorflow jess we've made it a high

439
00:19:24,500 --> 00:19:26,510
priority to be able to actually train

440
00:19:26,510 --> 00:19:29,419
directly in the browser this opens up

441
00:19:29,419 --> 00:19:32,330
the door for education in interactivity

442
00:19:32,330 --> 00:19:34,760
as well as retraining with data that

443
00:19:34,760 --> 00:19:37,039
never leaves the client so I'm gonna

444
00:19:37,039 --> 00:19:38,929
actually show you another demo of that

445
00:19:38,929 --> 00:19:46,429
back on the laptop over here okay Daniel

446
00:19:46,429 --> 00:19:51,159
you want to come help me here we go cool

447
00:19:51,159 --> 00:19:54,610
okay so the game is in three phases in

448
00:19:54,610 --> 00:19:57,519
phase one we're going to actually

449
00:19:57,519 --> 00:20:00,380
collect frames from the webcam and we're

450
00:20:00,380 --> 00:20:01,850
gonna we're gonna do is we're gonna use

451
00:20:01,850 --> 00:20:03,440
those frames to actually play a game of

452
00:20:03,440 --> 00:20:07,010
pac-man okay so Daniel once you start

453
00:20:07,010 --> 00:20:08,539
collecting frames what he's going to do

454
00:20:08,539 --> 00:20:10,760
is he's going to collect frames for up

455
00:20:10,760 --> 00:20:13,519
down left and right and those are going

456
00:20:13,519 --> 00:20:15,559
to be associated with the poses of with

457
00:20:15,559 --> 00:20:17,630
the four controls for the pac-man game

458
00:20:17,630 --> 00:20:21,200
itself so as he's collecting those were

459
00:20:21,200 --> 00:20:23,929
saving some of the images locally and

460
00:20:23,929 --> 00:20:26,299
were naturally training them all yet so

461
00:20:26,299 --> 00:20:28,490
once he's done actually collecting those

462
00:20:28,490 --> 00:20:30,409
frames we're going to train the model

463
00:20:30,409 --> 00:20:32,269
and again this is going to be trained

464
00:20:32,269 --> 00:20:34,549
entirely in the browser with no requests

465
00:20:34,549 --> 00:20:37,789
to a server anywhere okay so when we

466
00:20:37,789 --> 00:20:39,169
actually train that model what's gonna

467
00:20:39,169 --> 00:20:41,029
happen is we're actually going to take a

468
00:20:41,029 --> 00:20:43,490
pre trained mobile net model that's

469
00:20:43,490 --> 00:20:45,679
actually in the page right now and we're

470
00:20:45,679 --> 00:20:47,240
going to do a little retraining phase

471
00:20:47,240 --> 00:20:49,330
with data that he has just collected

472
00:20:49,330 --> 00:20:53,700
so why don't you press that train model

473
00:20:53,700 --> 00:20:56,499
awesome our loss value is actually going

474
00:20:56,499 --> 00:20:57,820
down it looks like we've learned

475
00:20:57,820 --> 00:21:00,610
something okay so the phase three of

476
00:21:00,610 --> 00:21:03,519
this game is to actually play so when he

477
00:21:03,519 --> 00:21:05,139
presses that button what's gonna happen

478
00:21:05,139 --> 00:21:06,610
is we're gonna take frames from that

479
00:21:06,610 --> 00:21:08,619
webcam and we're gonna make predictions

480
00:21:08,619 --> 00:21:10,830
given that model that we just trained

481
00:21:10,830 --> 00:21:13,389
why don't you press that play button and

482
00:21:13,389 --> 00:21:15,220
we'll see how it goes so if you look in

483
00:21:15,220 --> 00:21:16,779
the bottom right of the screen you'll

484
00:21:16,779 --> 00:21:19,149
actually see the predictions happening

485
00:21:19,149 --> 00:21:21,399
so it's it's highlighting the the

486
00:21:21,399 --> 00:21:23,679
control that it thinks it is and you'll

487
00:21:23,679 --> 00:21:25,570
see him actually playing the pac-man

488
00:21:25,570 --> 00:21:29,470
game now so obviously this is just a

489
00:21:29,470 --> 00:21:30,549
game

490
00:21:30,549 --> 00:21:31,690
but we're really excited about

491
00:21:31,690 --> 00:21:33,759
opportunities for accessibility you can

492
00:21:33,759 --> 00:21:35,619
imagine a Chrome extension that lets you

493
00:21:35,619 --> 00:21:37,090
train a model that lets you scroll the

494
00:21:37,090 --> 00:21:39,759
page and click now all of this code is

495
00:21:39,759 --> 00:21:42,009
online and available for you to go and

496
00:21:42,009 --> 00:21:43,629
fork and build your own applications

497
00:21:43,629 --> 00:21:45,279
with and we're really excited to see

498
00:21:45,279 --> 00:21:47,769
what you do with it all right men we

499
00:21:47,769 --> 00:21:55,950
gotta go back to the talk all right

500
00:21:55,950 --> 00:21:58,570
okay so let's chat a little bit about

501
00:21:58,570 --> 00:22:01,330
performance what we're looking at here

502
00:22:01,330 --> 00:22:04,630
is a benchmark of mobile net 1.0 running

503
00:22:04,630 --> 00:22:06,040
with tensorflow Python

504
00:22:06,040 --> 00:22:08,200
this is classic tensorflow not running

505
00:22:08,200 --> 00:22:11,140
what tensorflow jazz we're thinking

506
00:22:11,140 --> 00:22:12,700
about this in the context of a batch

507
00:22:12,700 --> 00:22:15,040
size of one and the reason that we want

508
00:22:15,040 --> 00:22:16,300
to think like that is because we're

509
00:22:16,300 --> 00:22:17,770
thinking of an interactive application

510
00:22:17,770 --> 00:22:20,620
like pac-man where you can only read one

511
00:22:20,620 --> 00:22:23,200
sensor frame at a time so you can't

512
00:22:23,200 --> 00:22:26,140
really batch that data on the first row

513
00:22:26,140 --> 00:22:27,670
we're looking at tensorflow

514
00:22:27,670 --> 00:22:30,970
running with cuda on a 1080 GTX this is

515
00:22:30,970 --> 00:22:33,310
a beefy machine and it's getting about

516
00:22:33,310 --> 00:22:35,320
three milliseconds per frame and I want

517
00:22:35,320 --> 00:22:37,810
to mention that the smaller the bar the

518
00:22:37,810 --> 00:22:40,480
faster it is in the second row we're

519
00:22:40,480 --> 00:22:43,300
looking at tensorflow CPU running with

520
00:22:43,300 --> 00:22:45,730
avx2 instructions on one of these

521
00:22:45,730 --> 00:22:48,460
MacBook Pros here we're getting about 60

522
00:22:48,460 --> 00:22:51,180
milliseconds for a frame there all right

523
00:22:51,180 --> 00:22:53,650
where does tensorflow jess fit into this

524
00:22:53,650 --> 00:22:57,700
Victor well it depends so running on

525
00:22:57,700 --> 00:22:59,950
that 1080 GTX that beefy machine we're

526
00:22:59,950 --> 00:23:01,630
getting about 11 milliseconds for a

527
00:23:01,630 --> 00:23:04,660
frame on tensorflow J's running on an

528
00:23:04,660 --> 00:23:06,400
integrated graphics card on one of these

529
00:23:06,400 --> 00:23:08,170
laptops we're getting about 100

530
00:23:08,170 --> 00:23:10,540
milliseconds for frame I just want to

531
00:23:10,540 --> 00:23:11,890
point out that 100 milliseconds is

532
00:23:11,890 --> 00:23:14,170
actually not so bad that pac-man game

533
00:23:14,170 --> 00:23:16,180
was running with this model and you can

534
00:23:16,180 --> 00:23:17,650
really build something interactive with

535
00:23:17,650 --> 00:23:20,980
that the web is only going to get faster

536
00:23:20,980 --> 00:23:23,500
and faster there are new set of

537
00:23:23,500 --> 00:23:25,630
standards like WebGL compute shaders and

538
00:23:25,630 --> 00:23:28,480
web GPU which gives you much closer to

539
00:23:28,480 --> 00:23:32,530
the metal access to the GPU but the web

540
00:23:32,530 --> 00:23:34,660
has its limitations you live in a

541
00:23:34,660 --> 00:23:36,370
sandbox environment and you can only

542
00:23:36,370 --> 00:23:38,680
really get access to the GPU through

543
00:23:38,680 --> 00:23:41,560
these api's so how do we scale beyond

544
00:23:41,560 --> 00:23:44,020
those limitations with that I'm going to

545
00:23:44,020 --> 00:23:45,820
hand it off to Nick who's going to talk

546
00:23:45,820 --> 00:23:51,090
about hollow scale thanks to kill today

547
00:23:51,090 --> 00:23:53,890
we're launching tensorflow support for

548
00:23:53,890 --> 00:23:57,429
nodejs

549
00:23:57,429 --> 00:24:00,649
thank you we're really excited to bring

550
00:24:00,649 --> 00:24:03,289
and easy to use high performance machine

551
00:24:03,289 --> 00:24:04,730
learning library to JavaScript

552
00:24:04,730 --> 00:24:09,110
developers the open source community

553
00:24:09,110 --> 00:24:11,960
around nodejs and npm is really awesome

554
00:24:11,960 --> 00:24:14,450
there's incredible movement in the space

555
00:24:14,450 --> 00:24:16,789
a ton of libraries and packages for

556
00:24:16,789 --> 00:24:19,249
developers to use today and now we're

557
00:24:19,249 --> 00:24:23,210
bringing ml to this front the engine

558
00:24:23,210 --> 00:24:26,419
that runs nodejs v8 is super fast it's

559
00:24:26,419 --> 00:24:28,610
had tons of resources put into it by

560
00:24:28,610 --> 00:24:30,470
companies like Google and we've seen the

561
00:24:30,470 --> 00:24:32,779
interpreter be up to ten times as fast

562
00:24:32,779 --> 00:24:36,169
as Python lots of room for performance

563
00:24:36,169 --> 00:24:40,399
improvements also using tensorflow gives

564
00:24:40,399 --> 00:24:42,740
us access to really high-end machine

565
00:24:42,740 --> 00:24:45,559
learning hardware like GPU devices and

566
00:24:45,559 --> 00:24:48,259
TP use in the cloud look for support for

567
00:24:48,259 --> 00:24:52,580
that soon let's step back and look at

568
00:24:52,580 --> 00:24:54,139
the architecture we highlighted earlier

569
00:24:54,139 --> 00:24:57,590
we have a layers API and in a little bit

570
00:24:57,590 --> 00:25:01,059
lower level core API that has our ops

571
00:25:01,059 --> 00:25:03,889
this whole runtime is powered by WebGL

572
00:25:03,889 --> 00:25:07,220
in the browser but today through NPM

573
00:25:07,220 --> 00:25:09,049
we're shipping a package that gives you

574
00:25:09,049 --> 00:25:11,389
tensor flow that gives you access to

575
00:25:11,389 --> 00:25:14,720
those TP use the GPU and CPU all of this

576
00:25:14,720 --> 00:25:18,529
is through our NPM package to show you

577
00:25:18,529 --> 00:25:20,929
how easy it is to use our node bindings

578
00:25:20,929 --> 00:25:23,529
I want to show you a little code snippet

579
00:25:23,529 --> 00:25:26,149
this application function right here is

580
00:25:26,149 --> 00:25:28,340
a very common server-side request

581
00:25:28,340 --> 00:25:30,799
response handler for an endpoint those

582
00:25:30,799 --> 00:25:31,789
who have worked with the Express

583
00:25:31,789 --> 00:25:33,740
framework know exactly what's going on

584
00:25:33,740 --> 00:25:37,159
here our endpoint listens for slash

585
00:25:37,159 --> 00:25:40,279
model and takes input as a request which

586
00:25:40,279 --> 00:25:42,799
we pass into a tensorflow j/s model and

587
00:25:42,799 --> 00:25:45,499
that output is pushed out into the

588
00:25:45,499 --> 00:25:49,309
response now to turn on high-performance

589
00:25:49,309 --> 00:25:51,740
sensor flow code we only need two lines

590
00:25:51,740 --> 00:25:54,320
of code an import which loads our

591
00:25:54,320 --> 00:25:56,960
binding and in an existing API call to

592
00:25:56,960 --> 00:25:58,340
set our back-end the tensorflow

593
00:25:58,340 --> 00:26:00,590
now this model is running with the

594
00:26:00,590 --> 00:26:04,280
performance of tensorflow

595
00:26:04,280 --> 00:26:07,920
what works today out of the box so we

596
00:26:07,920 --> 00:26:09,990
can take pre-existing Python models and

597
00:26:09,990 --> 00:26:13,020
run those natively and nodejs the models

598
00:26:13,020 --> 00:26:14,730
we've kind of showed off today all of

599
00:26:14,730 --> 00:26:16,700
those will run in our node runtime

600
00:26:16,700 --> 00:26:19,740
there's no need to bring up Python stack

601
00:26:19,740 --> 00:26:21,660
to your node infrastructure just run

602
00:26:21,660 --> 00:26:26,790
into JavaScript our MPM package today

603
00:26:26,790 --> 00:26:29,760
ships an off-the-shelf CPU bill there's

604
00:26:29,760 --> 00:26:32,490
no additional drivers to do just install

605
00:26:32,490 --> 00:26:35,570
our package and you're up and running

606
00:26:35,570 --> 00:26:39,870
our whole API we ship in tensorflow GS

607
00:26:39,870 --> 00:26:42,270
will work with our node runtime every

608
00:26:42,270 --> 00:26:45,270
API we've showcased will work today out

609
00:26:45,270 --> 00:26:51,450
of the box now we've built a little demo

610
00:26:51,450 --> 00:26:54,540
using Major League Baseball data and no

611
00:26:54,540 --> 00:26:56,580
GS to showcase what you can do with

612
00:26:56,580 --> 00:27:01,070
machine learning no GS and JavaScript

613
00:27:01,070 --> 00:27:03,420
we've used Major League Baseball

614
00:27:03,420 --> 00:27:06,240
advanced medias pitch FX data set to do

615
00:27:06,240 --> 00:27:08,580
some machine learning the pitch effects

616
00:27:08,580 --> 00:27:11,610
data set is this large library of sensor

617
00:27:11,610 --> 00:27:14,070
data about pitches that baseball players

618
00:27:14,070 --> 00:27:17,970
have thrown in actual baseball games for

619
00:27:17,970 --> 00:27:19,860
those that aren't super familiar with

620
00:27:19,860 --> 00:27:21,720
baseball we've given a little context

621
00:27:21,720 --> 00:27:24,150
here a pitcher will throw different

622
00:27:24,150 --> 00:27:26,400
types of pitches to fool the player

623
00:27:26,400 --> 00:27:27,930
who's trying to hit this ball there's

624
00:27:27,930 --> 00:27:30,480
pitches that have higher velocities

625
00:27:30,480 --> 00:27:32,070
there's pitches that are a little slower

626
00:27:32,070 --> 00:27:35,040
but have more movement in this example

627
00:27:35,040 --> 00:27:36,630
we've sort of highlighted the fastball

628
00:27:36,630 --> 00:27:38,490
to change up in the curveball those are

629
00:27:38,490 --> 00:27:40,830
all types of pitches don't get too hung

630
00:27:40,830 --> 00:27:42,900
up about the details of baseball what

631
00:27:42,900 --> 00:27:44,610
we're really trying to solve here is a

632
00:27:44,610 --> 00:27:46,800
very classic machine learning problem of

633
00:27:46,800 --> 00:27:48,810
taking sensor information and drawing a

634
00:27:48,810 --> 00:27:52,890
classification to that so for that I'm

635
00:27:52,890 --> 00:28:02,360
gonna actually showcase this demo

636
00:28:02,360 --> 00:28:05,630
Oh rent so on one side of my screen I

637
00:28:05,630 --> 00:28:07,250
have a terminal which I'm going to start

638
00:28:07,250 --> 00:28:09,290
my note application with and on the Left

639
00:28:09,290 --> 00:28:12,110
I have a web browser we've built this a

640
00:28:12,110 --> 00:28:14,720
very simple UI that listens to what our

641
00:28:14,720 --> 00:28:17,300
server is doing over sockets those have

642
00:28:17,300 --> 00:28:19,310
used the socket IO library and node know

643
00:28:19,310 --> 00:28:23,060
what this interaction is doing so I'm

644
00:28:23,060 --> 00:28:27,430
just gonna type node start my server and

645
00:28:27,430 --> 00:28:30,560
now alter node my model is up and

646
00:28:30,560 --> 00:28:33,230
running and training every time we take

647
00:28:33,230 --> 00:28:35,060
a pass through our data set we report

648
00:28:35,060 --> 00:28:36,680
that over the socket to our client and

649
00:28:36,680 --> 00:28:38,540
you can see the blue bar is moving a

650
00:28:38,540 --> 00:28:40,490
little bit closer to 100% that's our

651
00:28:40,490 --> 00:28:42,410
model understanding how to tell the

652
00:28:42,410 --> 00:28:44,750
difference between a curve ball or a

653
00:28:44,750 --> 00:28:46,970
fastball and as you can kind of see

654
00:28:46,970 --> 00:28:48,920
every step it moves a little bit

655
00:28:48,920 --> 00:28:51,080
differently and our model is having a

656
00:28:51,080 --> 00:28:52,340
little bit of trouble at the moment with

657
00:28:52,340 --> 00:28:54,980
the fastball sinker but it's only looked

658
00:28:54,980 --> 00:28:57,260
at data for a few passes the more this

659
00:28:57,260 --> 00:28:58,760
server runs the better it gets at

660
00:28:58,760 --> 00:29:02,540
training so all of this training data

661
00:29:02,540 --> 00:29:04,430
we've shown is historical baseball data

662
00:29:04,430 --> 00:29:09,320
from 2015 to 2017 I'm going to hit this

663
00:29:09,320 --> 00:29:11,360
test live button and this is going to

664
00:29:11,360 --> 00:29:14,150
use with ease the node framework to go

665
00:29:14,150 --> 00:29:16,370
out to Major League Baseball pull in

666
00:29:16,370 --> 00:29:19,190
some newer data some live data and run

667
00:29:19,190 --> 00:29:25,910
the evaluation so once this data comes

668
00:29:25,910 --> 00:29:27,770
in we're gonna see the orange bars and

669
00:29:27,770 --> 00:29:29,870
the orange bars shows how much better we

670
00:29:29,870 --> 00:29:31,490
are at predicting data that our model

671
00:29:31,490 --> 00:29:33,350
has never seen before these are live

672
00:29:33,350 --> 00:29:35,990
pictures and we're really good at I

673
00:29:35,990 --> 00:29:37,700
didn't find that curveball and not so

674
00:29:37,700 --> 00:29:40,510
great at that fastball sinker still so

675
00:29:40,510 --> 00:29:43,550
let's jump back and continue to look at

676
00:29:43,550 --> 00:29:50,659
our next slide

677
00:29:50,659 --> 00:29:52,860
this is the architecture of what we were

678
00:29:52,860 --> 00:29:54,929
doing in that demo we've built a very

679
00:29:54,929 --> 00:29:56,549
simple node server that hosts our

680
00:29:56,549 --> 00:29:59,039
javascript models and when we hit that

681
00:29:59,039 --> 00:30:01,049
live button it reaches out to Major

682
00:30:01,049 --> 00:30:03,149
League Baseball pulls in that live data

683
00:30:03,149 --> 00:30:05,100
and runs inference on those new pitches

684
00:30:05,100 --> 00:30:07,679
we continue to just report that to any

685
00:30:07,679 --> 00:30:11,630
connected clients through the browser

686
00:30:11,630 --> 00:30:13,830
where does this stack up and perform it

687
00:30:13,830 --> 00:30:16,409
so in that training set we were looking

688
00:30:16,409 --> 00:30:18,600
at 7,000 pitches and we were training

689
00:30:18,600 --> 00:30:22,230
every couple seconds 7,000 pitches so

690
00:30:22,230 --> 00:30:23,730
that's an interesting benchmark but

691
00:30:23,730 --> 00:30:26,130
let's actually classify that with the

692
00:30:26,130 --> 00:30:27,899
mobile net benchmark we showcased

693
00:30:27,899 --> 00:30:30,299
earlier so these are the numbers for

694
00:30:30,299 --> 00:30:32,940
Python tensorflow the GPU and the CPU

695
00:30:32,940 --> 00:30:36,090
inference time so we're just getting

696
00:30:36,090 --> 00:30:37,799
started we've just launched an NPM

697
00:30:37,799 --> 00:30:41,279
package we have a lot of a ways to go

698
00:30:41,279 --> 00:30:43,889
but we have some promising early numbers

699
00:30:43,889 --> 00:30:49,080
to showcase tensorflow when no GS is

700
00:30:49,080 --> 00:30:55,390
exactly as fast as Python tensorflow

701
00:30:55,390 --> 00:30:57,490
so with that I'm gonna hand it off to

702
00:30:57,490 --> 00:31:01,650
Nikhil to wrap up thanks Nick

703
00:31:01,650 --> 00:31:06,610
exciting stuff okay so let's recap some

704
00:31:06,610 --> 00:31:09,040
of the api's and libraries and tools

705
00:31:09,040 --> 00:31:10,840
that we have supported today with

706
00:31:10,840 --> 00:31:14,710
tensorflow jazz we have a low-level api

707
00:31:14,710 --> 00:31:16,960
called the core API which is a set of

708
00:31:16,960 --> 00:31:19,660
accelerated linear algebra kernels and a

709
00:31:19,660 --> 00:31:22,059
layer for automatic differentiation we

710
00:31:22,059 --> 00:31:23,380
saw an example of that with the

711
00:31:23,380 --> 00:31:27,730
polynomial Russian demo we also have a

712
00:31:27,730 --> 00:31:30,820
high-level layers API that encodes

713
00:31:30,820 --> 00:31:33,070
machine learning best practices into an

714
00:31:33,070 --> 00:31:36,220
API that's much more easy to use and we

715
00:31:36,220 --> 00:31:37,990
saw an example of that with that edition

716
00:31:37,990 --> 00:31:42,340
RNN translation demo we also have showed

717
00:31:42,340 --> 00:31:44,110
you a couple ways that you can take pre

718
00:31:44,110 --> 00:31:46,480
trained models from Python via saved

719
00:31:46,480 --> 00:31:49,030
model or via Kerris models and port

720
00:31:49,030 --> 00:31:51,010
those to the browser for inference or

721
00:31:51,010 --> 00:31:53,559
doing retraining or competing accuracy

722
00:31:53,559 --> 00:31:57,820
and of course we also showed you the new

723
00:31:57,820 --> 00:31:59,980
node J s support for tensorflow jazz

724
00:31:59,980 --> 00:32:02,230
today and we're really excited about

725
00:32:02,230 --> 00:32:07,750
that okay so this project tensorflow

726
00:32:07,750 --> 00:32:09,970
Jess was not just the three of us on

727
00:32:09,970 --> 00:32:11,620
stage here it was a cross team

728
00:32:11,620 --> 00:32:13,660
collaboration between many amazing

729
00:32:13,660 --> 00:32:17,440
people at Google and we also have some

730
00:32:17,440 --> 00:32:19,210
amazing open source contributors that I

731
00:32:19,210 --> 00:32:21,280
want to send a shout out to this project

732
00:32:21,280 --> 00:32:22,809
literally would not have been possible

733
00:32:22,809 --> 00:32:26,169
without them so thank you all of the

734
00:32:26,169 --> 00:32:27,549
things that we talked about here today

735
00:32:27,549 --> 00:32:31,390
the demos all the code is open source on

736
00:32:31,390 --> 00:32:34,360
our website J s tensorflow org all of

737
00:32:34,360 --> 00:32:36,660
the code is also open sourced on github

738
00:32:36,660 --> 00:32:38,860
github calm / tensorflow

739
00:32:38,860 --> 00:32:42,040
/ TF j s we also have a community

740
00:32:42,040 --> 00:32:43,929
mailing list this is a place where

741
00:32:43,929 --> 00:32:46,570
people can go and ask questions post

742
00:32:46,570 --> 00:32:48,820
their demos and and that kind of thing

743
00:32:48,820 --> 00:32:51,910
we have some office hours today at 3:30

744
00:32:51,910 --> 00:32:53,470
and we have some office hours tomorrow

745
00:32:53,470 --> 00:32:56,169
at 9:30 which I invite you to come and

746
00:32:56,169 --> 00:32:58,210
talk to us in person and we also have

747
00:32:58,210 --> 00:33:00,760
some tents we have the experiments tent

748
00:33:00,760 --> 00:33:03,130
that's @h that's where that move mirror

749
00:33:03,130 --> 00:33:04,720
demo the full-screen version of that

750
00:33:04,720 --> 00:33:08,080
will be and we also will be at the AI

751
00:33:08,080 --> 00:33:12,160
10th as well so we are really excited to

752
00:33:12,160 --> 00:33:13,960
build the next chapter of machine

753
00:33:13,960 --> 00:33:16,510
learning and JavaScript with you thank

754
00:33:16,510 --> 00:33:17,410
you

755
00:33:17,410 --> 00:33:39,329
[Music]

