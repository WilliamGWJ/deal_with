1
00:00:00,000 --> 00:00:03,240
tensorflow tensorflow a name you should

2
00:00:03,240 --> 00:00:04,650
eat hopefully you got that one for the

3
00:00:04,650 --> 00:00:10,290
outtakes right welcome to ask tensorflow

4
00:00:10,290 --> 00:00:11,759
this is the show where we answer your

5
00:00:11,759 --> 00:00:13,679
questions about tensorflow my name is

6
00:00:13,679 --> 00:00:15,000
Laurence Moroney I'm a developer

7
00:00:15,000 --> 00:00:16,440
advocate on tensorflow and with me I

8
00:00:16,440 --> 00:00:18,420
have Magnus it's them I'm also a

9
00:00:18,420 --> 00:00:20,340
developer advocate on tensor film we've

10
00:00:20,340 --> 00:00:21,720
got lots of great questions coming in

11
00:00:21,720 --> 00:00:23,039
from the community so should we just get

12
00:00:23,039 --> 00:00:24,510
straight to them yeah sounds good okay

13
00:00:24,510 --> 00:00:26,970
so the first question is from user three

14
00:00:26,970 --> 00:00:29,039
seven eight nine zero two zero zero and

15
00:00:29,039 --> 00:00:30,689
stack overflow I'd love to have to get a

16
00:00:30,689 --> 00:00:33,120
username like that and the question is

17
00:00:33,120 --> 00:00:35,309
when I try to run tensorflow on Windows

18
00:00:35,309 --> 00:00:38,219
using a GPU it fails with being unable

19
00:00:38,219 --> 00:00:41,190
to load some certain dll's and I have

20
00:00:41,190 --> 00:00:42,660
those dll's installed and I have

21
00:00:42,660 --> 00:00:44,579
tensorflow install and I've checked what

22
00:00:44,579 --> 00:00:46,950
can I do well there's a number of

23
00:00:46,950 --> 00:00:48,780
reasons for this and it's a common thing

24
00:00:48,780 --> 00:00:50,280
in Windows development like DLL

25
00:00:50,280 --> 00:00:52,559
mismatches but I found the most common

26
00:00:52,559 --> 00:00:54,270
DLL mismatch that's really easy to

27
00:00:54,270 --> 00:00:56,010
overlook is that when you go to the

28
00:00:56,010 --> 00:00:57,989
Nvidia site to download the drivers for

29
00:00:57,989 --> 00:01:00,359
your GPU the CUDA and the CU DNN drivers

30
00:01:00,359 --> 00:01:02,850
their website as it should will always

31
00:01:02,850 --> 00:01:04,710
default to giving you the most recent

32
00:01:04,710 --> 00:01:06,720
version of the drivers but tensorflow

33
00:01:06,720 --> 00:01:09,240
actually needs a specific exact version

34
00:01:09,240 --> 00:01:10,979
and if the most recent version one has

35
00:01:10,979 --> 00:01:12,960
passed down from the tensorflow one then

36
00:01:12,960 --> 00:01:14,700
you're gonna get that dll mismatch so

37
00:01:14,700 --> 00:01:16,500
for example when I was setting up my own

38
00:01:16,500 --> 00:01:18,600
windows development box I installed the

39
00:01:18,600 --> 00:01:20,400
latest Nvidia drivers which at that time

40
00:01:20,400 --> 00:01:24,060
were for cuda 9.1 and because they were

41
00:01:24,060 --> 00:01:25,830
the latest I thought I was okay whenever

42
00:01:25,830 --> 00:01:27,630
I tried to run tensorflow and I was

43
00:01:27,630 --> 00:01:29,850
getting DLL errors it took me a little

44
00:01:29,850 --> 00:01:31,890
while digging into them to realize that

45
00:01:31,890 --> 00:01:34,890
the missing dll was CUDA or T underscore

46
00:01:34,890 --> 00:01:37,590
90 DLL but when I looked really closely

47
00:01:37,590 --> 00:01:41,490
I had version 91 or nine one of DLL and

48
00:01:41,490 --> 00:01:43,649
as a result tensorflow was getting a

49
00:01:43,649 --> 00:01:45,600
little bit confused so when I went back

50
00:01:45,600 --> 00:01:47,909
to the Nvidia site and I looked in there

51
00:01:47,909 --> 00:01:49,920
like historic downloads there archive

52
00:01:49,920 --> 00:01:52,229
downloads I found version 9.0 I

53
00:01:52,229 --> 00:01:55,049
uninstalled 91 I installed nine zero and

54
00:01:55,049 --> 00:01:57,030
intensive flow worked perfectly well so

55
00:01:57,030 --> 00:01:59,009
I did blog about this experience because

56
00:01:59,009 --> 00:02:00,810
it was something that you know I've seen

57
00:02:00,810 --> 00:02:02,340
a lot of developers having a little bit

58
00:02:02,340 --> 00:02:03,930
of trouble with and I've put a link to

59
00:02:03,930 --> 00:02:05,820
their blog post in the in the comments

60
00:02:05,820 --> 00:02:07,259
below and complete with beautiful

61
00:02:07,259 --> 00:02:10,080
screenshots sounds good so CUDA problems

62
00:02:10,080 --> 00:02:12,450
are very common yeah definitely so just

63
00:02:12,450 --> 00:02:13,530
make sure that you have the

64
00:02:13,530 --> 00:02:15,330
the matching DLL so should we take a

65
00:02:15,330 --> 00:02:17,580
look at the next question yeah so when I

66
00:02:17,580 --> 00:02:19,350
try to run a tenth of a web I get

67
00:02:19,350 --> 00:02:21,510
overloaded with debug messages how do I

68
00:02:21,510 --> 00:02:23,190
turn them off and this was asked by

69
00:02:23,190 --> 00:02:25,770
d-las on Stack Overflow so that's a

70
00:02:25,770 --> 00:02:28,170
great question sometimes you can just

71
00:02:28,170 --> 00:02:31,320
see them flying flying so it is a great

72
00:02:31,320 --> 00:02:33,600
question dealers well debug messages are

73
00:02:33,600 --> 00:02:35,430
great because they help us understand

74
00:02:35,430 --> 00:02:37,050
what's going on in our code they can

75
00:02:37,050 --> 00:02:39,390
also be a bit cumbersome and it's hard

76
00:02:39,390 --> 00:02:41,130
to find our specific error message

77
00:02:41,130 --> 00:02:43,350
because of this so fortunately there is

78
00:02:43,350 --> 00:02:45,360
an easy enough way to turn them off

79
00:02:45,360 --> 00:02:47,489
there is an environment variable called

80
00:02:47,489 --> 00:02:49,500
TF underscore cpp underscore main

81
00:02:49,500 --> 00:02:51,209
underscore log on the school level and

82
00:02:51,209 --> 00:02:52,530
you can tell it's an environment

83
00:02:52,530 --> 00:02:53,970
variable with all the underscores and

84
00:02:53,970 --> 00:02:56,489
the caps right yes so this is the way

85
00:02:56,489 --> 00:02:59,160
you use it so you essentially set OS dot

86
00:02:59,160 --> 00:03:01,560
environ you set this environment

87
00:03:01,560 --> 00:03:04,650
variable to a specific log level and the

88
00:03:04,650 --> 00:03:06,690
default log level that we have in the

89
00:03:06,690 --> 00:03:08,220
system is zero which essentially means

90
00:03:08,220 --> 00:03:11,910
show everything there if you put one

91
00:03:11,910 --> 00:03:13,950
there instead it will filter out in four

92
00:03:13,950 --> 00:03:15,840
messages to you will filter out warning

93
00:03:15,840 --> 00:03:18,450
messages and three will also filter out

94
00:03:18,450 --> 00:03:20,700
all the error messages so if you set it

95
00:03:20,700 --> 00:03:23,160
to three as shown in this example you'll

96
00:03:23,160 --> 00:03:26,010
see very little output and then the nice

97
00:03:26,010 --> 00:03:27,780
thing is your own debug messages that

98
00:03:27,780 --> 00:03:28,950
you've inserted into your own code they

99
00:03:28,950 --> 00:03:31,019
won't be lost in all the noise no okay

100
00:03:31,019 --> 00:03:33,000
so great question yeah we move on to the

101
00:03:33,000 --> 00:03:34,950
next absolutely and the next one is one

102
00:03:34,950 --> 00:03:36,900
of my favorites and it's from Fidelma in

103
00:03:36,900 --> 00:03:39,810
ireland and she asks I would like to use

104
00:03:39,810 --> 00:03:42,720
tensorflow but I don't know Python do

105
00:03:42,720 --> 00:03:44,070
you have any other languages and how

106
00:03:44,070 --> 00:03:44,760
about Java

107
00:03:44,760 --> 00:03:47,100
well Fidelma thanks for the question and

108
00:03:47,100 --> 00:03:49,769
well we do have stuff in Java which can

109
00:03:49,769 --> 00:03:51,840
be found in their models tree master

110
00:03:51,840 --> 00:03:54,450
samples languages Java directory it does

111
00:03:54,450 --> 00:03:56,430
not have feature parity with the Python

112
00:03:56,430 --> 00:03:58,890
api's and it's more suited for inference

113
00:03:58,890 --> 00:04:01,290
from pre-trained models so I definitely

114
00:04:01,290 --> 00:04:02,970
recommend that Fidelma sticks with

115
00:04:02,970 --> 00:04:04,769
Python for the time being but we are

116
00:04:04,769 --> 00:04:06,630
working on more write madness including

117
00:04:06,630 --> 00:04:08,280
like some cool stuff in JavaScript that

118
00:04:08,280 --> 00:04:10,530
would be talking about soon Python as

119
00:04:10,530 --> 00:04:12,180
well if you want to use it is perfectly

120
00:04:12,180 --> 00:04:14,190
suited for complex mathematical models

121
00:04:14,190 --> 00:04:15,570
and they've got tons of supporting

122
00:04:15,570 --> 00:04:17,370
libraries for that as well and not to

123
00:04:17,370 --> 00:04:19,229
mention is really super easy to learn so

124
00:04:19,229 --> 00:04:20,940
I recommend that you give it a try if

125
00:04:20,940 --> 00:04:23,070
you haven't done so already but you know

126
00:04:23,070 --> 00:04:24,960
on the team we'd also really love to get

127
00:04:24,960 --> 00:04:26,550
feedback on the languages that people

128
00:04:26,550 --> 00:04:27,150
love

129
00:04:27,150 --> 00:04:28,889
Yeah right there whatever it is that

130
00:04:28,889 --> 00:04:30,300
you're programming in and you'd like to

131
00:04:30,300 --> 00:04:31,919
see supported intensive folk going

132
00:04:31,919 --> 00:04:33,750
forward you know please let us know and

133
00:04:33,750 --> 00:04:35,310
like leave a little note in the comments

134
00:04:35,310 --> 00:04:37,560
below right yeah so we take a look at

135
00:04:37,560 --> 00:04:39,720
the next question yeah let's do that so

136
00:04:39,720 --> 00:04:41,669
the next question is asked by LX in

137
00:04:41,669 --> 00:04:43,889
Seattle and the question is what is the

138
00:04:43,889 --> 00:04:45,810
difference between tensorflow mobile and

139
00:04:45,810 --> 00:04:48,240
tensile light well as you may know

140
00:04:48,240 --> 00:04:50,280
tensor field already supports mobile and

141
00:04:50,280 --> 00:04:52,560
embedded development of models using the

142
00:04:52,560 --> 00:04:55,050
tensor for mobile API but going forward

143
00:04:55,050 --> 00:04:57,030
tensorflow light should really be seen

144
00:04:57,030 --> 00:04:59,340
as the evolution of tensorflow mobile

145
00:04:59,340 --> 00:05:01,500
and as it matures it will become the

146
00:05:01,500 --> 00:05:03,030
recommended solution for deploying

147
00:05:03,030 --> 00:05:04,949
models on mobile and embedded devices

148
00:05:04,949 --> 00:05:07,680
with this announcement TFI tensorflow

149
00:05:07,680 --> 00:05:09,810
light is made available as a developer

150
00:05:09,810 --> 00:05:12,240
preview and tensorflow mobile will still

151
00:05:12,240 --> 00:05:14,010
be out there to support production apps

152
00:05:14,010 --> 00:05:16,350
the scope of tensorflow Lite is quite

153
00:05:16,350 --> 00:05:19,260
large though it's huge and it's still

154
00:05:19,260 --> 00:05:20,910
under active development so the

155
00:05:20,910 --> 00:05:22,530
Developer Preview is a constrained

156
00:05:22,530 --> 00:05:24,660
platform to ensure maximum performance

157
00:05:24,660 --> 00:05:26,610
or some of the most important common

158
00:05:26,610 --> 00:05:28,500
models you mean things like Inception

159
00:05:28,500 --> 00:05:30,030
and stuff like that is correct and

160
00:05:30,030 --> 00:05:31,500
mobile net the all the different

161
00:05:31,500 --> 00:05:33,660
resolution variants of mobile net core

162
00:05:33,660 --> 00:05:36,030
but the goal for continued development

163
00:05:36,030 --> 00:05:38,880
or should poor to simplify the developer

164
00:05:38,880 --> 00:05:40,889
experience and enable model deployment

165
00:05:40,889 --> 00:05:43,320
for a wide range of mobile and embedded

166
00:05:43,320 --> 00:05:45,870
device it's nice it's really exciting

167
00:05:45,870 --> 00:05:47,430
that developers are getting their hands

168
00:05:47,430 --> 00:05:49,110
intensive for life and it's gonna be

169
00:05:49,110 --> 00:05:51,720
great to see what everyone out there can

170
00:05:51,720 --> 00:05:53,280
do with it and so that end we've

171
00:05:53,280 --> 00:05:54,690
actually produced a number of episodes

172
00:05:54,690 --> 00:05:56,639
of coding tensorflow on this very

173
00:05:56,639 --> 00:05:58,800
channel all around tensorflow lights so

174
00:05:58,800 --> 00:06:00,570
there's three in the series one is

175
00:06:00,570 --> 00:06:02,010
introducing tensorflow light how it

176
00:06:02,010 --> 00:06:03,990
works and what you can do with it One is

177
00:06:03,990 --> 00:06:05,729
using tensorflow light on Android and

178
00:06:05,729 --> 00:06:07,020
the other one is using tensorflow light

179
00:06:07,020 --> 00:06:09,690
on iOS so go check him out I think we've

180
00:06:09,690 --> 00:06:10,830
time for one more question what do you

181
00:06:10,830 --> 00:06:12,690
think now yes Lauren this one's a beauty

182
00:06:12,690 --> 00:06:14,639
it's from David McLain on Twitter and

183
00:06:14,639 --> 00:06:16,919
David has asked is there a version of

184
00:06:16,919 --> 00:06:19,800
tensorflow for Chrome OS so David I

185
00:06:19,800 --> 00:06:21,389
assume you're using a Chromebook and you

186
00:06:21,389 --> 00:06:22,800
want to start developing on tensorflow

187
00:06:22,800 --> 00:06:24,870
now instead of like hacking your

188
00:06:24,870 --> 00:06:26,250
Chromebook to put Linux on it and

189
00:06:26,250 --> 00:06:27,570
install tensorflow there's a couple of

190
00:06:27,570 --> 00:06:28,889
other good options that you should think

191
00:06:28,889 --> 00:06:30,780
about one of them is there's something

192
00:06:30,780 --> 00:06:32,490
called Cola but I've put a link to it

193
00:06:32,490 --> 00:06:34,530
below where a collab is basically a

194
00:06:34,530 --> 00:06:36,599
Jupiter notebook in the cloud and it

195
00:06:36,599 --> 00:06:38,610
supports tensorflow so you can start on

196
00:06:38,610 --> 00:06:40,710
your Chromebook in your browser

197
00:06:40,710 --> 00:06:42,390
writing and testing training some stuff

198
00:06:42,390 --> 00:06:43,650
intensive flow it's actually really

199
00:06:43,650 --> 00:06:45,360
really cool but if you want to double

200
00:06:45,360 --> 00:06:47,190
click a level beneath that you can also

201
00:06:47,190 --> 00:06:50,310
create a VM on GCE right and using the

202
00:06:50,310 --> 00:06:52,980
Google cloud platform and in that VM you

203
00:06:52,980 --> 00:06:54,360
can install Linux and you can install

204
00:06:54,360 --> 00:06:55,620
tensorflow and you can start programming

205
00:06:55,620 --> 00:06:57,960
tensorflow right away and you can shell

206
00:06:57,960 --> 00:06:59,910
into that from your Chromebook and also

207
00:06:59,910 --> 00:07:00,960
when you're doing it this way you can

208
00:07:00,960 --> 00:07:02,190
take advantage of some of the great

209
00:07:02,190 --> 00:07:04,020
hardware that's in the cloud - like GPUs

210
00:07:04,020 --> 00:07:06,210
and TP use for accelerated your learning

211
00:07:06,210 --> 00:07:07,740
I hope that really helps and I think

212
00:07:07,740 --> 00:07:09,150
there was another option right there is

213
00:07:09,150 --> 00:07:11,280
one more option or if you're a Kangol

214
00:07:11,280 --> 00:07:12,870
user you know the platform that allows

215
00:07:12,870 --> 00:07:15,300
you to test machine learning and data

216
00:07:15,300 --> 00:07:17,220
science problems on different data sets

217
00:07:17,220 --> 00:07:19,770
you should really try out kaggle kernels

218
00:07:19,770 --> 00:07:21,990
that is essentially a notebook that has

219
00:07:21,990 --> 00:07:24,330
lots of packages installed and you can

220
00:07:24,330 --> 00:07:25,980
write all your tensorflow code in there

221
00:07:25,980 --> 00:07:26,880
and try it out

222
00:07:26,880 --> 00:07:28,890
Kaggle kernels cago kernels like the

223
00:07:28,890 --> 00:07:30,630
sound of that you can see the link below

224
00:07:30,630 --> 00:07:32,520
here so thanks David and that was a

225
00:07:32,520 --> 00:07:34,380
great question so that's it for this

226
00:07:34,380 --> 00:07:36,420
episode of Oz tensorflow so some great

227
00:07:36,420 --> 00:07:37,800
questions thanks everybody

228
00:07:37,800 --> 00:07:39,360
and remember if you want us to take a

229
00:07:39,360 --> 00:07:40,560
look at your questions and have them

230
00:07:40,560 --> 00:07:42,510
featured in a future show be sure to

231
00:07:42,510 --> 00:07:44,010
post on social media and use the

232
00:07:44,010 --> 00:07:46,170
ostensive flow hashtag and we'll look

233
00:07:46,170 --> 00:07:48,520
forward to seeing them thanks everybody

234
00:07:48,520 --> 00:07:55,700
[Music]

235
00:07:55,700 --> 00:07:57,760
you

