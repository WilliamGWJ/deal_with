1
00:00:01,060 --> 00:00:01,650
[Music]

2
00:00:01,650 --> 00:00:03,319
[Applause]

3
00:00:03,319 --> 00:00:05,850
hi everybody I'm Laurence Moroney from

4
00:00:05,850 --> 00:00:07,950
the tensorflow team at Google and today

5
00:00:07,950 --> 00:00:09,420
we're going to talk about text

6
00:00:09,420 --> 00:00:11,700
classification it's part one of a

7
00:00:11,700 --> 00:00:13,679
two-part series will will focus on the

8
00:00:13,679 --> 00:00:15,750
data and getting it ready to train a

9
00:00:15,750 --> 00:00:18,660
neural network you will do this hands-on

10
00:00:18,660 --> 00:00:20,580
using a workbook that you can find at

11
00:00:20,580 --> 00:00:21,869
the link in the description below

12
00:00:21,869 --> 00:00:25,320
and I'll step you through it text

13
00:00:25,320 --> 00:00:26,580
classification has some unique

14
00:00:26,580 --> 00:00:29,250
challenges so before you get coding let

15
00:00:29,250 --> 00:00:32,009
me step you through some of these first

16
00:00:32,009 --> 00:00:34,020
of all neural networks typically deal

17
00:00:34,020 --> 00:00:36,480
with numbers are not text when learning

18
00:00:36,480 --> 00:00:38,430
patterns that can be used for prediction

19
00:00:38,430 --> 00:00:41,010
or classification so in this case we're

20
00:00:41,010 --> 00:00:42,870
looking at learning from movie reviews

21
00:00:42,870 --> 00:00:45,030
to see if those reviews are positive or

22
00:00:45,030 --> 00:00:47,219
negative and the first step of course is

23
00:00:47,219 --> 00:00:49,289
to change the words into numbers that

24
00:00:49,289 --> 00:00:51,600
represent them there'll be a little bit

25
00:00:51,600 --> 00:00:53,219
more processing of these words into

26
00:00:53,219 --> 00:00:55,289
vectors determining their sentiments and

27
00:00:55,289 --> 00:00:57,539
we'll cover that in the next video so

28
00:00:57,539 --> 00:01:00,420
let's get coding first first things

29
00:01:00,420 --> 00:01:02,190
first I'll have to check the licenses

30
00:01:02,190 --> 00:01:05,580
before I begin and now I'll import

31
00:01:05,580 --> 00:01:08,520
tensorflow and numpy I'll also use care

32
00:01:08,520 --> 00:01:10,500
Us and print out the version of

33
00:01:10,500 --> 00:01:14,549
tensorflow that I'm using okay now it's

34
00:01:14,549 --> 00:01:17,759
time to get the data set the IMDB set is

35
00:01:17,759 --> 00:01:20,040
included with care us so let's download

36
00:01:20,040 --> 00:01:21,630
it and let's take a look at what's in

37
00:01:21,630 --> 00:01:24,930
there note that in this case the nice

38
00:01:24,930 --> 00:01:26,549
folks that care us have done the work

39
00:01:26,549 --> 00:01:28,650
for us of converting the words into

40
00:01:28,650 --> 00:01:31,770
integers they've also sorted them into a

41
00:01:31,770 --> 00:01:34,470
dictionary so that lower numbers are the

42
00:01:34,470 --> 00:01:36,509
most common words and higher numbers are

43
00:01:36,509 --> 00:01:38,790
the least common words so when we loaded

44
00:01:38,790 --> 00:01:41,460
the specified 10,000 words this will

45
00:01:41,460 --> 00:01:43,890
then give us the top 10,000 words that

46
00:01:43,890 --> 00:01:46,829
are used across all of the reviews okay

47
00:01:46,829 --> 00:01:49,320
now we've loaded the data and we have

48
00:01:49,320 --> 00:01:51,479
our training data and labels as well as

49
00:01:51,479 --> 00:01:53,970
our test data and labels it's also

50
00:01:53,970 --> 00:01:56,700
nicely sorted into integers for us which

51
00:01:56,700 --> 00:01:59,399
is a great first step for learning let's

52
00:01:59,399 --> 00:02:02,280
see what the data looks like next first

53
00:02:02,280 --> 00:02:04,229
we'll look at our training data you'll

54
00:02:04,229 --> 00:02:07,020
see that we have a total of 25,000 items

55
00:02:07,020 --> 00:02:09,929
of data and 25,000 labels describing

56
00:02:09,929 --> 00:02:12,150
them the labels are very simple it's

57
00:02:12,150 --> 00:02:13,310
zero for a negative

58
00:02:13,310 --> 00:02:15,610
view and one for a positive one a

59
00:02:15,610 --> 00:02:18,739
reviews look like this it's just a long

60
00:02:18,739 --> 00:02:21,620
set of numbers and these are the indexes

61
00:02:21,620 --> 00:02:24,349
into the array of words the review will

62
00:02:24,349 --> 00:02:26,690
start with a 1 indicating the start of

63
00:02:26,690 --> 00:02:29,060
the review so the first word in the

64
00:02:29,060 --> 00:02:31,519
review is word number 14 which

65
00:02:31,519 --> 00:02:34,190
translates to the word this followed by

66
00:02:34,190 --> 00:02:37,250
the value 22 which translates to the

67
00:02:37,250 --> 00:02:40,310
word film the next bit of code is then a

68
00:02:40,310 --> 00:02:42,319
handy-dandy way of decoding the review

69
00:02:42,319 --> 00:02:44,870
note that the values zero through three

70
00:02:44,870 --> 00:02:47,330
are reserved with one being the start of

71
00:02:47,330 --> 00:02:48,890
the review as we mentioned a moment ago

72
00:02:48,890 --> 00:02:51,709
and zero is for padding now this is

73
00:02:51,709 --> 00:02:53,000
important and you'll see that in a

74
00:02:53,000 --> 00:02:53,420
moment

75
00:02:53,420 --> 00:02:56,840
I can now decode the review and see that

76
00:02:56,840 --> 00:02:57,430
one

77
00:02:57,430 --> 00:03:01,340
14:22 other start character and this and

78
00:03:01,340 --> 00:03:03,910
then film it's pretty cool right

79
00:03:03,910 --> 00:03:07,190
now earlier I skipped over this piece of

80
00:03:07,190 --> 00:03:09,560
code showing me the length of the review

81
00:03:09,560 --> 00:03:12,980
so for example the first movie was 218

82
00:03:12,980 --> 00:03:16,459
words long and the second was 189 words

83
00:03:16,459 --> 00:03:19,070
long now that's really awkward and it's

84
00:03:19,070 --> 00:03:21,290
confusing to train a neural network if

85
00:03:21,290 --> 00:03:23,090
all of the training data is of different

86
00:03:23,090 --> 00:03:25,370
lengths so let's pick a standard length

87
00:03:25,370 --> 00:03:27,350
for every review and if it's longer

88
00:03:27,350 --> 00:03:29,450
we'll trim it to that length and if it's

89
00:03:29,450 --> 00:03:31,940
shorter we'll pad it to that length the

90
00:03:31,940 --> 00:03:33,890
Charis pre-processing api's make this

91
00:03:33,890 --> 00:03:36,739
really easy here you can see I'm taking

92
00:03:36,739 --> 00:03:38,780
the training and test data and making

93
00:03:38,780 --> 00:03:42,049
sure it's 256 words long if I need to

94
00:03:42,049 --> 00:03:43,819
pad it then I'll pad it with the pad

95
00:03:43,819 --> 00:03:45,920
character which is the 0 that we saw

96
00:03:45,920 --> 00:03:48,769
earlier a quick look will now show that

97
00:03:48,769 --> 00:03:51,910
it worked they're all 256 words long and

98
00:03:51,910 --> 00:03:54,350
if I now look at my first set of

99
00:03:54,350 --> 00:03:56,359
training data you'll see that it's

100
00:03:56,359 --> 00:03:59,329
padded by zeros remember it had been 218

101
00:03:59,329 --> 00:04:00,139
words long

102
00:04:00,139 --> 00:04:02,120
so the extras get patted out to make it

103
00:04:02,120 --> 00:04:05,840
256 great our training and test data is

104
00:04:05,840 --> 00:04:08,540
now ready so in the next episode you'll

105
00:04:08,540 --> 00:04:10,280
take a look at how to design a neural

106
00:04:10,280 --> 00:04:12,889
network to accept this data and to train

107
00:04:12,889 --> 00:04:14,780
a model to determine the sentiment of

108
00:04:14,780 --> 00:04:18,070
movie reviews I'll see you there

109
00:04:18,070 --> 00:04:19,190
[Music]

110
00:04:19,190 --> 00:04:19,839
you

111
00:04:19,839 --> 00:04:24,459
[Music]

