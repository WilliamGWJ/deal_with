1
00:00:03,259 --> 00:00:05,549
hey everyone my name is Josh Gordon and

2
00:00:05,549 --> 00:00:08,189
I'm here today with jayjay Oler and JJ

3
00:00:08,189 --> 00:00:10,469
is the founder of art studio and he

4
00:00:10,469 --> 00:00:12,389
recently added support for tensorflow

5
00:00:12,389 --> 00:00:15,719
and care us to our so JJ thank you very

6
00:00:15,719 --> 00:00:16,980
much for coming on the show thank you

7
00:00:16,980 --> 00:00:18,240
and could you tell me a little bit about

8
00:00:18,240 --> 00:00:19,310
the work you've done absolutely

9
00:00:19,310 --> 00:00:20,580
tensorflow

10
00:00:20,580 --> 00:00:22,529
came out I think about two and a half

11
00:00:22,529 --> 00:00:25,500
years ago and from the day that it came

12
00:00:25,500 --> 00:00:26,849
out I've been excited about what we

13
00:00:26,849 --> 00:00:29,490
could do with tensorflow from our our

14
00:00:29,490 --> 00:00:31,679
the art community is filled of people

15
00:00:31,679 --> 00:00:33,300
who are not they don't self-identify as

16
00:00:33,300 --> 00:00:35,190
software developers they identify as

17
00:00:35,190 --> 00:00:36,899
statisticians or economists or

18
00:00:36,899 --> 00:00:39,989
biologists and the interfaces we build

19
00:00:39,989 --> 00:00:42,540
to modeling and statistics from are tend

20
00:00:42,540 --> 00:00:44,100
to be really fluent high-level

21
00:00:44,100 --> 00:00:46,230
interfaces that kind of are really well

22
00:00:46,230 --> 00:00:47,969
married to the vocabulary of the domain

23
00:00:47,969 --> 00:00:49,289
that people are doing work in and so

24
00:00:49,289 --> 00:00:51,660
tensorflow brings this awesome

25
00:00:51,660 --> 00:00:53,879
capability for neural networks and even

26
00:00:53,879 --> 00:00:55,320
just as a general-purpose numerical

27
00:00:55,320 --> 00:00:57,690
computing framework and I thought wow we

28
00:00:57,690 --> 00:00:59,760
can do incredible things from our to

29
00:00:59,760 --> 00:01:01,260
make all this power available to all

30
00:01:01,260 --> 00:01:03,120
these people solving solving heart

31
00:01:03,120 --> 00:01:05,970
problems then particularly the the

32
00:01:05,970 --> 00:01:07,560
Charis interface which I hope we get to

33
00:01:07,560 --> 00:01:10,380
talk about a little bit more is a really

34
00:01:10,380 --> 00:01:12,119
nice high-level vocabulary for doing

35
00:01:12,119 --> 00:01:14,549
deep learning that fits really well with

36
00:01:14,549 --> 00:01:17,220
the way our users work and think and so

37
00:01:17,220 --> 00:01:19,380
I was excited to both can make the core

38
00:01:19,380 --> 00:01:21,150
capabilities of tensorflow available but

39
00:01:21,150 --> 00:01:23,040
then also to make the Charis API

40
00:01:23,040 --> 00:01:25,020
available that's one thing you did too

41
00:01:25,020 --> 00:01:26,340
is you contributed some really great

42
00:01:26,340 --> 00:01:29,040
educational resources especially yes so

43
00:01:29,040 --> 00:01:30,900
we probably spent as much or more time

44
00:01:30,900 --> 00:01:32,909
on educational resources as we did on

45
00:01:32,909 --> 00:01:35,670
the actual interfaces so I worked on a

46
00:01:35,670 --> 00:01:38,790
book along with Francois shalay about

47
00:01:38,790 --> 00:01:40,890
deep learning with art adapted his deep

48
00:01:40,890 --> 00:01:42,479
learning with Python book Francois is

49
00:01:42,479 --> 00:01:45,119
actually the creator of Karass so worked

50
00:01:45,119 --> 00:01:47,729
on that book we created a whole bunch of

51
00:01:47,729 --> 00:01:51,270
examples probably 25 or so examples of

52
00:01:51,270 --> 00:01:52,770
using Kerris and many many other

53
00:01:52,770 --> 00:01:55,740
examples we created a gallery of kind of

54
00:01:55,740 --> 00:01:57,659
longer form blog posts that describe

55
00:01:57,659 --> 00:02:00,299
like really in-depth worked examples in

56
00:02:00,299 --> 00:02:02,729
different domains so we have invested a

57
00:02:02,729 --> 00:02:04,680
huge amount in educational resources and

58
00:02:04,680 --> 00:02:06,030
are going to continue to do that and

59
00:02:06,030 --> 00:02:08,129
this book is excellent the book is

60
00:02:08,129 --> 00:02:10,530
awesome yes I've read the Python version

61
00:02:10,530 --> 00:02:11,459
cover-to-cover

62
00:02:11,459 --> 00:02:12,090
yep

63
00:02:12,090 --> 00:02:13,920
I taught a class with it students loved

64
00:02:13,920 --> 00:02:15,480
it I strongly recommend it to all the

65
00:02:15,480 --> 00:02:16,890
developers I meet what's remarkable

66
00:02:16,890 --> 00:02:19,110
about it is that it covers the concepts

67
00:02:19,110 --> 00:02:20,819
the conceptual terrain of deep learning

68
00:02:20,819 --> 00:02:23,519
in a way that's I think it's really

69
00:02:23,519 --> 00:02:25,110
intuitive for people to understand was

70
00:02:25,110 --> 00:02:27,420
not not a huge number of prerequisites

71
00:02:27,420 --> 00:02:30,330
but it also has a wealth of practical

72
00:02:30,330 --> 00:02:31,890
information about how to actually do

73
00:02:31,890 --> 00:02:34,290
deep learning what are the small

74
00:02:34,290 --> 00:02:36,690
problems you come up with what are the

75
00:02:36,690 --> 00:02:38,400
failure modes and how to overcome them

76
00:02:38,400 --> 00:02:40,920
so it's just it's a rare book that

77
00:02:40,920 --> 00:02:42,810
combines kind of conceptual material and

78
00:02:42,810 --> 00:02:44,970
practical material and so I I recommend

79
00:02:44,970 --> 00:02:47,310
that as the first thing that people who

80
00:02:47,310 --> 00:02:48,299
are in the art community and they say I

81
00:02:48,299 --> 00:02:49,530
want to learn more about this I

82
00:02:49,530 --> 00:02:51,180
recommend that they get that book and

83
00:02:51,180 --> 00:02:53,010
read it first it's probably a lot of

84
00:02:53,010 --> 00:02:55,769
work porting that over to our yeah it

85
00:02:55,769 --> 00:02:57,090
was but most of the book is

86
00:02:57,090 --> 00:02:59,010
predominantly conceptual and then there

87
00:02:59,010 --> 00:03:01,230
are these examples and so I really just

88
00:03:01,230 --> 00:03:03,360
changed the examples but really most of

89
00:03:03,360 --> 00:03:05,400
the book is ends up being conceptual it

90
00:03:05,400 --> 00:03:07,530
kind of at a higher level of the

91
00:03:07,530 --> 00:03:09,930
specific languages so it wasn't too bad

92
00:03:09,930 --> 00:03:11,340
and then another thing you have on the

93
00:03:11,340 --> 00:03:12,870
our website the our city website which

94
00:03:12,870 --> 00:03:14,730
is really cool is worked and end

95
00:03:14,730 --> 00:03:16,859
examples that's right we have a gallery

96
00:03:16,859 --> 00:03:18,690
where we don't just show you here's the

97
00:03:18,690 --> 00:03:20,250
mechanics of solving a certain type of

98
00:03:20,250 --> 00:03:21,959
problem but we go kind of from the

99
00:03:21,959 --> 00:03:23,730
beginning here's the motivation here's

100
00:03:23,730 --> 00:03:25,350
the data set maybe let's visualize the

101
00:03:25,350 --> 00:03:26,519
data set a little bit

102
00:03:26,519 --> 00:03:28,410
let's try different approaches to the

103
00:03:28,410 --> 00:03:29,430
problem and see what works and doesn't

104
00:03:29,430 --> 00:03:33,359
work so we we kind of cover and and like

105
00:03:33,359 --> 00:03:35,130
what a what the workflow of a data

106
00:03:35,130 --> 00:03:38,250
scientists would go through to solve

107
00:03:38,250 --> 00:03:39,750
these problems so and well again we're

108
00:03:39,750 --> 00:03:40,739
gonna be investing in more of those

109
00:03:40,739 --> 00:03:41,849
because I think that's the way that

110
00:03:41,849 --> 00:03:43,680
people can really get engaged with this

111
00:03:43,680 --> 00:03:46,139
is not just learning the basic mechanics

112
00:03:46,139 --> 00:03:48,359
and concepts but seeing how it actually

113
00:03:48,359 --> 00:03:49,410
applies to their field

114
00:03:49,410 --> 00:03:51,299
I like this combination a lot yes to

115
00:03:51,299 --> 00:03:52,319
really solid set of learning resources

116
00:03:52,319 --> 00:03:54,359
good so in addition to supporting care

117
00:03:54,359 --> 00:03:56,280
us you also have support for tensorflow

118
00:03:56,280 --> 00:03:58,200
estimators yes we have another our

119
00:03:58,200 --> 00:04:00,239
package there's actually a suite of

120
00:04:00,239 --> 00:04:01,889
7-hour packages that we have for

121
00:04:01,889 --> 00:04:03,540
tensorflow there's our package called

122
00:04:03,540 --> 00:04:04,889
tensorflow which is a low-level

123
00:04:04,889 --> 00:04:06,419
interface to the full tensor flow graph

124
00:04:06,419 --> 00:04:08,280
and the full potential api there's the

125
00:04:08,280 --> 00:04:09,480
Charis a path which we've been talking

126
00:04:09,480 --> 00:04:10,829
about and then we have tensorflow

127
00:04:10,829 --> 00:04:13,139
estimators which is another high level

128
00:04:13,139 --> 00:04:15,660
framework that Google has for doing

129
00:04:15,660 --> 00:04:17,489
models like classification and

130
00:04:17,489 --> 00:04:19,590
regression models classification and

131
00:04:19,590 --> 00:04:21,959
regression using DNS and so there's a

132
00:04:21,959 --> 00:04:24,510
really really high level functions that

133
00:04:24,510 --> 00:04:25,830
come with a nice framework for

134
00:04:25,830 --> 00:04:27,659
for data pre-processing and things and a

135
00:04:27,659 --> 00:04:29,520
nice framework for deploying the models

136
00:04:29,520 --> 00:04:31,349
so we have another package called TF

137
00:04:31,349 --> 00:04:33,930
estimators that covers that covers the

138
00:04:33,930 --> 00:04:36,030
estimators API deployment is it's really

139
00:04:36,030 --> 00:04:37,409
important to have as well it is and

140
00:04:37,409 --> 00:04:39,569
that's one of the things that I'm most

141
00:04:39,569 --> 00:04:42,180
excited about because traditionally with

142
00:04:42,180 --> 00:04:44,430
our when you do modeling and then you

143
00:04:44,430 --> 00:04:46,080
want to deploy the model in some fashion

144
00:04:46,080 --> 00:04:48,449
you have to bring the our runtime along

145
00:04:48,449 --> 00:04:50,250
with you and that can be a challenge so

146
00:04:50,250 --> 00:04:53,190
what the the design of tensorflow is

147
00:04:53,190 --> 00:04:54,870
that you're writing a program but that

148
00:04:54,870 --> 00:04:56,460
program is creating a graph and that

149
00:04:56,460 --> 00:04:59,190
graph is executed by a runtime a C++

150
00:04:59,190 --> 00:05:01,409
runtime so deploying models doesn't

151
00:05:01,409 --> 00:05:03,360
require that you bring R or Python or

152
00:05:03,360 --> 00:05:05,250
any these sorts of language that you

153
00:05:05,250 --> 00:05:08,879
languages that you used to model in to

154
00:05:08,879 --> 00:05:11,129
deployment and so we have another

155
00:05:11,129 --> 00:05:13,080
package called TF deploy that helps

156
00:05:13,080 --> 00:05:15,330
people with sort of serializing they're

157
00:05:15,330 --> 00:05:18,270
saved models putting rest interfaces on

158
00:05:18,270 --> 00:05:22,280
top of their saved models getting models

159
00:05:22,280 --> 00:05:24,750
actually brought into JavaScript there's

160
00:05:24,750 --> 00:05:26,879
the library called Kara CAS that let you

161
00:05:26,879 --> 00:05:28,289
take a Karass model and run it in a

162
00:05:28,289 --> 00:05:30,569
browser so we've got lots of tools for

163
00:05:30,569 --> 00:05:31,620
that and that's actually one of the most

164
00:05:31,620 --> 00:05:33,569
exciting things about tensorflow is that

165
00:05:33,569 --> 00:05:36,210
is this deployment model so tensorflow

166
00:05:36,210 --> 00:05:39,779
j/s ok supports a chaos' compatible api

167
00:05:39,779 --> 00:05:41,460
ok and i believe what this means is that

168
00:05:41,460 --> 00:05:43,380
people will be able to author models in

169
00:05:43,380 --> 00:05:45,090
our that's right using the chaos

170
00:05:45,090 --> 00:05:46,500
interface that's right and then deploy

171
00:05:46,500 --> 00:05:47,669
them and deploy them right into a

172
00:05:47,669 --> 00:05:49,710
browser yeah that's gonna be huge it's

173
00:05:49,710 --> 00:05:51,840
phenomenal yeah so I think a lot of

174
00:05:51,840 --> 00:05:52,710
people in the our community that I've

175
00:05:52,710 --> 00:05:54,240
taught I mean all communities I think

176
00:05:54,240 --> 00:05:55,979
this is such a fundamentally good idea

177
00:05:55,979 --> 00:05:58,650
to take models and serialize them into

178
00:05:58,650 --> 00:06:01,319
this runtime format that doesn't because

179
00:06:01,319 --> 00:06:03,090
the the languages and tools that are

180
00:06:03,090 --> 00:06:04,580
good for training you know for

181
00:06:04,580 --> 00:06:07,050
exploratory data analysis training

182
00:06:07,050 --> 00:06:08,669
models authoring models which are

183
00:06:08,669 --> 00:06:09,900
different than languages that are good

184
00:06:09,900 --> 00:06:11,729
for deployment it's a really good

185
00:06:11,729 --> 00:06:13,560
division of responsibilities that

186
00:06:13,560 --> 00:06:16,020
tensorflow kind of enforces and so I'm

187
00:06:16,020 --> 00:06:18,330
hopeful that our users who want to put

188
00:06:18,330 --> 00:06:19,770
their models in production now will have

189
00:06:19,770 --> 00:06:21,210
a really straightforward way to do that

190
00:06:21,210 --> 00:06:22,710
I think so too and it's a really good

191
00:06:22,710 --> 00:06:24,539
opportunity for data scientists to

192
00:06:24,539 --> 00:06:26,310
visualize the results of their

193
00:06:26,310 --> 00:06:27,629
experiments I actually deploy the

194
00:06:27,629 --> 00:06:30,029
toggles yeah yeah so say I'm an our

195
00:06:30,029 --> 00:06:32,550
developer new to deep learning about how

196
00:06:32,550 --> 00:06:34,409
much code is it going to take for me to

197
00:06:34,409 --> 00:06:36,000
write my first neural network well

198
00:06:36,000 --> 00:06:37,289
interestingly if you look at our

199
00:06:37,289 --> 00:06:39,120
examples that the hard part about deep

200
00:06:39,120 --> 00:06:39,330
learn

201
00:06:39,330 --> 00:06:42,210
is not generally writing the code and

202
00:06:42,210 --> 00:06:44,639
you know many of our examples are on the

203
00:06:44,639 --> 00:06:46,680
order of a hundred lines of code or even

204
00:06:46,680 --> 00:06:48,689
even less than that sometimes the hard

205
00:06:48,689 --> 00:06:50,639
part is actually figuring out what sort

206
00:06:50,639 --> 00:06:52,800
of model to build and how it should what

207
00:06:52,800 --> 00:06:54,090
the architecture of the model should be

208
00:06:54,090 --> 00:06:55,199
and what the hyper parameters of the

209
00:06:55,199 --> 00:06:56,789
mouth should be that's where all the

210
00:06:56,789 --> 00:06:59,250
time is the actual expression of the

211
00:06:59,250 --> 00:07:01,370
model and code is actually quite trivial

212
00:07:01,370 --> 00:07:03,900
but model and model building really ends

213
00:07:03,900 --> 00:07:05,689
up being not about the code but about

214
00:07:05,689 --> 00:07:09,060
about mapping your problem and the data

215
00:07:09,060 --> 00:07:11,340
and the tools you have together to get a

216
00:07:11,340 --> 00:07:13,110
good solution I completely agree it's

217
00:07:13,110 --> 00:07:14,340
well put and I think a lot of people

218
00:07:14,340 --> 00:07:15,870
from the art community especially from a

219
00:07:15,870 --> 00:07:17,789
stats and data science background will

220
00:07:17,789 --> 00:07:19,139
be natural the background and training

221
00:07:19,139 --> 00:07:21,289
of people in the art community the the

222
00:07:21,289 --> 00:07:23,219
the understanding how to do modeling

223
00:07:23,219 --> 00:07:26,940
statistics probability is perfect for

224
00:07:26,940 --> 00:07:28,860
for deep learning and I'm really excited

225
00:07:28,860 --> 00:07:30,300
once more people in the art community

226
00:07:30,300 --> 00:07:32,520
get get their hands on these tools of

227
00:07:32,520 --> 00:07:35,190
the kind of work that we're gonna see me

228
00:07:35,190 --> 00:07:35,520
too

229
00:07:35,520 --> 00:07:37,020
so JJ thanks again for coming on the

230
00:07:37,020 --> 00:07:39,629
show really appreciate it then just to

231
00:07:39,629 --> 00:07:41,520
close things out where's the best place

232
00:07:41,520 --> 00:07:42,870
for developers to go to learn more about

233
00:07:42,870 --> 00:07:45,539
deep learning in our the best place we

234
00:07:45,539 --> 00:07:47,129
have a website called tensorflow

235
00:07:47,129 --> 00:07:50,310
that our studio com it has documentation

236
00:07:50,310 --> 00:07:52,259
for all the packages as I talked about

237
00:07:52,259 --> 00:07:54,509
Kerris and estimators and and the core

238
00:07:54,509 --> 00:07:56,789
tensorflow api as information about

239
00:07:56,789 --> 00:07:59,129
deployment it has a gallery of in-depth

240
00:07:59,129 --> 00:08:02,520
examples kind of blog posts it has a

241
00:08:02,520 --> 00:08:04,199
whole bunch of additional learning

242
00:08:04,199 --> 00:08:06,599
resources so tensorflow down our studio

243
00:08:06,599 --> 00:08:08,339
comm is definitely the place to go to to

244
00:08:08,339 --> 00:08:10,139
get started ok thanks again really

245
00:08:10,139 --> 00:08:15,330
appreciate it thanks

246
00:08:15,330 --> 00:08:17,389
you

