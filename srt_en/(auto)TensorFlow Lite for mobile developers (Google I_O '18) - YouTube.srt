1
00:00:04,970 --> 00:00:07,470
thank you so much for coming to our

2
00:00:07,470 --> 00:00:10,650
session this morning I'm Sarah Sarah

3
00:00:10,650 --> 00:00:13,230
Javon I'm on the tensorflow Lite team

4
00:00:13,230 --> 00:00:16,260
and we work on bringing machine learning

5
00:00:16,260 --> 00:00:19,740
to mobile and small devices and later on

6
00:00:19,740 --> 00:00:21,990
I will introduce my colleague Andrew

7
00:00:21,990 --> 00:00:23,850
celli who will be doing the second half

8
00:00:23,850 --> 00:00:27,630
of this talk so the last couple of days

9
00:00:27,630 --> 00:00:30,359
have been really fun for me I've gotten

10
00:00:30,359 --> 00:00:32,669
to meet and speak with many of you and

11
00:00:32,669 --> 00:00:35,610
it's been really nice to see the

12
00:00:35,610 --> 00:00:38,149
excitement around tensorflow light and

13
00:00:38,149 --> 00:00:41,700
today I'm happy to be here and talk to

14
00:00:41,700 --> 00:00:44,160
you about all the work that our team is

15
00:00:44,160 --> 00:00:46,710
doing to make machine learning on small

16
00:00:46,710 --> 00:00:51,120
devices possible and easy so in today's

17
00:00:51,120 --> 00:00:54,629
talk we'll cover three areas first we'll

18
00:00:54,629 --> 00:00:57,329
talk about why machine learning directly

19
00:00:57,329 --> 00:01:00,120
on device is important and how it's

20
00:01:00,120 --> 00:01:02,129
different than what you may do on the

21
00:01:02,129 --> 00:01:05,010
server second we'll walk you through

22
00:01:05,010 --> 00:01:07,080
what we have built with tons of low

23
00:01:07,080 --> 00:01:09,930
light and lastly we'll show you how you

24
00:01:09,930 --> 00:01:11,820
can use sense of low light in your own

25
00:01:11,820 --> 00:01:16,590
apps so first let's talk about devices

26
00:01:16,590 --> 00:01:19,259
for a bit what do we mean when we say a

27
00:01:19,259 --> 00:01:20,670
device well

28
00:01:20,670 --> 00:01:23,070
usually a mobile device basically our

29
00:01:23,070 --> 00:01:26,759
phones so our phones are with us all the

30
00:01:26,759 --> 00:01:30,030
time we interact with them so many times

31
00:01:30,030 --> 00:01:33,180
during the day and modern phones come

32
00:01:33,180 --> 00:01:35,460
with a large number of sensors on them

33
00:01:35,460 --> 00:01:38,549
which give us really rich data about the

34
00:01:38,549 --> 00:01:42,210
physical world around us another

35
00:01:42,210 --> 00:01:45,000
category of devices is what we call edge

36
00:01:45,000 --> 00:01:48,149
devices and this industry has seen a

37
00:01:48,149 --> 00:01:50,970
huge explosion in the last few years so

38
00:01:50,970 --> 00:01:53,850
some examples are smart speakers smart

39
00:01:53,850 --> 00:01:58,079
watches smart cameras and as this market

40
00:01:58,079 --> 00:02:00,840
has grown we see that technology which

41
00:02:00,840 --> 00:02:02,729
only used to be available on more

42
00:02:02,729 --> 00:02:06,000
expensive devices is now available on

43
00:02:06,000 --> 00:02:10,140
far cheaper ones so now we are seeing

44
00:02:10,140 --> 00:02:11,760
that there is this massive growth in

45
00:02:11,760 --> 00:02:14,030
devices they're becoming in

46
00:02:14,030 --> 00:02:17,270
freezingly capable both mobile and edge

47
00:02:17,270 --> 00:02:19,700
and this is opening up many

48
00:02:19,700 --> 00:02:22,610
opportunities for novel applications of

49
00:02:22,610 --> 00:02:27,319
for machine learning so I expect that

50
00:02:27,319 --> 00:02:29,569
many of you are already familiar with

51
00:02:29,569 --> 00:02:32,360
the basic idea of machine learning but

52
00:02:32,360 --> 00:02:33,950
for those that aren't I'm going to

53
00:02:33,950 --> 00:02:37,550
really quickly cover the core concept so

54
00:02:37,550 --> 00:02:39,680
let's start with an example of something

55
00:02:39,680 --> 00:02:41,720
that we may want to do let's say

56
00:02:41,720 --> 00:02:44,989
classification of images so how do we do

57
00:02:44,989 --> 00:02:48,110
this so in the past what we would have

58
00:02:48,110 --> 00:02:51,590
done was to write a lot of rules that

59
00:02:51,590 --> 00:02:55,130
were hard coded very specific about some

60
00:02:55,130 --> 00:02:56,930
specific characteristics that we

61
00:02:56,930 --> 00:03:00,010
expected to see in parts of the image

62
00:03:00,010 --> 00:03:03,769
this was time consuming hard to do and

63
00:03:03,769 --> 00:03:06,010
frankly didn't work all that well and

64
00:03:06,010 --> 00:03:09,160
this is where machine learning comes in

65
00:03:09,160 --> 00:03:11,480
we with machine learning we learned

66
00:03:11,480 --> 00:03:14,390
based on examples so a simple way to

67
00:03:14,390 --> 00:03:16,370
think about machine learning is that we

68
00:03:16,370 --> 00:03:19,340
use algorithms to learn from data and

69
00:03:19,340 --> 00:03:22,670
then we make predictions about similar

70
00:03:22,670 --> 00:03:25,340
data that has not been seen before so

71
00:03:25,340 --> 00:03:27,590
it's a two-step process first the model

72
00:03:27,590 --> 00:03:29,810
learns and then we use it to make

73
00:03:29,810 --> 00:03:32,660
predictions the process of model

74
00:03:32,660 --> 00:03:34,220
learning is what we typically call

75
00:03:34,220 --> 00:03:36,410
training and when the model is making

76
00:03:36,410 --> 00:03:38,840
predictions about data is what we call

77
00:03:38,840 --> 00:03:44,120
inference this is a high-level view of

78
00:03:44,120 --> 00:03:46,459
what's happening during training the

79
00:03:46,459 --> 00:03:49,070
model is passed in label data that is

80
00:03:49,070 --> 00:03:51,049
input data along with The Associated

81
00:03:51,049 --> 00:03:54,799
prediction and since in this case we

82
00:03:54,799 --> 00:03:57,200
know what the right answer is we are

83
00:03:57,200 --> 00:04:00,230
able to calculate the error that is how

84
00:04:00,230 --> 00:04:02,209
many times is the model getting it wrong

85
00:04:02,209 --> 00:04:06,200
and by how much we use these errors to

86
00:04:06,200 --> 00:04:08,959
improve the model and this process is

87
00:04:08,959 --> 00:04:11,630
repeated many many times until we reach

88
00:04:11,630 --> 00:04:13,370
the point that we think that the model

89
00:04:13,370 --> 00:04:15,890
is good enough or that this is the best

90
00:04:15,890 --> 00:04:19,160
that we can do this involves a lot of

91
00:04:19,160 --> 00:04:21,919
steps and coordination and that is why

92
00:04:21,919 --> 00:04:24,750
we need a framework to make this easier

93
00:04:24,750 --> 00:04:28,509
and this is where tensorflow comes in

94
00:04:28,509 --> 00:04:30,970
it's Google's framework for machine

95
00:04:30,970 --> 00:04:34,449
learning it makes it easy to train and

96
00:04:34,449 --> 00:04:38,169
build neural networks and it is

97
00:04:38,169 --> 00:04:41,530
cross-platform it works on CPUs GPUs TP

98
00:04:41,530 --> 00:04:43,720
use as well as mobile and embedded

99
00:04:43,720 --> 00:04:46,210
platforms and the mobile and embedded

100
00:04:46,210 --> 00:04:47,710
piece of tensorflow

101
00:04:47,710 --> 00:04:50,590
which we call tensorflow lite is what we

102
00:04:50,590 --> 00:04:52,330
are going to be focusing on in our talk

103
00:04:52,330 --> 00:04:56,560
today so now we want to talk about why

104
00:04:56,560 --> 00:04:58,240
would you consider doing machine

105
00:04:58,240 --> 00:05:01,060
learning directly on device and there

106
00:05:01,060 --> 00:05:02,889
are several reasons that you may

107
00:05:02,889 --> 00:05:05,830
consider but probably the most important

108
00:05:05,830 --> 00:05:09,370
one is latency if the processing is

109
00:05:09,370 --> 00:05:10,930
happening on the device then you're not

110
00:05:10,930 --> 00:05:12,610
sending data back and forth to the

111
00:05:12,610 --> 00:05:15,759
server so if your use case involves real

112
00:05:15,759 --> 00:05:18,729
time processing of data such as audio or

113
00:05:18,729 --> 00:05:20,530
video then it's quite likely that you

114
00:05:20,530 --> 00:05:24,460
would consider doing this other reasons

115
00:05:24,460 --> 00:05:27,849
are that your processing can happen even

116
00:05:27,849 --> 00:05:29,919
when your device is not connected on to

117
00:05:29,919 --> 00:05:34,090
the Internet the data stays on device

118
00:05:34,090 --> 00:05:36,550
this is really useful if you're working

119
00:05:36,550 --> 00:05:38,469
with sensitive user data which you don't

120
00:05:38,469 --> 00:05:42,370
want to put on servers it's more power

121
00:05:42,370 --> 00:05:44,650
efficient because your device is not

122
00:05:44,650 --> 00:05:47,169
spending power transmitting data back

123
00:05:47,169 --> 00:05:50,289
and forth and lastly we are in a

124
00:05:50,289 --> 00:05:52,479
position to take advantage of all the

125
00:05:52,479 --> 00:05:54,909
sensor data that's already available and

126
00:05:54,909 --> 00:05:59,139
accessible on the device so this is all

127
00:05:59,139 --> 00:06:02,050
great but there's a catch like there

128
00:06:02,050 --> 00:06:05,500
always is and the catch is that doing on

129
00:06:05,500 --> 00:06:09,159
device ml is hard many of these devices

130
00:06:09,159 --> 00:06:12,039
have some pretty tight constraints they

131
00:06:12,039 --> 00:06:15,039
have small batteries tight memory and

132
00:06:15,039 --> 00:06:18,250
very little computation power tensorflow

133
00:06:18,250 --> 00:06:20,710
was built for processing on the server

134
00:06:20,710 --> 00:06:23,349
and it wasn't a great fit for these use

135
00:06:23,349 --> 00:06:26,139
cases and that is the reason that we

136
00:06:26,139 --> 00:06:28,270
built tensorflow light it's a

137
00:06:28,270 --> 00:06:28,779
lightweight

138
00:06:28,779 --> 00:06:31,180
machine learning library for mobile and

139
00:06:31,180 --> 00:06:34,750
embedded platforms so this is a

140
00:06:34,750 --> 00:06:37,029
high-level overview of the system it

141
00:06:37,029 --> 00:06:38,250
consists of a kind

142
00:06:38,250 --> 00:06:41,350
where we convert models from tensorflow

143
00:06:41,350 --> 00:06:43,630
format to tons of low light format and

144
00:06:43,630 --> 00:06:46,360
for efficiency reasons we use a format

145
00:06:46,360 --> 00:06:50,350
which is different then it consists of

146
00:06:50,350 --> 00:06:52,090
an interpreter which runs on device

147
00:06:52,090 --> 00:06:54,820
there are a library of ups and kernels

148
00:06:54,820 --> 00:06:57,580
and then we have api's which allow us to

149
00:06:57,580 --> 00:06:59,830
take advantage of hardware acceleration

150
00:06:59,830 --> 00:07:04,030
whenever it is available tensorflow Lite

151
00:07:04,030 --> 00:07:06,190
is cross-platform so it works on Android

152
00:07:06,190 --> 00:07:10,780
iOS Linux and a high level developer

153
00:07:10,780 --> 00:07:13,330
workflow here would be to take a train

154
00:07:13,330 --> 00:07:15,910
tensorflow model converted to tensorflow

155
00:07:15,910 --> 00:07:19,120
Lite format and then update your apps to

156
00:07:19,120 --> 00:07:21,130
use the tensorflow Lite interpreter

157
00:07:21,130 --> 00:07:25,830
using the appropriate API an iOS

158
00:07:25,830 --> 00:07:28,480
developers also have the option of using

159
00:07:28,480 --> 00:07:31,060
core ml instead and what they would do

160
00:07:31,060 --> 00:07:33,400
here is to take their train tensorflow

161
00:07:33,400 --> 00:07:36,430
model and convert it to core ml using

162
00:07:36,430 --> 00:07:38,500
the tensorflow - core mm converter and

163
00:07:38,500 --> 00:07:40,840
then use the converted model with the

164
00:07:40,840 --> 00:07:45,370
core ml runtime so the two common

165
00:07:45,370 --> 00:07:47,650
questions that we get when we talk to

166
00:07:47,650 --> 00:07:49,990
developers about tensorflow Lite is is

167
00:07:49,990 --> 00:07:53,620
it small and is it fast so let's talk

168
00:07:53,620 --> 00:07:56,290
about the first question one of our

169
00:07:56,290 --> 00:07:58,210
fundamental design goals with tensorflow

170
00:07:58,210 --> 00:08:01,030
Lite was to keep the memory and binary

171
00:08:01,030 --> 00:08:05,290
size small and I'm happy to say that the

172
00:08:05,290 --> 00:08:08,500
size of our core interpreter is only 75

173
00:08:08,500 --> 00:08:11,350
kilobytes and when you include all the

174
00:08:11,350 --> 00:08:13,630
support adopts this size is 400

175
00:08:13,630 --> 00:08:18,130
kilobytes so how did we do this so first

176
00:08:18,130 --> 00:08:20,290
of all we've been really careful about

177
00:08:20,290 --> 00:08:23,530
which dependencies we include secondly

178
00:08:23,530 --> 00:08:25,780
tensorflow light uses flood buffers

179
00:08:25,780 --> 00:08:27,790
which are far more memory efficient than

180
00:08:27,790 --> 00:08:30,520
protocol buffers are one other feature

181
00:08:30,520 --> 00:08:32,380
that I want to call out here intensive

182
00:08:32,380 --> 00:08:33,849
low light is what we call selective

183
00:08:33,849 --> 00:08:37,210
registration and that allows developers

184
00:08:37,210 --> 00:08:39,520
to only use the ops that their model

185
00:08:39,520 --> 00:08:41,620
needs and thus they can keep the

186
00:08:41,620 --> 00:08:46,240
footprint small now moving on to the

187
00:08:46,240 --> 00:08:49,120
second question which is of speed so we

188
00:08:49,120 --> 00:08:51,310
made several design choices throughout

189
00:08:51,310 --> 00:08:52,030
the system

190
00:08:52,030 --> 00:08:55,690
to enable fast start of low latency and

191
00:08:55,690 --> 00:08:59,440
high throughput so let's start with the

192
00:08:59,440 --> 00:09:02,320
model file format tensorflow light uses

193
00:09:02,320 --> 00:09:05,200
flatbuffers like I said and flatbuffers

194
00:09:05,200 --> 00:09:07,060
is a cross-platform

195
00:09:07,060 --> 00:09:10,060
efficient serialization library it was

196
00:09:10,060 --> 00:09:11,800
originally created at Google for game

197
00:09:11,800 --> 00:09:14,170
development and is now being used for

198
00:09:14,170 --> 00:09:16,530
other performance sensitive applications

199
00:09:16,530 --> 00:09:19,630
the advantage of using flatbuffers

200
00:09:19,630 --> 00:09:22,450
is that we can directly access the data

201
00:09:22,450 --> 00:09:25,660
without doing parsing or unperson of the

202
00:09:25,660 --> 00:09:28,050
large files which contain weights

203
00:09:28,050 --> 00:09:30,880
another thing that we do at the time of

204
00:09:30,880 --> 00:09:33,250
conversion is that we pre fuse the

205
00:09:33,250 --> 00:09:36,190
activations and biases and this leads to

206
00:09:36,190 --> 00:09:41,410
faster execution later at runtime the

207
00:09:41,410 --> 00:09:43,450
tensorflow Lite interpreter uses a

208
00:09:43,450 --> 00:09:45,910
static memory and static execution plan

209
00:09:45,910 --> 00:09:50,560
this leads to faster load times many of

210
00:09:50,560 --> 00:09:53,080
the kernels that tensorflow light comes

211
00:09:53,080 --> 00:09:55,210
with have been specially optimized to

212
00:09:55,210 --> 00:10:00,940
run fast only on unarmed CPUs now let's

213
00:10:00,940 --> 00:10:03,360
talk about hardware acceleration as

214
00:10:03,360 --> 00:10:06,540
machine learning has grown in prominence

215
00:10:06,540 --> 00:10:09,610
it has felt quite a bit of innovation at

216
00:10:09,610 --> 00:10:11,920
the silicon layer as well and many

217
00:10:11,920 --> 00:10:14,290
hardware companies are investing in

218
00:10:14,290 --> 00:10:16,120
building custom chips which can

219
00:10:16,120 --> 00:10:19,380
accelerate neural network processing

220
00:10:19,380 --> 00:10:22,570
GPUs and DSPs which have been around for

221
00:10:22,570 --> 00:10:24,250
some time are also now being

222
00:10:24,250 --> 00:10:26,800
increasingly used to do machine learning

223
00:10:26,800 --> 00:10:30,100
tasks tensorflow Lite was designed to

224
00:10:30,100 --> 00:10:32,380
take advantage of hardware acceleration

225
00:10:32,380 --> 00:10:35,950
whether it is through GPUs DSPs or

226
00:10:35,950 --> 00:10:41,950
custom AI chips on Android the recently

227
00:10:41,950 --> 00:10:45,340
released Android neural network API is

228
00:10:45,340 --> 00:10:47,860
an abstraction layer which makes it easy

229
00:10:47,860 --> 00:10:50,350
for tensorflow Lite to take advantage of

230
00:10:50,350 --> 00:10:53,350
the underlying acceleration and the way

231
00:10:53,350 --> 00:10:55,360
this works is that hardware vendors

232
00:10:55,360 --> 00:10:58,510
write specialized drivers or custom

233
00:10:58,510 --> 00:11:00,580
acceleration code for their hardware

234
00:11:00,580 --> 00:11:03,040
platforms and integrate with the Android

235
00:11:03,040 --> 00:11:04,160
and API

236
00:11:04,160 --> 00:11:07,170
tensorflow light in turn integrates with

237
00:11:07,170 --> 00:11:10,200
the Android and an API via its internal

238
00:11:10,200 --> 00:11:15,330
delegation API a point to note here is

239
00:11:15,330 --> 00:11:17,460
that developers only need to integrate

240
00:11:17,460 --> 00:11:19,740
their apps with tensorflow light

241
00:11:19,740 --> 00:11:21,900
tensorflow light will take care of

242
00:11:21,900 --> 00:11:24,450
abstracting away the details of hardware

243
00:11:24,450 --> 00:11:29,640
acceleration from them in addition to

244
00:11:29,640 --> 00:11:31,890
the Android and an API we are also

245
00:11:31,890 --> 00:11:34,290
working on building direct GPU

246
00:11:34,290 --> 00:11:37,800
acceleration in tensorflow light GPUs

247
00:11:37,800 --> 00:11:40,560
are widely available and used and like I

248
00:11:40,560 --> 00:11:41,910
said before they are now being

249
00:11:41,910 --> 00:11:43,980
increasingly used for doing machine

250
00:11:43,980 --> 00:11:47,150
learning tasks similar to era an API

251
00:11:47,150 --> 00:11:49,680
developers only integrate with

252
00:11:49,680 --> 00:11:51,240
tensorflow light if they want to take

253
00:11:51,240 --> 00:11:56,310
advantage of the GPU acceleration so the

254
00:11:56,310 --> 00:11:57,900
last bit on performance that I want to

255
00:11:57,900 --> 00:12:00,540
talk about is quantization and this is a

256
00:12:00,540 --> 00:12:03,029
good example of an optimization which

257
00:12:03,029 --> 00:12:04,920
cuts across several components in our

258
00:12:04,920 --> 00:12:07,980
system so first of all what is

259
00:12:07,980 --> 00:12:10,830
quantization a simple way to think about

260
00:12:10,830 --> 00:12:14,010
it is that it refers to techniques to

261
00:12:14,010 --> 00:12:16,170
store numbers and to perform

262
00:12:16,170 --> 00:12:18,930
calculations or numbers in formats that

263
00:12:18,930 --> 00:12:21,390
are more compact than 32-bit

264
00:12:21,390 --> 00:12:24,300
floating-point representations and why

265
00:12:24,300 --> 00:12:26,220
is this important well for two reasons

266
00:12:26,220 --> 00:12:30,330
first model size is a concern for small

267
00:12:30,330 --> 00:12:32,970
devices so the smaller the model the

268
00:12:32,970 --> 00:12:36,240
better it is secondly there are many

269
00:12:36,240 --> 00:12:39,000
processors which have specialized sim D

270
00:12:39,000 --> 00:12:41,280
instruction sets which process fixed

271
00:12:41,280 --> 00:12:43,320
point numbers much faster than they

272
00:12:43,320 --> 00:12:47,820
process floating-point numbers so the

273
00:12:47,820 --> 00:12:49,560
next question here is how much accuracy

274
00:12:49,560 --> 00:12:52,140
do we lose if we are using eight bits or

275
00:12:52,140 --> 00:12:55,650
16 bits instead of the 32 bits which are

276
00:12:55,650 --> 00:12:57,089
used for representing floating-point

277
00:12:57,089 --> 00:13:00,810
numbers well the answer obviously

278
00:13:00,810 --> 00:13:02,490
depends on which model that we are using

279
00:13:02,490 --> 00:13:06,000
but in general the learning process is

280
00:13:06,000 --> 00:13:09,330
robust to noise and quantization can be

281
00:13:09,330 --> 00:13:12,209
thought of as a form of noise so what we

282
00:13:12,209 --> 00:13:14,950
find is that the accuracy is 10

283
00:13:14,950 --> 00:13:16,870
to be usually within acceptable

284
00:13:16,870 --> 00:13:21,730
thresholds a simple way of doing

285
00:13:21,730 --> 00:13:24,100
quantization is to shrink the weights

286
00:13:24,100 --> 00:13:27,550
and biases after training and we are

287
00:13:27,550 --> 00:13:29,170
shortly going to be releasing a tool

288
00:13:29,170 --> 00:13:31,840
which developers can use to shrink the

289
00:13:31,840 --> 00:13:36,040
size of their models in addition to that

290
00:13:36,040 --> 00:13:38,890
we have been actively working on doing

291
00:13:38,890 --> 00:13:41,500
quantization at training time and this

292
00:13:41,500 --> 00:13:43,750
is an active area of ongoing research

293
00:13:43,750 --> 00:13:46,420
and what we find here is that we are

294
00:13:46,420 --> 00:13:48,580
able to get accuracies which are

295
00:13:48,580 --> 00:13:50,650
comparable to the floating-point models

296
00:13:50,650 --> 00:13:53,020
for architectures like mobile light as

297
00:13:53,020 --> 00:13:55,240
well as inception and we recently

298
00:13:55,240 --> 00:13:57,640
release a tool which allows developers

299
00:13:57,640 --> 00:14:00,940
to use this and we are working on adding

300
00:14:00,940 --> 00:14:05,110
support for more models in this okay so

301
00:14:05,110 --> 00:14:06,730
I talked about a bunch of performance

302
00:14:06,730 --> 00:14:09,250
optimizations now let's talk about what

303
00:14:09,250 --> 00:14:11,500
does it translate to in terms of numbers

304
00:14:11,500 --> 00:14:15,250
so we benchmark to models mobile lat and

305
00:14:15,250 --> 00:14:18,400
Inception v3 or the pixel tool and as

306
00:14:18,400 --> 00:14:20,200
you can see here we are getting speed

307
00:14:20,200 --> 00:14:22,510
ups of more than three times when we

308
00:14:22,510 --> 00:14:25,000
compare quantized models running on

309
00:14:25,000 --> 00:14:27,010
tensorflow light versus floating-point

310
00:14:27,010 --> 00:14:29,950
models running on tensorflow I'll point

311
00:14:29,950 --> 00:14:31,510
out here that these numbers do not

312
00:14:31,510 --> 00:14:34,900
include any hardware acceleration we

313
00:14:34,900 --> 00:14:37,390
have done some initial benchmarking with

314
00:14:37,390 --> 00:14:39,610
hardware acceleration and we see

315
00:14:39,610 --> 00:14:41,590
additional speed ups of three to four

316
00:14:41,590 --> 00:14:44,440
times with that which is really

317
00:14:44,440 --> 00:14:46,930
promising and exciting so stay tuned in

318
00:14:46,930 --> 00:14:50,430
the next few months to hear more on that

319
00:14:50,430 --> 00:14:52,990
now that I've talked about the design of

320
00:14:52,990 --> 00:14:55,660
tensor flow and performance I want to

321
00:14:55,660 --> 00:14:57,310
show you what tensor flow light can do

322
00:14:57,310 --> 00:15:08,320
in practice let's please roll the video

323
00:15:08,320 --> 00:15:11,149
so this is a simple demo application

324
00:15:11,149 --> 00:15:13,660
which is running the mobile net

325
00:15:13,660 --> 00:15:16,160
classification model which we trained on

326
00:15:16,160 --> 00:15:18,649
common office objects and as you can see

327
00:15:18,649 --> 00:15:20,990
it's doing a good job detecting them

328
00:15:20,990 --> 00:15:23,690
even this tensorflow logo that we

329
00:15:23,690 --> 00:15:26,570
trained this model on like I said it's

330
00:15:26,570 --> 00:15:29,959
cross-platform so it's running on iOS as

331
00:15:29,959 --> 00:15:33,680
well as Android and we also are running

332
00:15:33,680 --> 00:15:37,730
it here on Android things this was a

333
00:15:37,730 --> 00:15:40,339
simple demo we have more exciting demos

334
00:15:40,339 --> 00:15:42,980
for you later on in the talk now let's

335
00:15:42,980 --> 00:15:44,990
talk about production use cases I'm

336
00:15:44,990 --> 00:15:46,970
happy to say that we've been working

337
00:15:46,970 --> 00:15:49,490
with partner teams inside Google to

338
00:15:49,490 --> 00:15:51,430
bring tons of low-light to Google Apps

339
00:15:51,430 --> 00:15:54,830
so portrait mode on Android camera hey

340
00:15:54,830 --> 00:15:57,140
Google and Google assistant and smart

341
00:15:57,140 --> 00:15:59,600
reply are some features which are going

342
00:15:59,600 --> 00:16:01,760
to be powered by tensorflow light in the

343
00:16:01,760 --> 00:16:04,779
next few months

344
00:16:04,779 --> 00:16:07,550
additionally tensorflow light is the

345
00:16:07,550 --> 00:16:09,020
machine learning engine which is

346
00:16:09,020 --> 00:16:11,180
powering the custom model functionality

347
00:16:11,180 --> 00:16:15,320
in the newly announced ml kit and for

348
00:16:15,320 --> 00:16:16,910
those of you that may have missed the

349
00:16:16,910 --> 00:16:19,190
announcement mo kit is a machine

350
00:16:19,190 --> 00:16:22,490
learning SDK it exposes both on device

351
00:16:22,490 --> 00:16:24,830
and cloud powered api's for machine

352
00:16:24,830 --> 00:16:27,020
learning as well as the ability to bring

353
00:16:27,020 --> 00:16:30,940
your own custom models and use them

354
00:16:30,940 --> 00:16:33,650
these are some examples of apps that are

355
00:16:33,650 --> 00:16:36,160
already using tensorflow lite VRML kit

356
00:16:36,160 --> 00:16:39,050
picsArt it's a really popular photo

357
00:16:39,050 --> 00:16:41,810
editing in collage making app and visco

358
00:16:41,810 --> 00:16:46,220
it's a really cool photography app so

359
00:16:46,220 --> 00:16:48,020
back to tensorflow light and what is

360
00:16:48,020 --> 00:16:51,079
currently supported so we have support

361
00:16:51,079 --> 00:16:53,870
for 50 commonly used operations which

362
00:16:53,870 --> 00:16:56,120
developers can use in their own models I

363
00:16:56,120 --> 00:16:58,790
will point out here that if you need an

364
00:16:58,790 --> 00:17:01,400
app which is not currently supported you

365
00:17:01,400 --> 00:17:03,740
do have the option of using what we call

366
00:17:03,740 --> 00:17:06,679
a custom up and using that and later on

367
00:17:06,679 --> 00:17:08,540
in this talk Andrew will show you how

368
00:17:08,540 --> 00:17:11,900
you can do that up support is currently

369
00:17:11,900 --> 00:17:14,569
limited to inference we will be working

370
00:17:14,569 --> 00:17:16,870
on adding training support in the future

371
00:17:16,870 --> 00:17:20,569
we support several common popular open

372
00:17:20,569 --> 00:17:21,800
source models

373
00:17:21,800 --> 00:17:23,990
as well as the quantized counterparts

374
00:17:23,990 --> 00:17:26,810
for some of them and with this I'm going

375
00:17:26,810 --> 00:17:29,030
to invite my colleague Andrew to talk to

376
00:17:29,030 --> 00:17:30,830
you about how you can use tensor flow

377
00:17:30,830 --> 00:17:35,550
light in your own apps thanks Sara

378
00:17:35,550 --> 00:17:36,910
[Applause]

379
00:17:36,910 --> 00:17:39,970
[Music]

380
00:17:39,970 --> 00:17:42,410
so now that you know what tentacle light

381
00:17:42,410 --> 00:17:46,310
is and what it can do and where it can

382
00:17:46,310 --> 00:17:48,380
be run I'm sure you know you want to

383
00:17:48,380 --> 00:17:50,810
know how to use it so we can break that

384
00:17:50,810 --> 00:17:53,180
up into four important steps the first

385
00:17:53,180 --> 00:17:54,770
one it and probably the most important

386
00:17:54,770 --> 00:17:56,870
is get a model you need to decide what

387
00:17:56,870 --> 00:17:58,640
you want to do it could be image

388
00:17:58,640 --> 00:17:59,630
classification

389
00:17:59,630 --> 00:18:02,690
it could be object detection or it could

390
00:18:02,690 --> 00:18:05,420
be even speech recognition whatever that

391
00:18:05,420 --> 00:18:07,670
model is you need to train it yourself

392
00:18:07,670 --> 00:18:09,380
you can do that with tentacle just like

393
00:18:09,380 --> 00:18:11,420
you trained any other tensor flow model

394
00:18:11,420 --> 00:18:13,880
or you can download a pre train model if

395
00:18:13,880 --> 00:18:15,230
you're not ready to make your own model

396
00:18:15,230 --> 00:18:17,420
yet or if an existing model satisfies

397
00:18:17,420 --> 00:18:20,600
your needs second you need to convert

398
00:18:20,600 --> 00:18:22,520
your model from tensor flow to tensor

399
00:18:22,520 --> 00:18:24,080
fold light and we'll show some examples

400
00:18:24,080 --> 00:18:27,860
of how to do that in a second third if

401
00:18:27,860 --> 00:18:29,480
there's any custom ops that you need to

402
00:18:29,480 --> 00:18:32,030
write this could be because you want to

403
00:18:32,030 --> 00:18:33,590
spot optimize something with some

404
00:18:33,590 --> 00:18:35,480
special instructions you know about or

405
00:18:35,480 --> 00:18:37,310
it could be that you're using a piece of

406
00:18:37,310 --> 00:18:39,260
functionality that we do not yet support

407
00:18:39,260 --> 00:18:41,720
like a specialized piece of signal

408
00:18:41,720 --> 00:18:43,940
processing whatever it might be you can

409
00:18:43,940 --> 00:18:45,740
write your ops this may not be necessary

410
00:18:45,740 --> 00:18:48,560
of course the last step is to write an

411
00:18:48,560 --> 00:18:50,150
app and you're going to use whatever

412
00:18:50,150 --> 00:18:53,000
client API is appropriate for the target

413
00:18:53,000 --> 00:18:55,720
platform so let's dive into some code

414
00:18:55,720 --> 00:18:59,030
converting your tenth of a model once

415
00:18:59,030 --> 00:19:00,350
you're done with a tensorflow training

416
00:19:00,350 --> 00:19:02,300
you typically have a saved model or you

417
00:19:02,300 --> 00:19:04,820
might have a graph desk what you need to

418
00:19:04,820 --> 00:19:07,340
do first is put this through the

419
00:19:07,340 --> 00:19:09,170
converter so here I'm showing how to do

420
00:19:09,170 --> 00:19:10,820
this within Python so if you download

421
00:19:10,820 --> 00:19:13,010
the normal tensorflow to Lane

422
00:19:13,010 --> 00:19:15,080
that's pre-compiled like the pip you're

423
00:19:15,080 --> 00:19:19,100
able to run the the converter and it

424
00:19:19,100 --> 00:19:21,140
just takes a save model directory in or

425
00:19:21,140 --> 00:19:24,980
a frozen graph def and it you specify a

426
00:19:24,980 --> 00:19:27,140
file name of what TF Lite file you want

427
00:19:27,140 --> 00:19:28,880
and that will output a flat buffer

428
00:19:28,880 --> 00:19:30,980
that's on disk that you can now ship to

429
00:19:30,980 --> 00:19:34,100
whatever device you want now how much

430
00:19:34,100 --> 00:19:35,210
you get it to the device

431
00:19:35,210 --> 00:19:37,250
you could put it into the package you

432
00:19:37,250 --> 00:19:40,250
could also say distribute it through a

433
00:19:40,250 --> 00:19:42,289
cloud service where you can update your

434
00:19:42,289 --> 00:19:44,779
model on the fly without updating your

435
00:19:44,779 --> 00:19:47,600
core application whatever you want to do

436
00:19:47,600 --> 00:19:51,860
is possible so next once you've

437
00:19:51,860 --> 00:19:54,289
converted well you might actually run

438
00:19:54,289 --> 00:19:55,730
into some issues doing a conversion

439
00:19:55,730 --> 00:19:58,850
because there's a couple of things that

440
00:19:58,850 --> 00:20:00,890
can go wrong so the first one is you

441
00:20:00,890 --> 00:20:02,090
need to make sure that you have a frozen

442
00:20:02,090 --> 00:20:04,850
graft F or a save model both of these

443
00:20:04,850 --> 00:20:06,860
are able to get rid of the parts of the

444
00:20:06,860 --> 00:20:08,600
graph that are used for training these

445
00:20:08,600 --> 00:20:10,309
are typically things like variable

446
00:20:10,309 --> 00:20:12,220
assignment variable initialization

447
00:20:12,220 --> 00:20:14,210
optimization passes these are not

448
00:20:14,210 --> 00:20:16,190
strictly necessary for doing inference

449
00:20:16,190 --> 00:20:18,110
that is prediction so you want to get

450
00:20:18,110 --> 00:20:19,970
rid of those out of the graph because we

451
00:20:19,970 --> 00:20:21,409
don't want to support those operations

452
00:20:21,409 --> 00:20:23,059
right now because we want to have the

453
00:20:23,059 --> 00:20:25,159
smallest version of the runtime that can

454
00:20:25,159 --> 00:20:27,620
be distributed to keep your binary size

455
00:20:27,620 --> 00:20:30,649
small the second thing that you need to

456
00:20:30,649 --> 00:20:32,360
do is make sure that you write any

457
00:20:32,360 --> 00:20:34,460
custom operators that you need and now

458
00:20:34,460 --> 00:20:35,840
I'll go into a little bit of an example

459
00:20:35,840 --> 00:20:38,840
of doing that well before that let me

460
00:20:38,840 --> 00:20:40,549
tell you one more thing which is we also

461
00:20:40,549 --> 00:20:42,409
have some visualizers let you understand

462
00:20:42,409 --> 00:20:44,450
the model that you've transformed and

463
00:20:44,450 --> 00:20:46,669
the transformation process so take a

464
00:20:46,669 --> 00:20:48,080
look at those they're linked off of the

465
00:20:48,080 --> 00:20:52,010
documentation so let's get into writing

466
00:20:52,010 --> 00:20:54,230
a custom op so what kind of optimized we

467
00:20:54,230 --> 00:20:56,149
need well here I have an example that's

468
00:20:56,149 --> 00:20:58,159
a little bit silly but it's to return

469
00:20:58,159 --> 00:21:00,289
pie so the important thing when you

470
00:21:00,289 --> 00:21:01,460
write an op is that you need to

471
00:21:01,460 --> 00:21:03,860
implement for C functions so we have a C

472
00:21:03,860 --> 00:21:06,440
API for defining operations and the

473
00:21:06,440 --> 00:21:09,529
reason we do this is that all of our

474
00:21:09,529 --> 00:21:11,270
operations are implemented in this way

475
00:21:11,270 --> 00:21:13,130
so they can run on devices that only

476
00:21:13,130 --> 00:21:16,070
support C eventually but you can write

477
00:21:16,070 --> 00:21:18,860
kernels in C++ in this case what I'm

478
00:21:18,860 --> 00:21:21,860
doing is I'm ignoring the input tensors

479
00:21:21,860 --> 00:21:23,840
and I'm putting an output tensor which

480
00:21:23,840 --> 00:21:27,830
is M pi now if you had input tensors and

481
00:21:27,830 --> 00:21:30,200
you wanted to make a an output tensor

482
00:21:30,200 --> 00:21:32,600
you could also read the input tensors

483
00:21:32,600 --> 00:21:35,630
and then say oh x 3 and now I have a x 3

484
00:21:35,630 --> 00:21:37,190
operation this was going to be

485
00:21:37,190 --> 00:21:39,110
application dependent and of course as I

486
00:21:39,110 --> 00:21:41,149
said before you don't always need to do

487
00:21:41,149 --> 00:21:43,340
this I'm just laying this out here to

488
00:21:43,340 --> 00:21:44,990
show that if there's some functionality

489
00:21:44,990 --> 00:21:45,470
that you need

490
00:21:45,470 --> 00:21:46,980
we are extensible

491
00:21:46,980 --> 00:21:50,500
okay once you've converted your model

492
00:21:50,500 --> 00:21:52,330
you need to use a client API let me

493
00:21:52,330 --> 00:21:54,430
start with the C++ API but we have other

494
00:21:54,430 --> 00:21:56,200
language bindings as well that I'll get

495
00:21:56,200 --> 00:21:59,770
to and but in any of the bindings it's

496
00:21:59,770 --> 00:22:01,330
going to follow the same basic pattern

497
00:22:01,330 --> 00:22:05,020
the pattern is create an interpreter and

498
00:22:05,020 --> 00:22:08,350
load the model fill in your data execute

499
00:22:08,350 --> 00:22:10,330
the model and read back your data so

500
00:22:10,330 --> 00:22:12,700
it's very simple so in the C++ API the

501
00:22:12,700 --> 00:22:14,170
first thing you do is create a model

502
00:22:14,170 --> 00:22:16,540
object and this is given the file name

503
00:22:16,540 --> 00:22:21,010
of the tensorflow light file and it

504
00:22:21,010 --> 00:22:22,840
creates an object that is going to hold

505
00:22:22,840 --> 00:22:25,060
that model and M map it so as I said

506
00:22:25,060 --> 00:22:26,440
before we use flat buffers and the

507
00:22:26,440 --> 00:22:28,600
reason why is that we can M map the

508
00:22:28,600 --> 00:22:30,160
buffers which means that there is zero

509
00:22:30,160 --> 00:22:31,510
latency to start running the model

510
00:22:31,510 --> 00:22:33,970
effectively okay

511
00:22:33,970 --> 00:22:36,570
second if you have any custom operations

512
00:22:36,570 --> 00:22:39,340
you can register them so basically at

513
00:22:39,340 --> 00:22:40,720
this phase you're deciding which

514
00:22:40,720 --> 00:22:43,740
operations to include into your runtime

515
00:22:43,740 --> 00:22:46,270
by default we provide a built in op

516
00:22:46,270 --> 00:22:48,760
resolver that's that includes all of our

517
00:22:48,760 --> 00:22:51,280
default operations you might also use

518
00:22:51,280 --> 00:22:53,110
selective registration that we alluded

519
00:22:53,110 --> 00:22:55,030
to before where you include only a

520
00:22:55,030 --> 00:22:57,370
subset of the operations in this case

521
00:22:57,370 --> 00:22:59,260
you might provide a minimal resolver and

522
00:22:59,260 --> 00:23:01,150
if you wanted to use the custom

523
00:23:01,150 --> 00:23:03,070
operation that we had before you would

524
00:23:03,070 --> 00:23:05,560
create a custom resolver that would tell

525
00:23:05,560 --> 00:23:07,660
tensive row light how to find your

526
00:23:07,660 --> 00:23:11,830
custom operation so now we know what our

527
00:23:11,830 --> 00:23:14,590
ops are and where to get the code for

528
00:23:14,590 --> 00:23:16,810
them and we know our model now we need

529
00:23:16,810 --> 00:23:18,460
to create an interpreter object so we

530
00:23:18,460 --> 00:23:20,920
take the pair of model and resolver and

531
00:23:20,920 --> 00:23:22,180
put it together and it returns an

532
00:23:22,180 --> 00:23:24,100
interpreter this interpreter is going to

533
00:23:24,100 --> 00:23:26,620
be our handle for doing our execution so

534
00:23:26,620 --> 00:23:29,560
the next step is we're going to perform

535
00:23:29,560 --> 00:23:30,940
our execution but before we can do that

536
00:23:30,940 --> 00:23:33,580
we need to fill the buffer so if you

537
00:23:33,580 --> 00:23:35,380
have a model like a classification model

538
00:23:35,380 --> 00:23:37,090
that is something that takes an image in

539
00:23:37,090 --> 00:23:38,560
where are you going to get that image

540
00:23:38,560 --> 00:23:40,240
well the obvious place you might get it

541
00:23:40,240 --> 00:23:42,940
would be from your devices storage if

542
00:23:42,940 --> 00:23:45,160
it's an image file name but also

543
00:23:45,160 --> 00:23:47,050
commonly would be a camera whatever it

544
00:23:47,050 --> 00:23:50,590
might be you produce a like a buffer in

545
00:23:50,590 --> 00:23:52,270
in this class it's gonna be a floats

546
00:23:52,270 --> 00:23:54,400
hour and an in star buffer and you fill

547
00:23:54,400 --> 00:23:56,680
it in to our buffer and once you fill

548
00:23:56,680 --> 00:23:58,960
this buffer you're ready to run so we

549
00:23:58,960 --> 00:24:00,190
filled our buffer

550
00:24:00,190 --> 00:24:01,899
tensa for light has all the information

551
00:24:01,899 --> 00:24:04,570
it needs to run the the execution and we

552
00:24:04,570 --> 00:24:07,659
just call invoke now it's going to block

553
00:24:07,659 --> 00:24:09,759
until that execution is done and then

554
00:24:09,759 --> 00:24:11,470
we're going to be able to read the

555
00:24:11,470 --> 00:24:14,289
output of it in and in an analogous way

556
00:24:14,289 --> 00:24:16,809
to our input so that is we can get a

557
00:24:16,809 --> 00:24:18,669
float star buffer out which could

558
00:24:18,669 --> 00:24:21,609
represent the class numbers and then

559
00:24:21,609 --> 00:24:23,649
you're free to do with that data

560
00:24:23,649 --> 00:24:25,479
whatever you want so for example in an

561
00:24:25,479 --> 00:24:26,919
image classification app that we showed

562
00:24:26,919 --> 00:24:29,739
before you would read that index out map

563
00:24:29,739 --> 00:24:31,929
it back to a string and then put it into

564
00:24:31,929 --> 00:24:35,440
your gooeys display great so now we know

565
00:24:35,440 --> 00:24:37,239
how to use C++ what if you're using

566
00:24:37,239 --> 00:24:40,239
another platform for example raspberry

567
00:24:40,239 --> 00:24:43,239
pi on raspberry pi the most common thing

568
00:24:43,239 --> 00:24:45,700
to use is probably Python and again it's

569
00:24:45,700 --> 00:24:46,929
gonna follow the same basic pattern

570
00:24:46,929 --> 00:24:48,909
first we create an interpreter object

571
00:24:48,909 --> 00:24:50,919
the interpreter object is now our handle

572
00:24:50,919 --> 00:24:52,450
how do we feed data

573
00:24:52,450 --> 00:24:54,909
well since it's Python we can use numpy

574
00:24:54,909 --> 00:24:56,499
arrays and this is really convenient

575
00:24:56,499 --> 00:24:57,549
because if you'd need to do

576
00:24:57,549 --> 00:24:59,529
pre-processing or post processing you

577
00:24:59,529 --> 00:25:00,729
can do it with the primitives that

578
00:25:00,729 --> 00:25:02,409
you're familiar with and this is kind of

579
00:25:02,409 --> 00:25:04,330
a theme that goes on that we want to

580
00:25:04,330 --> 00:25:06,789
keep our bindings as idiomatic as

581
00:25:06,789 --> 00:25:08,139
possible in the language that they are

582
00:25:08,139 --> 00:25:11,080
and also keep it performant so in this

583
00:25:11,080 --> 00:25:14,049
case we put in some known PI ray and we

584
00:25:14,049 --> 00:25:15,940
take out some numpy array so that's

585
00:25:15,940 --> 00:25:17,799
Python what if you're writing an Android

586
00:25:17,799 --> 00:25:19,210
app or you want to write an Android

587
00:25:19,210 --> 00:25:21,159
things application then you might use

588
00:25:21,159 --> 00:25:25,119
the Java API so in this case it's the

589
00:25:25,119 --> 00:25:26,950
same thing you take you build an

590
00:25:26,950 --> 00:25:29,200
interpreter give it the file name of the

591
00:25:29,200 --> 00:25:30,759
interpreter it might be from a resource

592
00:25:30,759 --> 00:25:32,529
if you're doing an Android application

593
00:25:32,529 --> 00:25:35,259
and then finally you're gonna fill the

594
00:25:35,259 --> 00:25:39,279
inputs in and and call wrong so one of

595
00:25:39,279 --> 00:25:40,749
the things that we did for the Java API

596
00:25:40,749 --> 00:25:42,639
is that we know that many Java

597
00:25:42,639 --> 00:25:43,779
programmers don't really want to deal

598
00:25:43,779 --> 00:25:46,479
with building their own native library

599
00:25:46,479 --> 00:25:48,669
so in that case you can just use our

600
00:25:48,669 --> 00:25:50,950
Gradle file here which will include our

601
00:25:50,950 --> 00:25:52,479
pre compiled version of tensor faux

602
00:25:52,479 --> 00:25:53,889
light you don't have to download our

603
00:25:53,889 --> 00:25:56,139
source code and even for the tooling

604
00:25:56,139 --> 00:25:57,789
parts where you do the conversion from

605
00:25:57,789 --> 00:25:59,499
tensorflow to tensor of light you can

606
00:25:59,499 --> 00:26:01,330
download the pre compiled version of of

607
00:26:01,330 --> 00:26:05,129
tensorflow as i alluded to before great

608
00:26:05,129 --> 00:26:07,929
so what if you're doing iOS well in that

609
00:26:07,929 --> 00:26:09,489
case you can use the C post will say be

610
00:26:09,489 --> 00:26:12,340
API you can also use the Objective C API

611
00:26:12,340 --> 00:26:13,900
but again we

612
00:26:13,900 --> 00:26:15,640
a precompiled binary in the form of a

613
00:26:15,640 --> 00:26:20,920
cocoa pod okay so now that you know how

614
00:26:20,920 --> 00:26:22,810
to use tensor for life I want to tell

615
00:26:22,810 --> 00:26:23,860
you a little bit about what's going to

616
00:26:23,860 --> 00:26:26,080
be coming up intensive row light one

617
00:26:26,080 --> 00:26:27,550
thing that we've haven't been asked for

618
00:26:27,550 --> 00:26:30,520
a lot is adding more operations so the

619
00:26:30,520 --> 00:26:32,290
more operations that we add the more

620
00:26:32,290 --> 00:26:34,750
models can be run from tensorflow out of

621
00:26:34,750 --> 00:26:36,610
the box the other thing that happens

622
00:26:36,610 --> 00:26:38,920
with machine learning that's often

623
00:26:38,920 --> 00:26:40,750
difficult is that researchers come up

624
00:26:40,750 --> 00:26:42,430
with new techniques all the time and

625
00:26:42,430 --> 00:26:44,350
that means that tensorflow is always

626
00:26:44,350 --> 00:26:46,630
adding operations that means that we're

627
00:26:46,630 --> 00:26:48,910
going to continue to follow tensor flow

628
00:26:48,910 --> 00:26:50,920
as it adds important operations and add

629
00:26:50,920 --> 00:26:54,220
them into tensor for light as well okay

630
00:26:54,220 --> 00:26:55,960
the second thing we're going to do is

631
00:26:55,960 --> 00:26:56,980
we're going to improve the tooling

632
00:26:56,980 --> 00:26:59,040
provide better documentation and

633
00:26:59,040 --> 00:27:02,170
tutorials and try to focus on ease of

634
00:27:02,170 --> 00:27:03,670
use so it's really easy for you to

635
00:27:03,670 --> 00:27:05,830
understand on end-to-end examples how to

636
00:27:05,830 --> 00:27:09,430
integrate tensor flow life and the third

637
00:27:09,430 --> 00:27:11,470
thing which sara already mentioned but

638
00:27:11,470 --> 00:27:13,180
I'll mention again is that we're excited

639
00:27:13,180 --> 00:27:15,250
about on device training on device

640
00:27:15,250 --> 00:27:17,140
training is really exciting because it

641
00:27:17,140 --> 00:27:20,400
allows us to refine a model based on a

642
00:27:20,400 --> 00:27:23,020
user's experience it allows us to

643
00:27:23,020 --> 00:27:25,660
decouple that experience from going to

644
00:27:25,660 --> 00:27:27,280
the cloud so if they're disconnected we

645
00:27:27,280 --> 00:27:29,380
can and continue improving the model so

646
00:27:29,380 --> 00:27:31,000
there's a lot of requests for this this

647
00:27:31,000 --> 00:27:33,040
of course will require more and more

648
00:27:33,040 --> 00:27:34,840
computation on the device but we're

649
00:27:34,840 --> 00:27:37,810
excited about upcoming upcoming hardware

650
00:27:37,810 --> 00:27:39,250
accelerators that will make this more

651
00:27:39,250 --> 00:27:44,020
and more possible okay one more question

652
00:27:44,020 --> 00:27:46,450
before we get into some exciting demos

653
00:27:46,450 --> 00:27:48,550
when should I use 10 circle light

654
00:27:48,550 --> 00:27:50,500
so as we alluded to before we're

655
00:27:50,500 --> 00:27:52,180
starting to use tensorflow light for our

656
00:27:52,180 --> 00:27:53,650
first party applications and thirty

657
00:27:53,650 --> 00:27:56,080
third party applications are also using

658
00:27:56,080 --> 00:27:59,830
it that means that what we're doing

659
00:27:59,830 --> 00:28:01,360
moving forward is that we're going to

660
00:28:01,360 --> 00:28:03,160
make ten circle light our standard

661
00:28:03,160 --> 00:28:05,620
solution for running ml on small devices

662
00:28:05,620 --> 00:28:07,690
and mobile devices tensor fly to

663
00:28:07,690 --> 00:28:09,880
tensorflow light currently supports a

664
00:28:09,880 --> 00:28:12,550
subset of tensorflow ops this means that

665
00:28:12,550 --> 00:28:14,710
our recommendation is that you should

666
00:28:14,710 --> 00:28:17,710
use tensor fro light if you can and let

667
00:28:17,710 --> 00:28:20,290
us know

668
00:28:20,290 --> 00:28:22,300
and let us to know about any missing

669
00:28:22,300 --> 00:28:24,310
functionality you need it's not quite

670
00:28:24,310 --> 00:28:26,230
done you probably want to see our demos

671
00:28:26,230 --> 00:28:29,230
so with that I want to show you a video

672
00:28:29,230 --> 00:28:32,500
of retrained models we showed you that

673
00:28:32,500 --> 00:28:34,990
tensorflow go be logo being recognized

674
00:28:34,990 --> 00:28:36,970
this is a common theme that we get which

675
00:28:36,970 --> 00:28:39,280
is people like our pre trained examples

676
00:28:39,280 --> 00:28:41,470
like mobile net but they may not have an

677
00:28:41,470 --> 00:28:42,910
application where they need to tell the

678
00:28:42,910 --> 00:28:45,130
difference between five dog breeds and

679
00:28:45,130 --> 00:28:46,900
many zoo animals they might have an

680
00:28:46,900 --> 00:28:48,790
office scenario where they have markers

681
00:28:48,790 --> 00:28:50,140
and whiteboards and in fact as we were

682
00:28:50,140 --> 00:28:51,970
testing the app we found we had this

683
00:28:51,970 --> 00:28:54,340
issue - it's like we don't have the

684
00:28:54,340 --> 00:28:55,900
classes that are in these pre trained

685
00:28:55,900 --> 00:28:57,700
models so one of the great things that

686
00:28:57,700 --> 00:28:59,680
one of our other tensorflow members

687
00:28:59,680 --> 00:29:01,660
created was something called tensor full

688
00:29:01,660 --> 00:29:03,760
for poets and there was a codelab about

689
00:29:03,760 --> 00:29:05,650
that and it's available online as well

690
00:29:05,650 --> 00:29:07,810
and it basically allows you to take a

691
00:29:07,810 --> 00:29:09,820
pre train image model that has really

692
00:29:09,820 --> 00:29:11,740
good detector ability and put your own

693
00:29:11,740 --> 00:29:13,420
classes into it and I want to show you a

694
00:29:13,420 --> 00:29:15,670
demo app that we created that runs on

695
00:29:15,670 --> 00:29:17,590
the PC and creates ten to full line

696
00:29:17,590 --> 00:29:23,130
models for you so can we go to the video

697
00:29:23,130 --> 00:29:26,140
okay so we showed you before can we

698
00:29:26,140 --> 00:29:27,970
recognize scissors and post-it notes

699
00:29:27,970 --> 00:29:30,400
well let's try it out you always want to

700
00:29:30,400 --> 00:29:32,830
try these models check ok the scissors

701
00:29:32,830 --> 00:29:35,620
looks good right ok great post-it notes

702
00:29:35,620 --> 00:29:37,390
also looks good but what if we had

703
00:29:37,390 --> 00:29:40,210
another object an object that's you know

704
00:29:40,210 --> 00:29:43,600
more common more important like this

705
00:29:43,600 --> 00:29:46,840
metal tensorflow logo this happens in

706
00:29:46,840 --> 00:29:49,390
everyday life right ok let's go take a

707
00:29:49,390 --> 00:29:51,610
look at how this does well it's label

708
00:29:51,610 --> 00:29:53,380
this other that's not very good but the

709
00:29:53,380 --> 00:29:54,640
great thing about machine learning is

710
00:29:54,640 --> 00:29:56,200
that we can fix this and the way we fix

711
00:29:56,200 --> 00:29:58,270
it is we add data so we have our

712
00:29:58,270 --> 00:29:59,920
application we've gone to our training

713
00:29:59,920 --> 00:30:01,660
tab now and now we're going to define a

714
00:30:01,660 --> 00:30:03,760
class called tensorflow and this is

715
00:30:03,760 --> 00:30:06,820
basically short for tentacle logo and

716
00:30:06,820 --> 00:30:09,130
now from our webcam we're gonna click

717
00:30:09,130 --> 00:30:10,840
capture and we're gonna capture a couple

718
00:30:10,840 --> 00:30:12,910
of different perspectives as many as we

719
00:30:12,910 --> 00:30:13,180
can

720
00:30:13,180 --> 00:30:14,950
and ideally you would take it on

721
00:30:14,950 --> 00:30:16,600
different backgrounds so it doesn't

722
00:30:16,600 --> 00:30:19,330
associate the background with it being a

723
00:30:19,330 --> 00:30:20,920
tensor for the logo then I click the

724
00:30:20,920 --> 00:30:22,630
train button and right now it's using

725
00:30:22,630 --> 00:30:24,370
tensorflow to Train the model and you

726
00:30:24,370 --> 00:30:25,900
can see it's converging to a good

727
00:30:25,900 --> 00:30:27,910
validation accuracy it's going to reload

728
00:30:27,910 --> 00:30:29,440
the model and we're testing it intense

729
00:30:29,440 --> 00:30:30,820
or full light running on the PC right

730
00:30:30,820 --> 00:30:31,760
now and

731
00:30:31,760 --> 00:30:33,710
see that it's recognizing tents are full

732
00:30:33,710 --> 00:30:36,890
correctly so it's that fast and easy but

733
00:30:36,890 --> 00:30:39,620
also we can take that model and we can

734
00:30:39,620 --> 00:30:42,590
move to Android and iOS and use the

735
00:30:42,590 --> 00:30:46,550
exact same model and update it so thanks

736
00:30:46,550 --> 00:30:49,250
now let's move to a live demo so I'm

737
00:30:49,250 --> 00:30:58,990
gonna go over here to the podium alright

738
00:30:58,990 --> 00:31:02,180
okay so classification what I just

739
00:31:02,180 --> 00:31:03,680
showed you is kind of this idea that you

740
00:31:03,680 --> 00:31:05,480
have an image in and you put an image

741
00:31:05,480 --> 00:31:08,090
out and you put classifications out but

742
00:31:08,090 --> 00:31:09,590
what if you have multiple objects in the

743
00:31:09,590 --> 00:31:11,810
scene or you have something in a corner

744
00:31:11,810 --> 00:31:13,250
of an object you also want to know where

745
00:31:13,250 --> 00:31:16,550
in the where in the scene that object is

746
00:31:16,550 --> 00:31:19,430
and that enters this model called single

747
00:31:19,430 --> 00:31:21,110
shot detection it's a type of model and

748
00:31:21,110 --> 00:31:23,590
it turns out that our friends in

749
00:31:23,590 --> 00:31:26,150
tentacle research released a package

750
00:31:26,150 --> 00:31:28,130
called object detection as part of the

751
00:31:28,130 --> 00:31:29,750
tentacle models and that basically

752
00:31:29,750 --> 00:31:32,180
allows you to use their pre trained

753
00:31:32,180 --> 00:31:34,700
model that recognizes many classes so

754
00:31:34,700 --> 00:31:36,650
what I've done is I want to load that

755
00:31:36,650 --> 00:31:38,780
onto a small device in this case we're

756
00:31:38,780 --> 00:31:40,970
talking you a lot of things about mobile

757
00:31:40,970 --> 00:31:42,980
devices I want to show you another small

758
00:31:42,980 --> 00:31:45,260
device this is a Raspberry Pi so the

759
00:31:45,260 --> 00:31:48,950
Raspberry Pi is a really cool example of

760
00:31:48,950 --> 00:31:51,290
a device because it's very cheap and

761
00:31:51,290 --> 00:31:52,760
easy to get so any high school student

762
00:31:52,760 --> 00:31:54,530
could have one of these you can have

763
00:31:54,530 --> 00:31:56,930
many of these and just use them for a

764
00:31:56,930 --> 00:31:58,640
dedicated project but the other great

765
00:31:58,640 --> 00:32:00,890
thing about them is not only are they

766
00:32:00,890 --> 00:32:02,750
relatively powerful but they're also

767
00:32:02,750 --> 00:32:04,700
able to interface with other hardware

768
00:32:04,700 --> 00:32:08,870
they have GPIO pins and this this can be

769
00:32:08,870 --> 00:32:10,160
capitalized in a number of different

770
00:32:10,160 --> 00:32:12,380
ways but one way is to run Linux and

771
00:32:12,380 --> 00:32:13,670
that's what we're doing here but you can

772
00:32:13,670 --> 00:32:15,350
also use Android things which you can

773
00:32:15,350 --> 00:32:17,410
see one of the cool sand of the sandbox

774
00:32:17,410 --> 00:32:19,700
has many examples doing that so you

775
00:32:19,700 --> 00:32:21,260
could also do this with Android things

776
00:32:21,260 --> 00:32:24,230
so in this case I have the system the

777
00:32:24,230 --> 00:32:25,910
system board right here and it's

778
00:32:25,910 --> 00:32:28,070
connected to a motor controller and this

779
00:32:28,070 --> 00:32:29,150
motor controller is just a

780
00:32:29,150 --> 00:32:32,180
microcontroller that interfaces to servo

781
00:32:32,180 --> 00:32:34,220
motors these servo motors can go up and

782
00:32:34,220 --> 00:32:35,990
down left and right and they can

783
00:32:35,990 --> 00:32:38,150
basically aim the camera so now what

784
00:32:38,150 --> 00:32:39,230
we're going to do is we're going to load

785
00:32:39,230 --> 00:32:41,680
our object detection model onto this

786
00:32:41,680 --> 00:32:44,270
device and we're gonna actually run it

787
00:32:44,270 --> 00:32:45,140
in order to

788
00:32:45,140 --> 00:32:48,530
recognize different objects so let's go

789
00:32:48,530 --> 00:32:53,030
to the demo feed please and we can see

790
00:32:53,030 --> 00:32:55,040
my app you can tell by the beautiful

791
00:32:55,040 --> 00:32:56,480
nature of this app that I'm not a great

792
00:32:56,480 --> 00:32:58,370
app developer but this is what I can do

793
00:32:58,370 --> 00:33:00,680
on a weekend so give me a little bit of

794
00:33:00,680 --> 00:33:02,780
slack okay so here if we hold up to

795
00:33:02,780 --> 00:33:04,940
Apple it's recognizing the Apple and

796
00:33:04,940 --> 00:33:06,140
it's telling us you know what

797
00:33:06,140 --> 00:33:08,720
probability and where the object is now

798
00:33:08,720 --> 00:33:10,940
that's all good and fine but when we

799
00:33:10,940 --> 00:33:13,670
couple it with the ability to move where

800
00:33:13,670 --> 00:33:15,050
I'm going to turn on the motors now and

801
00:33:15,050 --> 00:33:15,920
now I'm going to bring back the Apple

802
00:33:15,920 --> 00:33:17,990
and what I'm going to do is I'm going to

803
00:33:17,990 --> 00:33:21,320
move the Apple in in the screen and it's

804
00:33:21,320 --> 00:33:23,600
gonna try to keep it centered so as I

805
00:33:23,600 --> 00:33:25,700
move this Apple it's basically going to

806
00:33:25,700 --> 00:33:26,960
try to keep it centered so it's like a

807
00:33:26,960 --> 00:33:29,390
little virtual camera person and this

808
00:33:29,390 --> 00:33:31,400
works on other objects like this banana

809
00:33:31,400 --> 00:33:33,920
here hopefully oh there we go

810
00:33:33,920 --> 00:33:35,990
and it's going to keep that Center and

811
00:33:35,990 --> 00:33:38,030
if you put two objects in the in the

812
00:33:38,030 --> 00:33:40,700
screen it's going to try to keep them

813
00:33:40,700 --> 00:33:44,120
both in okay so so we've got a little

814
00:33:44,120 --> 00:33:46,130
bit of false detection but basically

815
00:33:46,130 --> 00:33:47,270
it's going to try to keep them both

816
00:33:47,270 --> 00:33:50,030
Center so this is really a fun

817
00:33:50,030 --> 00:33:51,950
application and I bet you can come up

818
00:33:51,950 --> 00:33:53,720
with many different applications that

819
00:33:53,720 --> 00:33:56,180
are really exciting to do with this type

820
00:33:56,180 --> 00:33:57,740
of application so can we go back to the

821
00:33:57,740 --> 00:34:05,470
slides again

822
00:34:05,470 --> 00:34:08,210
so I like I said this is basically what

823
00:34:08,210 --> 00:34:09,620
I can do in a weekend but I imagine

824
00:34:09,620 --> 00:34:12,110
great app developers and people with a

825
00:34:12,110 --> 00:34:14,840
lot of creativity about connecting

826
00:34:14,840 --> 00:34:17,060
devices and connecting software can do

827
00:34:17,060 --> 00:34:20,450
many interesting things so what I want

828
00:34:20,450 --> 00:34:22,550
to do now is I want to tell you

829
00:34:22,550 --> 00:34:24,830
in summary tents are full light you've

830
00:34:24,830 --> 00:34:27,710
seen a lot about it basically we feel it

831
00:34:27,710 --> 00:34:29,900
tents or flight makes on device ml small

832
00:34:29,900 --> 00:34:32,570
fast and easy and we think that you're

833
00:34:32,570 --> 00:34:34,669
gonna find it very useful in all of your

834
00:34:34,669 --> 00:34:37,640
applications and we're excited to see

835
00:34:37,640 --> 00:34:40,910
what you build come talk to us I'm going

836
00:34:40,910 --> 00:34:43,760
to be in office hours at 12:30 you can

837
00:34:43,760 --> 00:34:46,460
come talk to me in addition you can come

838
00:34:46,460 --> 00:34:47,929
to our sandbox if you haven't already

839
00:34:47,929 --> 00:34:50,540
and we have of course the examples that

840
00:34:50,540 --> 00:34:52,750
I showed you here we have the the

841
00:34:52,750 --> 00:34:55,940
tracking camera we also have the object

842
00:34:55,940 --> 00:34:57,620
classification on mobile device but

843
00:34:57,620 --> 00:35:00,140
another cool thing that we have is the

844
00:35:00,140 --> 00:35:02,600
donkey cars and this was done by a group

845
00:35:02,600 --> 00:35:05,240
outside of Google and we converted them

846
00:35:05,240 --> 00:35:07,490
over to tensor faux light and we are

847
00:35:07,490 --> 00:35:10,160
excited to say that their application

848
00:35:10,160 --> 00:35:11,480
works really well with tensorflow light

849
00:35:11,480 --> 00:35:13,910
as well so with that I hope you check

850
00:35:13,910 --> 00:35:17,300
these things out I want to tell you that

851
00:35:17,300 --> 00:35:18,830
if you want to get started

852
00:35:18,830 --> 00:35:21,440
you can go to our documentation page you

853
00:35:21,440 --> 00:35:23,090
can go to the tensorflow door page and

854
00:35:23,090 --> 00:35:24,860
there is a TF Lite page where you can

855
00:35:24,860 --> 00:35:26,840
find more information about it in

856
00:35:26,840 --> 00:35:29,210
addition our code is all open source you

857
00:35:29,210 --> 00:35:31,880
can get it on github you can download it

858
00:35:31,880 --> 00:35:35,420
modify it submit a pull request and of

859
00:35:35,420 --> 00:35:37,220
course file any issues that you have

860
00:35:37,220 --> 00:35:39,140
while using it in addition if you want

861
00:35:39,140 --> 00:35:40,880
to talk about tentacle light talk about

862
00:35:40,880 --> 00:35:43,040
your applications ask us about feature

863
00:35:43,040 --> 00:35:45,430
requests please send to our mailing list

864
00:35:45,430 --> 00:35:48,290
this community is really exciting we

865
00:35:48,290 --> 00:35:50,240
found that in open sourcing tensorflow

866
00:35:50,240 --> 00:35:52,520
we got a lot of excitement we got a lot

867
00:35:52,520 --> 00:35:53,870
of interest and we made it a much better

868
00:35:53,870 --> 00:35:56,150
piece of software to use forever in both

869
00:35:56,150 --> 00:35:58,160
people inside Google and outside Google

870
00:35:58,160 --> 00:35:59,960
and we hope that you'll engage tenser

871
00:35:59,960 --> 00:36:01,250
fold light in the same way that

872
00:36:01,250 --> 00:36:03,920
tensorflow has been engaged so with that

873
00:36:03,920 --> 00:36:06,200
I want to thank you for your attention

874
00:36:06,200 --> 00:36:09,770
for coming to i/o for listening to our

875
00:36:09,770 --> 00:36:12,260
talk about tensor pro-lite I also want

876
00:36:12,260 --> 00:36:14,930
to thank you thank our Google partners

877
00:36:14,930 --> 00:36:16,910
this product didn't come out of

878
00:36:16,910 --> 00:36:18,080
isolation

879
00:36:18,080 --> 00:36:19,730
from all of our experience building

880
00:36:19,730 --> 00:36:22,250
mobile apps with machine intelligence as

881
00:36:22,250 --> 00:36:24,320
we gain experience we found that there

882
00:36:24,320 --> 00:36:26,150
was a common need and that was the

883
00:36:26,150 --> 00:36:28,940
genesis of tensor fold light so all of

884
00:36:28,940 --> 00:36:30,530
our partners provided application

885
00:36:30,530 --> 00:36:34,040
provided feedback even provided code and

886
00:36:34,040 --> 00:36:37,220
help with with our models so thank you

887
00:36:37,220 --> 00:36:39,950
so much to you and to them and enjoy the

888
00:36:39,950 --> 00:36:41,540
rest of i/o

889
00:36:41,540 --> 00:36:45,010
[Applause]

890
00:36:45,010 --> 00:37:06,300
[Music]

