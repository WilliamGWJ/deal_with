1
00:00:02,880 --> 00:00:06,110
[Music]

2
00:00:06,110 --> 00:00:08,429
we are here today to speak with you

3
00:00:08,429 --> 00:00:11,039
about tensor close high-level api's so

4
00:00:11,039 --> 00:00:12,780
one area I'm particularly passionate

5
00:00:12,780 --> 00:00:14,459
about is making machine learning as

6
00:00:14,459 --> 00:00:16,560
accessible as possible to as many people

7
00:00:16,560 --> 00:00:19,619
as possible and the tensorflow team has

8
00:00:19,619 --> 00:00:21,300
been investing very heavily in the same

9
00:00:21,300 --> 00:00:24,150
thing so we spent a lot of energy making

10
00:00:24,150 --> 00:00:26,519
tensorflow easier to use so there's

11
00:00:26,519 --> 00:00:28,830
three things that are concrete that I'd

12
00:00:28,830 --> 00:00:31,980
like to walk you through and the very

13
00:00:31,980 --> 00:00:35,220
first is even if you're brand new to

14
00:00:35,220 --> 00:00:36,750
tensorflow you're brand new to machine

15
00:00:36,750 --> 00:00:38,390
learning even if you're new to Python

16
00:00:38,390 --> 00:00:40,950
one area that seems silly but is

17
00:00:40,950 --> 00:00:42,270
non-trivial for a lot of people is

18
00:00:42,270 --> 00:00:44,040
actually just installing tensorflow and

19
00:00:44,040 --> 00:00:45,480
different dependencies and I know for

20
00:00:45,480 --> 00:00:46,890
Python developers is just pip install

21
00:00:46,890 --> 00:00:47,580
tensorflow

22
00:00:47,580 --> 00:00:49,170
but that can be hard for people that are

23
00:00:49,170 --> 00:00:51,060
brand new so I'm gonna show you

24
00:00:51,060 --> 00:00:53,370
something called collab and I'll walk

25
00:00:53,370 --> 00:00:55,080
you through collab it's basically a

26
00:00:55,080 --> 00:00:56,730
jupiter notebook server running in the

27
00:00:56,730 --> 00:00:58,020
cloud it's free of charge it has

28
00:00:58,020 --> 00:00:58,650
tensorflow

29
00:00:58,650 --> 00:01:00,660
pre-installed comes with a free GPU it's

30
00:01:00,660 --> 00:01:02,220
awesome I'll walk you through how to use

31
00:01:02,220 --> 00:01:03,540
that how'd it get started with

32
00:01:03,540 --> 00:01:06,540
tensorflow the next thing tensorflow has

33
00:01:06,540 --> 00:01:08,880
many different api's but my personal

34
00:01:08,880 --> 00:01:10,500
favorite what I'd strongly strongly

35
00:01:10,500 --> 00:01:11,730
recommend to you is something called

36
00:01:11,730 --> 00:01:15,480
chaos and chaos the chaos API is

37
00:01:15,480 --> 00:01:16,830
completely implemented inside of

38
00:01:16,830 --> 00:01:19,440
tensorflow it's great I can't tell you

39
00:01:19,440 --> 00:01:21,659
how much fun I've had using it so I'll

40
00:01:21,659 --> 00:01:23,010
walk you through writing hello world and

41
00:01:23,010 --> 00:01:25,650
care us the same API is also useful for

42
00:01:25,650 --> 00:01:27,870
tensorflow Jas and then I'm gonna point

43
00:01:27,870 --> 00:01:30,030
you to some educational resources to

44
00:01:30,030 --> 00:01:34,170
learn more so briefly this is what I

45
00:01:34,170 --> 00:01:36,060
would do if you want to try tensorflow

46
00:01:36,060 --> 00:01:38,640
and chaos and TF data and eager

47
00:01:38,640 --> 00:01:40,770
execution in the fastest possible way

48
00:01:40,770 --> 00:01:43,770
and I should tell you off the bat so all

49
00:01:43,770 --> 00:01:45,600
these API is there fully implemented and

50
00:01:45,600 --> 00:01:48,900
they're working well we are just now

51
00:01:48,900 --> 00:01:51,720
starting to write all the samples and

52
00:01:51,720 --> 00:01:54,180
Doc's around them so I have a feeling

53
00:01:54,180 --> 00:01:55,560
the samples I was able to cook up for

54
00:01:55,560 --> 00:01:58,409
this talk are they're quite rough but

55
00:01:58,409 --> 00:02:00,840
stay tuned and check back in the next

56
00:02:00,840 --> 00:02:02,460
few months as we flesh this out but let

57
00:02:02,460 --> 00:02:04,500
me just show you how to dive right in so

58
00:02:04,500 --> 00:02:06,119
if you go to this website it will bring

59
00:02:06,119 --> 00:02:07,560
you to this github site and if you

60
00:02:07,560 --> 00:02:12,239
scroll down to the readme you'll see a

61
00:02:12,239 --> 00:02:13,950
sequence of a few notebooks

62
00:02:13,950 --> 00:02:15,450
and I just wanna show you how easy it is

63
00:02:15,450 --> 00:02:17,720
to get started if you just click on one

64
00:02:17,720 --> 00:02:19,920
what happens is they open up immediately

65
00:02:19,920 --> 00:02:23,040
in collab and so now you have a jupiter

66
00:02:23,040 --> 00:02:24,720
notebook it's running entirely in the

67
00:02:24,720 --> 00:02:28,830
cloud you can hit connect to connect to

68
00:02:28,830 --> 00:02:32,580
a kernel and now I can start running

69
00:02:32,580 --> 00:02:33,810
these cells and I'll walk you through

70
00:02:33,810 --> 00:02:35,880
this in more detail in a few minutes but

71
00:02:35,880 --> 00:02:37,080
if you go through the first notebook

72
00:02:37,080 --> 00:02:38,790
this is going to show you how to write

73
00:02:38,790 --> 00:02:41,239
your first neural network using Karos

74
00:02:41,239 --> 00:02:42,959
there's a little bit of pre-processing

75
00:02:42,959 --> 00:02:44,640
code but the notebook is very short

76
00:02:44,640 --> 00:02:47,040
the next notebook will show you how to

77
00:02:47,040 --> 00:02:49,290
do the same thing using Karos in

78
00:02:49,290 --> 00:02:51,299
combination with TF data and eager

79
00:02:51,299 --> 00:02:53,010
execution and then we go into a little

80
00:02:53,010 --> 00:02:55,200
bit more depth so it's literally that

81
00:02:55,200 --> 00:02:56,130
easy to get started

82
00:02:56,130 --> 00:02:59,370
so there's broadly five steps to write

83
00:02:59,370 --> 00:03:01,319
hello world and tensorflow using Karos

84
00:03:01,319 --> 00:03:03,299
the good news is steps three four and

85
00:03:03,299 --> 00:03:04,950
five are literally one line of code and

86
00:03:04,950 --> 00:03:07,200
you can see that on the second line

87
00:03:07,200 --> 00:03:09,269
we're importing emne stand this is easy

88
00:03:09,269 --> 00:03:11,040
because the data set is already we have

89
00:03:11,040 --> 00:03:12,239
a loader for it that's baked into

90
00:03:12,239 --> 00:03:14,790
tensorflow here's the format of the data

91
00:03:14,790 --> 00:03:16,980
set so as imported it's divided already

92
00:03:16,980 --> 00:03:19,079
for us into train and test train is

93
00:03:19,079 --> 00:03:21,840
about 60,000 test is 10,000 the top

94
00:03:21,840 --> 00:03:24,420
right I have a diagram of the format of

95
00:03:24,420 --> 00:03:26,040
the images if you look at the notebooks

96
00:03:26,040 --> 00:03:28,440
on that workshop directory the best

97
00:03:28,440 --> 00:03:30,180
thing you can do when you import a data

98
00:03:30,180 --> 00:03:32,040
set is to spend a lot of time asking

99
00:03:32,040 --> 00:03:34,470
really basic questions so literally when

100
00:03:34,470 --> 00:03:36,329
you import the data print it out and

101
00:03:36,329 --> 00:03:37,410
there's a couple points that I want to

102
00:03:37,410 --> 00:03:39,959
make one this is the complete code to

103
00:03:39,959 --> 00:03:42,530
define the network so it's code concise

104
00:03:42,530 --> 00:03:44,639
too broadly

105
00:03:44,639 --> 00:03:46,920
the more layers you add to your network

106
00:03:46,920 --> 00:03:49,799
and the more neurons or units per layer

107
00:03:49,799 --> 00:03:52,109
the more capacity your network has

108
00:03:52,109 --> 00:03:54,239
meaning the more types of patterns that

109
00:03:54,239 --> 00:03:57,120
can recognize the problem is the more

110
00:03:57,120 --> 00:03:59,250
things your network can recognize the

111
00:03:59,250 --> 00:04:00,870
more likely it is to memorize the

112
00:04:00,870 --> 00:04:02,310
training data here's the cool part

113
00:04:02,310 --> 00:04:04,319
building your model is where there are

114
00:04:04,319 --> 00:04:06,209
many many machine learning concepts that

115
00:04:06,209 --> 00:04:07,650
you have to spend a lot of time learning

116
00:04:07,650 --> 00:04:10,290
the next three steps there are literally

117
00:04:10,290 --> 00:04:12,180
concepts that are basically involved

118
00:04:12,180 --> 00:04:14,010
with running an experiment here's the

119
00:04:14,010 --> 00:04:15,870
only parameter so here's how you train

120
00:04:15,870 --> 00:04:18,989
the model so it's one line fit is

121
00:04:18,989 --> 00:04:21,329
synonymous with train and we're training

122
00:04:21,329 --> 00:04:22,590
it using the training images and the

123
00:04:22,590 --> 00:04:24,330
training labels training a network is a

124
00:04:24,330 --> 00:04:27,180
little bit like tuning a guitar so think

125
00:04:27,180 --> 00:04:27,750
of you have a good

126
00:04:27,750 --> 00:04:29,730
car and you want to it starts untuned

127
00:04:29,730 --> 00:04:31,800
and you want to tune the string is to

128
00:04:31,800 --> 00:04:33,870
hit a particular note so you start

129
00:04:33,870 --> 00:04:35,820
tuning it and like every time you twist

130
00:04:35,820 --> 00:04:37,860
the wheel in the guitar you can think of

131
00:04:37,860 --> 00:04:39,450
that as an F Bach after that you can

132
00:04:39,450 --> 00:04:41,340
evaluate it and evaluate just means

133
00:04:41,340 --> 00:04:44,190
giving some new data classify it with my

134
00:04:44,190 --> 00:04:46,320
network and take a look at the accuracy

135
00:04:46,320 --> 00:04:48,090
and other metrics that's also just one

136
00:04:48,090 --> 00:04:49,410
line of code thank you very much

137
00:04:49,410 --> 00:04:50,700
everyone I really appreciate your time

138
00:04:50,700 --> 00:04:52,440
and hope this stuff is useful

139
00:04:52,440 --> 00:05:14,360
[Music]

