1
00:00:00,470 --> 00:00:05,270
[Music]

2
00:00:05,270 --> 00:00:07,589
hello everybody this is Laurence Moroney

3
00:00:07,589 --> 00:00:09,719
I'm here at the tensorflow developer

4
00:00:09,719 --> 00:00:11,639
summit were in the tensorflow cafe and

5
00:00:11,639 --> 00:00:13,380
have jeremiah with me all the way from

6
00:00:13,380 --> 00:00:15,000
Zurich that's right it's been an

7
00:00:15,000 --> 00:00:17,279
exciting trip so all the way from Zurich

8
00:00:17,279 --> 00:00:19,380
and you announced TF hub tensorflow hub

9
00:00:19,380 --> 00:00:21,210
at your talk so tell me all about it

10
00:00:21,210 --> 00:00:23,130
tester flow hub is something we're

11
00:00:23,130 --> 00:00:25,980
really excited about we realised that we

12
00:00:25,980 --> 00:00:26,869
want to help people

13
00:00:26,869 --> 00:00:28,980
reuse machine learning which anything is

14
00:00:28,980 --> 00:00:30,330
really hard to do you need a lot of

15
00:00:30,330 --> 00:00:32,850
stuff so we're letting people package up

16
00:00:32,850 --> 00:00:34,710
good machine learning and share it with

17
00:00:34,710 --> 00:00:35,070
the world

18
00:00:35,070 --> 00:00:37,110
okay now you built this in Zurich right

19
00:00:37,110 --> 00:00:39,210
we did we did this is our first big

20
00:00:39,210 --> 00:00:41,790
infrastructure project there we've been

21
00:00:41,790 --> 00:00:44,280
growing Google research to Europe we

22
00:00:44,280 --> 00:00:45,750
have a brain team there that's been

23
00:00:45,750 --> 00:00:47,100
growing and our applied machine

24
00:00:47,100 --> 00:00:49,350
intelligence team is also growing quick

25
00:00:49,350 --> 00:00:52,260
nice nice now so this TF hub it's almost

26
00:00:52,260 --> 00:00:54,210
like a natural extension to some of the

27
00:00:54,210 --> 00:00:55,649
things we've been doing on github right

28
00:00:55,649 --> 00:00:57,629
where we have like model repository and

29
00:00:57,629 --> 00:00:58,859
github but you're taking a lot further

30
00:00:58,859 --> 00:01:00,780
right right certainly sharing models

31
00:01:00,780 --> 00:01:03,090
isn't anything new the big difference

32
00:01:03,090 --> 00:01:04,680
here is that we realize that when you

33
00:01:04,680 --> 00:01:07,020
share a model either fits your problem

34
00:01:07,020 --> 00:01:08,460
exactly okay

35
00:01:08,460 --> 00:01:11,820
or it doesn't you can't use it okay you

36
00:01:11,820 --> 00:01:13,770
can either give it the inputs at once

37
00:01:13,770 --> 00:01:16,049
and take the outputs if you want to do

38
00:01:16,049 --> 00:01:17,189
anything outside that you're sunk

39
00:01:17,189 --> 00:01:19,409
alright so tensorflow hub

40
00:01:19,409 --> 00:01:21,750
gives you smaller pieces so it's more

41
00:01:21,750 --> 00:01:23,700
likely you can reuse them I think the

42
00:01:23,700 --> 00:01:25,500
way to think about it is a model is like

43
00:01:25,500 --> 00:01:28,200
a binary okay a module is like a library

44
00:01:28,200 --> 00:01:29,070
okay

45
00:01:29,070 --> 00:01:31,200
a model is a binary and a module is a

46
00:01:31,200 --> 00:01:32,159
library that's right

47
00:01:32,159 --> 00:01:33,780
we need that on a t-shirt that's right

48
00:01:33,780 --> 00:01:36,780
that's right so where can I find all

49
00:01:36,780 --> 00:01:38,189
these where is tensor hug word where

50
00:01:38,189 --> 00:01:39,720
does that live ten to five checkout

51
00:01:39,720 --> 00:01:42,210
tensorflow org flash hub tend to float

52
00:01:42,210 --> 00:01:44,130
that's easy to remember so what kind of

53
00:01:44,130 --> 00:01:45,750
models are on there well we've got all

54
00:01:45,750 --> 00:01:48,000
kinds of things we certainly have ones

55
00:01:48,000 --> 00:01:50,009
for image processing things that will

56
00:01:50,009 --> 00:01:52,259
let you help or help you build your own

57
00:01:52,259 --> 00:01:54,600
image classifiers if you use tensorflow

58
00:01:54,600 --> 00:01:56,520
for poets we've really taken that

59
00:01:56,520 --> 00:01:58,350
process and streamlined it down to

60
00:01:58,350 --> 00:02:01,829
really a single line of Python so we've

61
00:02:01,829 --> 00:02:04,020
got all kinds of all kinds of models

62
00:02:04,020 --> 00:02:05,430
some of the newer ones include the

63
00:02:05,430 --> 00:02:06,930
neural architecture search models that

64
00:02:06,930 --> 00:02:07,819
are really state-of-the-art

65
00:02:07,819 --> 00:02:10,619
as Andrew mentioned in his talk those

66
00:02:10,619 --> 00:02:11,790
are incredible because with that one

67
00:02:11,790 --> 00:02:12,160
line up

68
00:02:12,160 --> 00:02:13,930
Python you actually get over 60,000

69
00:02:13,930 --> 00:02:16,600
hours of GPU training when it's

70
00:02:16,600 --> 00:02:18,370
discovering the architecture and

71
00:02:18,370 --> 00:02:21,010
training it so it's pretty powerful so

72
00:02:21,010 --> 00:02:23,230
one line gives me 60,000 hours worth of

73
00:02:23,230 --> 00:02:25,360
training use 60,000 GPU hours yep

74
00:02:25,360 --> 00:02:27,220
there's the image ones we've also got

75
00:02:27,220 --> 00:02:29,800
some really exciting text ones where you

76
00:02:29,800 --> 00:02:31,540
can give it the entire sentence and it

77
00:02:31,540 --> 00:02:32,410
will give you back a vector that

78
00:02:32,410 --> 00:02:34,360
characterizes it and again we can do

79
00:02:34,360 --> 00:02:36,130
that same tensorflow for poets trick

80
00:02:36,130 --> 00:02:38,470
where we build a classifier on top of it

81
00:02:38,470 --> 00:02:40,060
and one of the ones we're really excited

82
00:02:40,060 --> 00:02:42,880
about is the universal sentence encoder

83
00:02:42,880 --> 00:02:45,970
this is a paper that just came out on

84
00:02:45,970 --> 00:02:48,670
Archive last night so it's just hot off

85
00:02:48,670 --> 00:02:51,430
the presses and it's great to see people

86
00:02:51,430 --> 00:02:53,200
that can use it instantly just by

87
00:02:53,200 --> 00:02:55,090
clicking on the TF hub link that's in

88
00:02:55,090 --> 00:02:56,860
the paper so what is it all about the

89
00:02:56,860 --> 00:02:59,080
universal sentence encoder so this is

90
00:02:59,080 --> 00:03:02,380
some new work that is doing things like

91
00:03:02,380 --> 00:03:04,480
letting you understand the semantic

92
00:03:04,480 --> 00:03:06,820
differences between different sentences

93
00:03:06,820 --> 00:03:08,800
it actually works on a sentence level

94
00:03:08,800 --> 00:03:10,030
which is a little bit different than

95
00:03:10,030 --> 00:03:12,370
word Tyvek a lot of those you just look

96
00:03:12,370 --> 00:03:14,350
up a single word but this will take the

97
00:03:14,350 --> 00:03:16,420
entire sentence and consider that as it

98
00:03:16,420 --> 00:03:18,070
builds this characterization in the form

99
00:03:18,070 --> 00:03:20,080
of an embedding now remember always that

100
00:03:20,080 --> 00:03:21,820
what was it the fruit flies like bananas

101
00:03:21,820 --> 00:03:23,020
have you heard of that that's right

102
00:03:23,020 --> 00:03:24,490
that's right that's the exact problem

103
00:03:24,490 --> 00:03:27,010
it's solving oh cool I have to look that

104
00:03:27,010 --> 00:03:28,660
up so what was it called again that's

105
00:03:28,660 --> 00:03:30,160
the universal sentence encoder and

106
00:03:30,160 --> 00:03:32,350
that's on TF hub already it's there

107
00:03:32,350 --> 00:03:34,030
ready for you to use it oh wow gotta

108
00:03:34,030 --> 00:03:36,040
check it out so now if I'm like a

109
00:03:36,040 --> 00:03:37,780
specialist in building models in some

110
00:03:37,780 --> 00:03:38,800
scenario I don't know what the scenario

111
00:03:38,800 --> 00:03:40,989
is and I want to contribute you know how

112
00:03:40,989 --> 00:03:42,100
would I go about doing that

113
00:03:42,100 --> 00:03:43,870
yeah we're really excited we're working

114
00:03:43,870 --> 00:03:45,370
very quickly to make it possible for

115
00:03:45,370 --> 00:03:47,410
other people to upload and share these

116
00:03:47,410 --> 00:03:48,430
things I think that's something that's

117
00:03:48,430 --> 00:03:51,270
really important to us certainly as

118
00:03:51,270 --> 00:03:53,739
talented as we are inside Google you

119
00:03:53,739 --> 00:03:56,730
know answer who is really a global

120
00:03:56,730 --> 00:03:58,660
community and there's the wisdom of

121
00:03:58,660 --> 00:04:00,190
crowds right there's there's a lot of

122
00:04:00,190 --> 00:04:01,510
people who know stuff that we don't know

123
00:04:01,510 --> 00:04:03,010
and they can that's right that's right

124
00:04:03,010 --> 00:04:06,070
cool so thank you so much this has been

125
00:04:06,070 --> 00:04:07,209
so much fun and I've learned so much

126
00:04:07,209 --> 00:04:09,220
already so I really want to try some of

127
00:04:09,220 --> 00:04:11,650
these models Liam told me about so thank

128
00:04:11,650 --> 00:04:13,750
you Jeremiah that's been fun and thanks

129
00:04:13,750 --> 00:04:15,160
everybody for watching this episode if

130
00:04:15,160 --> 00:04:16,330
you've got any questions for me if

131
00:04:16,330 --> 00:04:17,620
you've got any questions for Jeremiah

132
00:04:17,620 --> 00:04:18,790
please leave them in the comments below

133
00:04:18,790 --> 00:04:20,229
and if you're looking for any of the

134
00:04:20,229 --> 00:04:21,609
links we spoke about we'll put them in

135
00:04:21,609 --> 00:04:22,930
the description and whatever you do

136
00:04:22,930 --> 00:04:23,890
don't forget to hit that subscribe

137
00:04:23,890 --> 00:04:25,020
button like

138
00:04:25,020 --> 00:04:26,350
so much

139
00:04:26,350 --> 00:04:38,850
[Music]

140
00:04:38,850 --> 00:04:47,889
[Music]

